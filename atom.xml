<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[后端技术杂谈 | 飒然Hang]]></title>
  <link href="http://www.rowkey.me/atom.xml" rel="self"/>
  <link href="http://www.rowkey.me/"/>
  <updated>2020-06-02T06:34:52+00:00</updated>
  <id>http://www.rowkey.me/</id>
  <author>
    <name><![CDATA[飒然Hang]]></name>
    <email><![CDATA[superhj1987@126.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[技术管理者标准管理模板]]></title>
    <link href="http://www.rowkey.me/blog/2020/04/25/tech-leader-manage/"/>
    <updated>2020-04-25T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2020/04/25/tech-leader-manage</id>
    <content type="html"><![CDATA[<p>对于技术团队新晋升的一些研发Leader，即使在大公司具有完善的培训机制，大多数人在一开始还是会手足无措，不能很好地做到从个人贡献者到团队贡献者角色的转变。于是根据自己以及公司内部很多技术管理者的工作经验梳理出了一些技术管理者的管理模板，可以作为管理工作的实践参考。</p>

<!--more-->


<p><img src="http://www.rowkey.me/post_images/tech-manage.png" alt="" /></p>

<h2>看方向</h2>

<ul>
<li><p>向上级明确团队的职责</p></li>
<li><p>基于职责确定团队的使命、目标</p></li>
<li><p>把职责、使命向团队成员传达清楚</p></li>
<li><p>做好团队规划，包括：规模、分工、梯队、资源盘点等</p></li>
<li><p>建立团队的WIki，包括：职责、使命、目标、团队规划、人员分工、规章制度等</p></li>
</ul>


<h2>管事</h2>

<ul>
<li><p>OKR</p>

<ul>
<li><p>制定团队OKR，对齐公司和部门OKR</p></li>
<li><p>跟进团队成员的个人OKR制定和进度跟踪</p></li>
<li><p>跟踪OKR进展，识别高绩效人才</p></li>
</ul>
</li>
<li><p>技术管理</p>

<ul>
<li><p>参与技术方向决策，将研发规范、例会等信息明确传达给团队成员并推进</p>

<ul>
<li><p>技术评审规范</p></li>
<li><p>代码风格规范</p></li>
<li><p>代码开发规范</p></li>
<li><p>代码管理规范</p></li>
<li><p>CodeReview规范</p></li>
</ul>
</li>
<li><p>组织技术评审、CodeReview</p></li>
<li><p>制定学习分享机制并切实推行</p></li>
<li><p>团队所负责维护的系统的周期巡检</p></li>
<li><p>公司层面基础技术以及成熟开源项目的引入和推进</p></li>
</ul>
</li>
<li><p>项目管理</p>

<ul>
<li><p>技术方案确定</p>

<ul>
<li><p>技术选型</p></li>
<li><p>技术架构</p></li>
<li><p>技术难点</p></li>
<li><p>性能瓶颈</p></li>
<li><p>上下游系统</p></li>
<li><p>功能模块</p></li>
</ul>
</li>
<li><p>根据技术评审的结果预估开发工期并做好关键时间点的把控</p>

<ul>
<li><p>系统、模块、功能的设计以及简述</p></li>
<li><p>参与的研发人员以及分工</p></li>
<li><p>预估工时</p></li>
<li><p>预计完成时间</p></li>
<li><p>关键时间点、里程碑</p></li>
<li><p>确定会议机制：晨会、周会</p></li>
</ul>
</li>
<li><p>创建并保持项目文档的更新</p>

<ul>
<li><p>技术调研文档</p></li>
<li><p>方案选型文档</p></li>
<li><p>需求文档</p></li>
<li><p>系统设计文档</p></li>
</ul>
</li>
<li><p>项目风险管理</p></li>
<li><p>项目质量管理，包括代码质量把控和监控告警设施的接入</p></li>
<li><p>协调资源推进项目进展</p></li>
</ul>
</li>
<li><p>技术产品运营</p>

<ul>
<li><p>提炼团队项目的公共抽象部分，组件化和平台化</p></li>
<li><p>组件、技术平台的推广</p></li>
</ul>
</li>
<li><p>成本管理</p>

<ul>
<li><p>技术选型时把成本做为重要考量项</p></li>
<li><p>提升团队资源的利用率</p></li>
<li><p>关注团队的人力成本和技术成本</p></li>
<li><p>关注团队的产出价值</p></li>
</ul>
</li>
<li><p>流程改进</p>

<ul>
<li><p>定位阻碍研发的流程节点，寻找有效的解决方案</p></li>
<li><p>寻求有效工具或者方案提升关键流程效率</p></li>
</ul>
</li>
<li><p>制度建设</p>

<ul>
<li><p>明确公司和部门的规章制度并推进实行</p></li>
<li><p>根据团队需要，制定团队规章制度</p></li>
<li><p>制定SOP，保障下限水准</p></li>
<li><p>明确团队例会制度</p></li>
</ul>
</li>
</ul>


<h2>管人</h2>

<ul>
<li><p>定期的一对一沟通</p>

<ul>
<li><p>你所负责业务的完成情况到现在怎么样？目标完成情况怎么样？</p></li>
<li><p>这段时间自我评价绩效如何？什么原因？</p></li>
<li><p>你个人有没有什么你觉得我应该知道的？</p></li>
</ul>
</li>
<li><p>关注团队成员职业规划和能力成长，给与指导和建议</p></li>
<li><p>关注团队成员工作状态</p></li>
<li><p>组织团建，提高团队凝聚力</p></li>
</ul>


<h2>管理仪表盘</h2>

<p>建立自己的管理仪表盘，关注关键数据</p>

<ul>
<li><p>系统监控数据（QPS、硬件资源使用率、错误数等） -> 提前发现系统瓶颈，消除隐患；提高资源利用率，降低成本</p></li>
<li><p>项目构建报告（单元测试覆盖率报告、代码质量报告、构建失败与成功概况） -> 关注项目研发质量，保障持续交付</p></li>
<li><p>项目/任务进度 -> 保证项目/任务正常进行</p></li>
<li><p>业务关键数据指标 -> 关注业务价值，提升团队成员成就感</p></li>
<li><p>OKR进度 -> 关注OKR实现状况，识别高绩效人员</p></li>
<li><p>团队成员的每日/周的工作状况 -> 关注团队成员状况</p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Java工程师应该知道的Web安全]]></title>
    <link href="http://www.rowkey.me/blog/2020/03/10/web-security/"/>
    <updated>2020-03-10T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2020/03/10/web-security</id>
    <content type="html"><![CDATA[<p>Java开发很大的一个应用场景就是Web，即使不是Web, 很多时候也是采用的和Web类似的处理方式。因此了解目前常见的Web安全问题并做防范是非常关键的。</p>

<p>Web安全问题，从大的方面可以分为：</p>

<ul>
<li>客户端安全：通过浏览器进行攻击的安全问题。</li>
<li>服务端安全：通过发送请求到服务端进行攻击的安全问题。</li>
</ul>


<p>常见的客户端安全问题有：</p>

<ul>
<li>跨站脚本攻击</li>
<li>跨站点请求伪造</li>
</ul>


<p>常见的服务端安全问题有：</p>

<ul>
<li>SQL注入</li>
<li>基于约束条件的SQL攻击</li>
<li>DDOS攻击</li>
<li>Session fixation</li>
</ul>


<p>本文主要针对这些问题进行讲述。</p>

<!--more-->


<h2>跨站脚本攻击</h2>

<p>跨站脚本攻击，全称Cross Site Script（XSS），故名思议是跨越两个站点的攻击方式。一般指的是攻击方通过“HTML”注入的方式篡改了网页，插入了恶意的脚本，从而在用户浏览网页或者移动客户端使用WebView加载时，默默地做了一些控制操作。</p>

<p>XSS可以说是客户端安全的首要问题，稍有不注意就会漏出相关接口被利用。</p>

<p>一个XSS攻击的例子，如下：</p>

<ul>
<li>一个Java应用提供了一个接口可以上传个人动态，动态内容是富文本的。</li>
<li><p>攻击者上传的内容如下：</p>

<p>  <code>&lt;img src="1" onerror="alert('attack')"/&gt;</code></p></li>
<li><p>在服务端和客户端程序未做任何过滤的情况下，其他用户访问这个动态的页面时，就会执行这个脚本。</p></li>
</ul>


<p>如果脚本不是一个alert，而是换成跳转到一个具有删除操作的URL或者脚本获取用户的Cookie然后发送到远程服务器上，可想而知危害有多大。</p>

<p>防范此种攻击的常用方式有以下几种：</p>

<ul>
<li>对任何允许用户输入的地方做检查，防止其提交脚本相关特殊字符串，如script、onload、onerror等。客户端和服务端都要做检查。</li>
<li>做输入过滤，即将特殊字符都过滤掉或者换成HTML转义后的字符。Java中可以使用Apache commons-lang中的StringEscapeUtils的escape前缀的方法来做转义。</li>
<li>给Cookie属性设置上HttpOnly，可以防止脚本获取到Cookie。</li>
<li>对输出内容做过滤。这个可在客户端做，也可在服务端做。服务端主要就是转义HTML字符，客户端可以使用escape方法来过滤。</li>
</ul>


<h2>跨站点请求伪造</h2>

<p>跨站点请求伪造，全称Cross Site Request Forgery,简称CSRF。也是一种常见的攻击方式。</p>

<p>此种攻击方式，主要是通过诱导用户点击某些链接，从而隐含地发起对其他站点的请求，进而进行数据操作。</p>

<p>一个攻击示例如下：</p>

<ul>
<li>一个用户登录了一个站点，访问<a href="http://xx/delete_notes?id=xx%E5%8D%B3%E5%8F%AF%E5%88%A0%E9%99%A4%E4%B8%80%E4%B8%AA%E7%AC%94%E8%AE%B0%E3%80%82">http://xx/delete_notes?id=xx%E5%8D%B3%E5%8F%AF%E5%88%A0%E9%99%A4%E4%B8%80%E4%B8%AA%E7%AC%94%E8%AE%B0%E3%80%82</a></li>
<li><p>攻击者在它的站点中构造一个页面，HTML页面含有以下内容：</p>

<p>  <code>&lt;img src="http://xx/delete_notes?id=xx"/&gt;</code></p></li>
<li><p>当用户被诱导访问攻击者的站点时就发起了一个删除笔记的请求。</p></li>
</ul>


<p>对于CSRF攻击的常用解决方案有以下几种：</p>

<ul>
<li>对重要请求要求验证码输入,这样就能防止在用户不知情的情况下，被发送请求。</li>
<li>使用类似防盗链的机制，对header的refer进行检验以确认请求来自合法的源。</li>
<li>对重要请求都附带一个服务端生成的随机token, 提交时对此token进行验证。这也是业界一个很普遍的做法。</li>
</ul>


<h2>SQL注入</h2>

<p>SQL注入攻击是一个很常见的攻击方式，原理是通过发送特殊的参数，拼接服务端的SQL字符串，从而达到改变SQL功能的目的。</p>

<p>一个攻击例子如下：</p>

<ul>
<li><p>服务端登录验证使用下面的方式,其中userName和userPwd都是用户直接上传的参数</p>

<pre><code class="``">  String sql = "select * from user where user_name = '" + userName + "' and pwd = " + userPwd;
</code></pre></li>
<li>用户提交userName为admin&#8217;&ndash;,userPwd随便字符串xxx</li>
<li>拼接好之后的SQL语句变成了：<code>select * from user where user_name = 'admmin'--' and pwd = 'xxx'</code>（&ndash;为SQL语句的注释）, 这样只要存在user_name为admin的用户，此语句就能成功执行并返回admin用户的信息。</li>
</ul>


<p>这里需要说明的是，如果服务器的请求错误信息没有做进一步封装，直接把原始的数据库错误返回，那么有经验的攻击者通过返回结果多次尝试就会有机会找出SQL注入的机会。</p>

<p>防范此种攻击的方案有以下几个：</p>

<ul>
<li>在Java中构造SQL查询语句时，杜绝拼接用户参数，尤其是拼接SQL查询的where条件。全部使用PreparedStatement预编译语句, 通过？来传递参数。</li>
<li>在业务层面，过滤、转义SQL特殊字符，Apache commons-lang中的StringEscapeUtil提供了escapeSQL的功能（最新的lang3已经删除此方法，因为其只是简单的替换&#8217;为&#8217;&lsquo;）。</li>
</ul>


<h2>基于约束条件的SQL攻击</h2>

<p>基于约束条件的SQL攻击基于的原理如下：</p>

<ul>
<li>在处理SQL中的字符串时，字符串末尾的空格字符都会被删除，包括WHERE子句和INSERT语句，但LIKE子句除外。</li>
<li>在任意INSERT查询中，SQL会根据varchar(n)来限制字符串的最大长度，即超过n的字符串只保留前n个字符。</li>
</ul>


<p>如此，我们设计一个用户表（暂且忽略设计的合理性），对其中的用户名和密码字段都设置为25个字符限制：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>CREATE TABLE test_user (
</span><span class='line'>    `user_name` varchar(25),
</span><span class='line'>    `pwd`  varchar(25)
</span><span class='line'>);</span></code></pre></td></tr></table></div></figure>


<p>有一个user_name为<code>user_test</code>的用户注册，于是向数据库添加一条记录。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>insert into test_user values("user_test","111111");</span></code></pre></td></tr></table></div></figure>


<p>接着，一个user_name为&#8217;user_test              1&#8217;(中间留有25个空格)的用户再来注册。一般的业务逻辑如下：</p>

<ul>
<li><p>判断用户名是否存在</p>

<pre><code class="``">  select * from test_user where user_name = 'user_test              1'
</code></pre>

<p>  因为查询语句不会截断字符串，因此这样获取不到记录，表示用户不存在。</p></li>
<li><p>用户名不存在，那么插入新用户。</p>

<pre><code class="``">  insert into test_user values("user_test              1","123456")
</code></pre></li>
</ul>


<p>这样，由于<code>user_name</code>约束为25个字符，那么新用户的<code>user_name</code>成为了&#8217;user_test      &lsquo;（后面是16个空格字符）。现在数据库记录如下（第二个记录后面是16个空格）：</p>

<table>
<thead>
<tr>
<th>user_name </th>
<th> pwd</th>
</tr>
</thead>
<tbody>
<tr>
<td>user_test               </td>
<td> 111111</td>
</tr>
<tr>
<td>user_test               </td>
<td> 123456</td>
</tr>
</tbody>
</table>


<p>这样，当使用<code>user_name='user_test'</code>和<code>pwd='123456'</code>登录时，能匹配到第二条记录，登录是成功的。但是用户信息使用的第一条的记录，于是攻击者就获取到了第一个用户的操作权限。</p>

<p>防范此种攻击的措施如下：</p>

<ul>
<li>为具有唯一性的那些列添加UNIQUE索引。</li>
<li>在数据库操作前先将输入参数修剪为特定长度。</li>
</ul>


<h2>DDOS攻击</h2>

<p>DDOS，全称Distributed Denial of Service, 分布式拒绝服务攻击。攻击者利用很多台机器同时向某个服务发送大量请求，人为构造并发压力，从而使得服务被冲垮，无法为正常用户提供服务。常见的DDOS攻击包括：</p>

<ul>
<li>SYN flood</li>
<li>UDP flood</li>
<li>ICMP flood</li>
</ul>


<p>其中SYN flood是最为经典的DDOS攻击。其利用了TCP连接三次握手时需要先发送SYN的机制，通过发送大量SYN包使得服务端建立大量半连接，消耗非常多的CPU和内存。针对这种攻击，很多解决方案就是在TCP层就使用相关算法识别异常流量，直接拒绝建立连接。但是，如果攻击者控制很多机器对一个资源消耗比较大的服务接口发起正常访问请求，那么这个方式就无效了。</p>

<p>由于难于区分是否是正常用户的请求，因此DDOS是非常难以防范的，但仍有一些措施能够尽量地减少DDOS带来的影响，如下：</p>

<ul>
<li>合理使用缓存、异步等措施提高应用性能。应用抗并发的能力越强，就越不容易被DDOS冲垮服务。</li>
<li>合理使用云计算相关组件，自动识别高峰流量并做自动扩容。</li>
<li><p>在应用中限制来自某一IP或者某一设备ID的请求频率。超过此频率就将其放入黑名单，下次请求直接拒绝服务。Java中可以通过Redis的incr和expire操作来达到。如下：</p>

<pre><code class="``">  String ip = NetworkUtil.getClientIP(request, false); //获取客户端ip地址
  String key = "ddos." + ip;
  long count = suishenRedisTemplate.incr(key); //incr不会影响expire
  if (count &gt; 10000) {
      throw new AccessException("access too frequently with ip: "
           + StringUtils.defaultString(ip));
  } else {
      if (count == 1) {
          suishenRedisTemplate.expire(key, 10);
      }
      return true;
  }
</code></pre>

<p>  上述代码即可将同一IP的请求限制在十秒钟10000次。</p>

<p>  此逻辑越靠近访问链路的前面效果越好，比如直接在Nginx中拦截效果就要比在业务应用中做要好。</p></li>
</ul>


<p>还需要提到的是DDOS一个新的变种，反射型DDOS攻击，也被称为放大攻击。原理如下图所示：</p>

<p><img src="http://www.rowkey.me/post_images/reflect-ddos.png" alt="" /></p>

<p>此种攻击，攻击者并不直接攻击目标服务IP，而是伪造被攻击者的IP，发送请求包到网上一些开放的特殊服务的服务器（放大器。这些服务器由于协议的特点并不会验证源IP的真伪，于是会将数倍于请求报文的回复数据发送到被攻击者的IP，从而对后者间接形成DDOS攻击。任何设计不完善的、基于UDP请求的协议或者ICMP协议都能形成放大器，包括DNS请求、Ping请求、NTP monlist请求、SSDP协议（简单服务发现协议）等。此种攻击不需要大量的肉鸡、难以追踪，正变得越来越流行。防范此种攻击通常的手段就是进行DDOS流量清洗和增加ACL过滤规则。</p>

<h2>Session fixation</h2>

<p>Session fixation攻击，故名思议就是会话固定攻击。在我们平时的Web开发中都是基于Session做用户会话管理的。在浏览器中，Session的ID一般是存储在Cookie中的，甚至直接附带在query参数中。如果Session在未登录变为登录的情况下不发生改变的话，Session fixation攻击就形成了。</p>

<p>一个攻击示例如下：</p>

<ul>
<li>攻击者进入网站<a href="http://xx.com%E3%80%82">http://xx.com%E3%80%82</a></li>
<li>攻击者发送<a href="http://xx.com?JSESSIONID=123456%E7%BB%99%E4%B8%80%E4%B8%AA%E7%94%A8%E6%88%B7%E3%80%82">http://xx.com?JSESSIONID=123456%E7%BB%99%E4%B8%80%E4%B8%AA%E7%94%A8%E6%88%B7%E3%80%82</a></li>
<li>用户点击此链接进入网站，由于URL后面有JSESSIONID，因此直接使用此做为Session的ID。</li>
<li>用户成功登陆后，攻击者就可以利用伪造的Session ID获取用户的各种操作权限。</li>
</ul>


<p>此种攻击的关键点就在于Tomcat使用JSESSIONID做为Session ID。因此，防范此种攻击的核心之一就在于不能使用客户端传来的Session ID。此外还有以下方法：</p>

<ul>
<li>不要接受由GET或者POST参数指定的Session ID值。</li>
<li>针对每一个请求都生成新的Session。</li>
<li>只接受服务端生成的Session ID。</li>
<li>为Session指定过期时间。</li>
</ul>


<p>Java Web项目中,可以实现一个拦截器, 将使用query参数传递JSESSIONID的请求的Session删除掉：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>public void doFilter(ServletRequest request, ServletResponse response,
</span><span class='line'>                         FilterChain chain) throws IOException, ServletException
</span><span class='line'>    ...
</span><span class='line'>    
</span><span class='line'>    if (httpRequest.isRequestedSessionIdFromURL()) {
</span><span class='line'>        HttpSession session = httpRequest.getSession();
</span><span class='line'>        if (session != null) {
</span><span class='line'>            session.invalidate();
</span><span class='line'>        }
</span><span class='line'>    }
</span><span class='line'>    ...
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>此外，对于每一次登录后的Session都重新生成ID, 并设置合理的失效期。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>public JSONResult login(@RequestBody LoginRequestBody requestBody,
</span><span class='line'>                            HttpServletRequest request)
</span><span class='line'>    ...
</span><span class='line'>    boolean loginResult = doLogin();
</span><span class='line'>    if(loginResult){
</span><span class='line'>        request.changeSessionId(); //重新生成Session ID
</span><span class='line'>        request.getSession().setMaxInactiveInterval(1800); //30分钟失效
</span><span class='line'>    }
</span><span class='line'>    ...
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<h2>隐私数据存储</h2>

<p>随着市面上发生一次次数据库被脱导致用户隐私数据被泄漏的事情，越来越多的人意识到了隐私的重要性，在选择一个应用的时候也越来越在意对自己隐私数据的保护。这里所说的隐私数据包括：手机号、实名、身份证号、家庭住址、单位地址、家庭情况、密码等等。那么在技术层面如何存储这些隐私数据来保障用户的隐私安全呢？</p>

<ol>
<li><p>使用单向散列算法</p>

<p> 此种方式对明文进行加密后是无法恢复明文的，因此仅仅适用于密码这种不需要恢复明文只需要做验证的场景。</p></li>
<li><p>使用加密算法</p>

<p> 此种方式，在存储和使用用户数据的时候都进行加/解密运算，能够在一定程度上保护数据的安全性。但每次都要进行加解密使得代价有点高，而如果使用简单的算法则无法面对穷举或者字典攻击。并且加密的数据对于SQL等数据库查询语句优化是不友好的，操作都得通过程序进行。此外，算法所使用的密钥的安全也是一个问题，存储在哪里都有被拿到的机会。而如果进一步对于每个用户或者每条数据都使用不同的密钥，那么就会提高程序的逻辑复杂性。</p>

<p> 还得考虑到日志采集、数据分析等非具体业务场景，这些隐私数据最终还是要变为明文进行流通，无法从根本上保证隐私数据的安全。</p></li>
</ol>


<p>综上分析，可以采取以下这种方案：</p>

<ol>
<li><p>每一个用户都有自己的密钥，对其手机号、身份证等隐私信息使用加密算法来混淆其中的几位。如：159efadsc2681。如此，在只是需要展示这些信息的地方无须解密，直接使用即可。只有诸如发送短信、用户信用验证时才需要解密。</p></li>
<li><p>密钥存储在另一个库中，由另外一个团队维护、独立管理，具有最高级别的访问权限，访问QPS也受严格控制。</p></li>
<li><p>如果给数据分析部门提供数据，则提供隐私数据转换后的数据。例如：对用户的归属地分析，那么可以提供身份证转化为地区归属地后的信息而不是直接提供身份证号。</p></li>
</ol>


<p>如此，即使脱库也无法解密所有数据。而且密钥库和业务库独立，单独脱一个库是没有意义的。密钥库的访问权限和访问频率也都受限制，即使是内部人员脱库都很容易被发现。</p>

<p>总之，对诸如身份证号、通讯录、支付宝账号等隐私信息要注意加密或者散列存储，一定不要明文发送到客户端，展示也不要明文展示，只有当真正使用的时候再去获取明文。</p>

<blockquote><p>本文节选自《Java工程师修炼之道》一书。</p></blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Java工程师应该知道的RPC]]></title>
    <link href="http://www.rowkey.me/blog/2020/02/17/rpc/"/>
    <updated>2020-02-17T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2020/02/17/rpc</id>
    <content type="html"><![CDATA[<p>RPC, Remote Procedure Call,故名思议就是远程过程调用，一般都有跨语言支持。大规模分布式应用中普遍使用RPC来做内部服务、模块之间的数据通信，还有助于解耦服务、系统的垂直拆分，使得系统可扩展性更强，并能够让Java程序员用与开发本地程序一样的语法与方式去开发分布式应用程序。</p>

<p>RPC分为客户端（服务调用方）和服务端（服务提供方），都运行在自己的JVM中。客户端只需要引入要使用的接口，接口的实现和运行都在服务端。RPC主要依赖的技术包括序列化、反序列化和数据传输协议。是一种定义与实现相分离的设计：</p>

<p><img src="http://www.rowkey.me/post_images/rpc/rpc.png" alt="" /></p>

<p>目前Java使用比较多的RPC方案主要有RMI、Hessian、Dubbo以及Thrift。</p>

<p>这里需要提出的一点就是，这里的RPC主要指的内部服务之间的调用，因此虽然RESTful也可以用于内部服务间的调用（跨语言、跨网段、跨防火墙），但其主要用途还是为外部系统提供服务，因此本文没有将其包含在内。</p>

<!--more-->


<h2>RMI</h2>

<p>RMI，remote method invoke, 远程方法调用。是JAVA自带的远程方法调用工具，其基于TCP连接，可以使用任意端口，不易跨网段调用，不能穿越防火墙。但它是JAVA语言最开始时的设计，后来很多框架的原理都基于RMI。其调用逻辑如下图所示：</p>

<p><img src="http://www.rowkey.me/post_images/rpc/rmi.png" alt="" /></p>

<ol>
<li>服务注册：服务端注册服务绑定到注册中心registry。</li>
<li>服务查找：客户端根据服务名从注册中心查询要使用的接口获取引用。</li>
<li>服务调用：Stub序列化调用参数并将其发送给Skeleton，后者调用服务方法，并将结果序列化返回给Stub。</li>
</ol>


<p>其序列化和反序列化使用的都是JDK自带的序列化机制。</p>

<p>这里服务注册管理中心是在服务端的。其实这个可以完全独立出来作为一个单独的服务，其他的RPC框架很多都是选择zookeepr充当此角色。</p>

<p>可以使用Spring那一节讲的RmiServiceExporter和RmiProxyFactoryBean来使用RMI。</p>

<h2>Hessian</h2>

<p>Hessian是一个基于HTTP协议的RPC方案，其序列化机制是自己实现的，负载均衡和容错需要依赖于Web容器/服务。其体系结构和RMI类似，不过并没有注册中心Registry这一角色，而是通过使用地址来显式调用。其中需要使用HessianProxyFactory根据配置的地址create一个代理对象。使用此代理对象去调用服务。</p>

<p><img src="http://www.rowkey.me/post_images/rpc/hessian.png" alt="" /></p>

<p>和RMI一样，可以使用Spring那一节讲的HessianServiceExporter和HessianProxyFactoryBean来使用。</p>

<h2>Thrift</h2>

<p>Thrift是Facebook开源的RPC框架，现已进入Apache开源项目。其采用接口描述语言（IDL）定义 RPC 接口和数据类型，通过编译器生成不同语言的代码（支持 C++，Java，Python，Ruby等），数据传输采用二进制格式，是自己实现的序列化机制。没有注册中心的概念。</p>

<p><img src="http://www.rowkey.me/post_images/rpc/thrift.png" alt="" /></p>

<p>Thrift的使用需要先编写接口的IDL，然后使用它自带的工具生成代码。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>namespace java me.rowkey.pje.datatrans.rpc.thrift
</span><span class='line'>
</span><span class='line'>typedef i32 int
</span><span class='line'>service TestService
</span><span class='line'>{
</span><span class='line'>    int add(1:int n1, 2:int n2),
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>//代码生成
</span><span class='line'>thrift --gen java TestService.thrift</span></code></pre></td></tr></table></div></figure>


<p>以上即可在gen-java目录下生成TestService的Java代码TestService.java, 其中的核心是接口TestService.Iface，实现此类即可提供服务。需要注意的是Thrift有一个问题就是在接口比较多的时候，生成的Java代码文件太大。</p>

<p>服务提供方：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>TProcessor tprocessor = 
</span><span class='line'>  new TestService.Processor&lt;TestService.Iface&gt;(new TestServiceImpl());
</span><span class='line'>
</span><span class='line'>TServerSocket serverTransport = new TServerSocket(8088);
</span><span class='line'>TServer.Args tArgs = new TServer.Args(serverTransport);
</span><span class='line'>tArgs.processor(tprocessor);
</span><span class='line'>tArgs.protocolFactory(new TBinaryProtocol.Factory());
</span><span class='line'>
</span><span class='line'>// 简单的单线程服务模型
</span><span class='line'>TServer server = new TSimpleServer(tArgs);
</span><span class='line'>server.serve();</span></code></pre></td></tr></table></div></figure>


<p>服务消费方：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>TTransport transport = new TSocket("localhost", 8088, TIMEOUT);
</span><span class='line'>TestService.Client testService = 
</span><span class='line'>  new TestService.Client(new TBinaryProtocol(transport));
</span><span class='line'>transport.open();
</span><span class='line'>
</span><span class='line'>int result = testService.add(1,2);
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p>这里需要说明的一点就是，Thrift提供了多种服务器模型、数据传输协议以及传输层供选择：</p>

<ul>
<li><p>服务提供者的服务模型除了上面用的TSimpleServer简单单线程服务模型，还有几个常用的模型：</p>

<ul>
<li>TThreadPoolServer：线程池服务模型，使用标准的阻塞式IO，预先创建一组线程处理请求。</li>
<li>TNonblockingServe：非阻塞式IO。</li>
<li>THsHaServer: 半同步半异步的服务端模型。</li>
</ul>
</li>
<li><p>数据传输协议除了上面例子使用的BinaryProtocol二进制格式，还有下面几种：</p>

<ul>
<li>TCompactProtocol : 压缩格式。</li>
<li>TJSONProtocol : JSON格式。</li>
<li>TSimpleJSONProtocol : 提供JSON只写协议, 生成的文件很容易通过脚本语言解析。</li>
</ul>
</li>
<li><p>传输层除了上面例子的TServerSocket和TSocket，还有</p>

<ul>
<li>TFramedTransport：以frame为单位进行传输，非阻塞式服务中使用。</li>
<li>TFileTransport：以文件形式进行传输。</li>
<li>THttpClient: 以HTTP协议的形式进行传输。</li>
</ul>
</li>
</ul>


<h2>Dubbo</h2>

<p>Dubbo是阿里开源的服务治理框架。与前面讲的几个RPC协议相比，Dubbo不仅仅是一个RPC框架，还包含了服务治理方面的很多功能：</p>

<ul>
<li>服务注册</li>
<li>服务自动发现</li>
<li>负载均衡</li>
<li>集群容错</li>
</ul>


<p>这里仅仅针对Dubbo的RPC协议来讲，其传输是基于TCP协议的，使用了高性能的NIO框架Netty，序列化可以有多种选择，默认使用Hessian的序列化实现。Dubbo默认使用Zookeeper作为服务注册、管理中心。</p>

<p><img src="http://www.rowkey.me/post_images/rpc/dubbo.png" alt="" /></p>

<p>一个基于Spring XML配置的使用例子如下：</p>

<ul>
<li><p>服务提供者XML配置</p>

<pre><code class="``">  &lt;!-- 消费方应用名，用于计算依赖关系，不是匹配条件，不要与提供方一样 --&gt;
  &lt;dubbo:application name="test_server"/&gt;

  &lt;!-- 使用zk注册中心暴露服务地址 --&gt;
  &lt;dubbo:registry address="zookeeper://zk1.dmp.com:2181?backup=zk2.dmp.com:2181,zk3.dmp.com:2181" file="${catalina.base}/logs/eservice/dubbo.cache"/&gt;

  &lt;dubbo:service path="emailService" interface="me.rowkey.pje.rpc.test.service.IEmailService" ref="emailApiService" /&gt;
</code></pre></li>
<li><p>服务消费者XML配置</p>

<pre><code class="``">  &lt;!-- 提供方应用信息，用于计算依赖关系 --&gt;
  &lt;dubbo:application name="test_consumer"/&gt;

  &lt;!-- 使用zk注册中心 --&gt;
  &lt;dubbo:registry address="zookeeper://zk1.dmp.com:2181?backup=zk2.dmp.com:2181,zk3.dmp.com:2181" /&gt;

  &lt;dubbo:reference id="emailService" interface="me.rowkey.pje.rpc.test.service.IEmailService"/&gt;
</code></pre>

<p>  在相关bean中注入emailService即可使用。</p></li>
</ul>


<h2>序列化</h2>

<p>序列化是RPC的一个很关键的地方，序列化、反序列的速度、尺寸大小都关系着RPC的性能。包括上面提到的几个序列化协议，现在使用较为普遍的Java序列化协议有以下几种：</p>

<ol>
<li><p>Java Serialiazer</p>

<p> JDK自带的序列化机制, 使用起来比较方便。但是其是对象结构到内容的完全描述，包含所有的信息，因此速度较慢，占用空间也比较大，且只支持Java语言。一般不推荐使用。</p>

<p> 需要注意的是字段serialVersionUID的作用是为了在序列化时保持版本的兼容性，即在版本升级时反序列化仍保持对象的唯一性。否则如果你在序列化后更改/删除了类的字段，那么再反序列化时就会抛出异常;而如果设置了此字段的值，那么会将不一样的field以type的预设值填充。</p>

<pre><code class="`"> //序列化
 ByteArrayOutputStream bout = new ByteArrayOutputStream();
 ObjectOutputStream out = new ObjectOutputStream(bout);
 out.writeObject(obj);
 byte[] bytes = bout.toByteArray();

 //反序列化
 ObjectInputStream bin = new ObjectInputStream(new ByteArrayInputStream(bytes));
 bin.readObject();
</code></pre></li>
<li><p>Hessian</p>

<p> 底层是基于List和Hashmap实现的，着重于数据，附带简单的类型信息的方法，支持多种语言，兼容性比较好, 与JDK序列化相比高效且空间较小；但其在序列化的类有父类的时候，如果有字段相同，父类的值会覆盖子类的值，因此使用Hessian时一定要注意子类和父类不能有同名字段。</p>

<p> 需要注意的一点，Hessian的实现里有v1和v2两种版本的协议支持，并不兼容，推荐使用Hessian2相关的类。</p>

<p> 与后来出现的其他二进制序列化工具相比，其速度和空间都不是优势。</p>

<pre><code class="`"> //序列化
 ByteArrayOutputStream os = new ByteArrayOutputStream();
 Hessian2Output out = new Hessian2Output(os);
 out.startMessage();
 TestUser user = new TestUser();
 out.writeObject(user);
 out.completeMessage();
 out.flush();
 byte[] bytes = os.toByteArray();
 out.close();
 os.close();

 //反序列化
 ByteArrayInputStream ins = new ByteArrayInputStream(bytes);
 Hessian2Input input = new Hessian2Input(ins);
 input.startMessage();
 TestUser newUser = (TestUser)input.readObject();
 input.completeMessage();
 input.close();
 ins.close();
</code></pre></li>
<li><p>MsgPack</p>

<p> MsgPack是一个非常高效的对象序列化库，支持多种语言，有点像JSON，但是非常快，且占用空间也较小，号称比Protobuf还要快4倍。</p>

<p> 使用MsgPack需要在序列化的类上加@Message注解；为了保证序列化向后兼容，新增加的属性需要加在类的最后面，且要加@Optional注解，否则反序列化会报错。</p>

<p> 此外，MsgPack提供了动态类型的功能，通过接口Value来实现动态类型，首先将字节数组序列化为Value类型的对象，然后用converter转化为本身的类型。</p>

<p> MsgPack不足的一点就是其序列化和反序列都非常消耗资源。</p>

<pre><code class="`"> //TestUser.java
 @Message
 public class TestUser{
     private String name;
     private String mobile;
     ...
 }

 TestUser user = new TestUser();
 MessagePack messagePack = new MessagePack();

 //序列化
 byte[] bs = messagePack.write(user);

 //反序列化
 user = messagePack.read(bs, TestUser.class);
</code></pre></li>
<li><p>Kryo</p>

<p> Kryo是一个快速高效的Java对象图形序列化框架，使用简单、速度快、序列化后体积小。实现代码非常简单，远远小于MsgPack。但其文档较少，跨语言支持也较差，适用于Java语言。目前Kryo的版本到了4.x, 对于之前2.X之前版本的很多问题都做了修复。</p>

<pre><code class="`"> Kryo kryo = new Kryo();

 // 序列化
 ByteArrayOutputStream os = new ByteArrayOutputStream();
 Output output = new Output(os);
 TestUser user = new TestUser();
 kryo.writeObject(output, user);
 output.close();
 byte[] bytes = os.toByteArray();

 // 反序列化
 Input input = new Input(new ByteArrayInputStream(bytes));
 TestUser newUser = kryo.readObject(input, TestUser.class);
 input.close();
</code></pre></li>
<li><p>Thrift</p>

<p> 上面讲的Thrift RPC框架其内部的序列化机制可以单独使用，主要是对TBinaryProtocol的使用。和接口的生成方式类似，需要先定义IDL，再使用Thrift生成。其序列化性能比较高，空间占用也比较少。但其设计目标并非是单独做为序列化框架使用的，一般都是整体作为RPC框架使用的。</p>

<p> 定义IDL:</p>

<pre><code class="`"> //TestUser.thrift
 namespace java me.rowkey.pje.datatrans.rpc.thrift

 struct TestUser {
     1: required string name
     2: required string mobile
 }

 thrift --gen java TestUser.thrift
</code></pre>

<p> 使用生成的TestUser类做序列化和反序列化：</p>

<pre><code class="`"> TestUser user = new TestUser(); //由thrift代码生成引擎生成

 //序列化
 ByteArrayOutputStream bos = new ByteArrayOutputStream();
 user.write(new TBinaryProtocol(new TIOStreamTransport(bos)));
 byte[] result = bos.toByteArray();
 bos.close();

 //反序列化
 ByteArrayInputStream bis = new ByteArrayInputStream(result);
 TestUser user = new TestUser();
 user.read(new TBinaryProtocol(new TIOStreamTransport(bis)));
 bis.close();
</code></pre>

<p> 需要注意的是由于Thrift序列化时,丢弃了部分信息，使用ID+Type来做标识，因此对新增的字段属性, 采用ID递增的方式标识并以Optional修饰来添加才能做到向后兼容。</p></li>
<li><p>Protobuf</p>

<p>Protobuf是Google开源的序列化框架，是Google公司内部的混合语言数据标准，用于RPC系统和持续数据存储系统，非常轻便高效，具有很好的可扩展性、也具有良好的向后兼容和向前兼容性。与上述的几种序列化框架对比，序列化数据紧凑、速度快、空间占用少、资源消耗较低、使用简单，但其缺点在于需要静态编译生成代码、可读性差、缺乏自描述、向后兼容有一定的约束限制。</p>

<p>这里需要注意目前ProtoBuf的版本到了3.x，比2.x支持更多语言但更简洁。去掉了一些复杂的语法和特性，更强调约定而弱化语法。因此，如果是首次使用就直接使用3.x版本。这里也针对Protobuf 3来讲。</p>

<p>首先需要编写.proto文件,并使用Protobuf代码生成引擎生成Java代码。</p>

<pre><code class="`"> //TestUser.proto
 syntax = "proto3";
 option java_package = "me.rowkey.pje.datatrans.rpc.proto";
 option java_outer_classname = "TestUserProto";
 message TestUser
 {
     string name=1;
     string mobile=2;
 }

 protoc --java_out=./ TestUser.proto
</code></pre>

<p>即生成TestUserProto.java，使用此类，即可完成序列化和反序列化：</p>

<pre><code class="`"> //序列化
 TestUserProto.TestUser testUser = 
           TestUserProto.TestUser.newBuilder()
           .setMobile("xxx")
           .setName("xxx")
           .build();

 byte[] bytes = testUser.toByteArray();

 //反序列化
 testUser = TestUserProto.TestUser.parseFrom(bytes);
</code></pre></li>
</ol>


<p>综上，对以上几个序列化框架做对比如下：</p>

<p> | 优点 | 缺点
&mdash;-|&mdash;&ndash;|&mdash;&mdash;
Java | JDK自带实现，包含对象的所有信息| 速度较慢，占用空间也比较大，只支持Java语言
Hessian | 支持语言比较多，兼容性较好 | 较慢
MsgPack | 使用简单，速度快，体积小| 兼容性较差，耗资源
Kryo | 速度快，序列化后体积小 | 跨语言支持较差，文档较少
Thrift | 高效 | 需要静态编译；是Thrift内部序列化机制，很难和其他传输层协议共同使用
Protobuf | 速度快 | 需要静态编译</p>

<p>在兼顾使用简单、速度快、体积小且主要使用在Java开发的场景下，Kryo是比较好的方案；如果特别要求占用空间、性能，那么Protobuf则是更好的选择。此外，JSON其实也是一种序列化方式，如果比较关注阅读性的话，那么JSON是更好的选择。</p>

<h2>提示</h2>

<p>面对这些RPC框架，选择的时候应该从以下几方面进行考虑：</p>

<ul>
<li>是否允许代码侵入：即是否需要依赖相应的代码生成器生成代码，比如Thrift需要，而Dubbo、Hessian就不需要。</li>
<li>是否需要长连接、二进制序列化获取高性能：如果需要性能比较高，那么果断选取基于TCP的Thrift、Dubbo。</li>
<li>是否需要跨网段、跨防火墙：这种情况一般就需要选择基于Http协议的，Hessian和Thrift的HTTP Transport。</li>
<li>是否需要跨语言调用：Thrift、Hessian对于语言的支持是比较丰富的，而Dubbo目前只支持Java语言。</li>
</ul>


<p>此外，除了上述框架之外，Google推出的基于HTTP 2.0的gRPC框架也开始得到了应用，其序列化协议基于Protobuf, 网络框架使用了Netty4。但其需要生成代码，可扩展性也比较差。</p>

<blockquote><p>本文节选自《Java工程师修炼之道》一书。</p></blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[我是科蜜，20年的...]]></title>
    <link href="http://www.rowkey.me/blog/2020/01/27/kobe/"/>
    <updated>2020-01-27T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2020/01/27/kobe</id>
    <content type="html"><![CDATA[<p>5：30左右突然惊醒，拿起手机一看有同学给我发微信说科比挂了。我大大的问号，赶快看了一下朋友圈和网易新闻，已经有人发出了国外网站正式的报道。。。心里顿时五味陈杂，一时不知道如何是好。一个陪伴了自己整个少年时代的偶像说没就没了，还是以这种意外的方式，相信好胜心那么强的他也是非常不甘心的。也许有人会说，人家这么一个超级巨星，你们这些粉丝矫情啥，人家都不认识你。确实，我的存在对他来说是无所谓的，但是他对我的意义却是不一般，我也相信他对于无数他的粉丝都有不一样的意义。</p>

<!--more-->


<p>记得2000年我上初中，在同学家里玩NBA Live游戏，同学跟我说这个湖人队8号投篮真准，那是我第一次认识科比。那时候电视只有中央2台每周会播一次nba比赛，每到湖人比赛我都必看。也到处搜集科比的各种贴画，家里贴满了他的海报。那时候自己的爱好就是搜集科比的各种资料。也是因为科比，我开始喜欢上打篮球，虽然受限于身高，水平一直不咋样，但好胜心和他差不多，经常为了赢不了球，摸不到球，上不了场而特别难受。</p>

<p>后来上了初四实验班（相当于高中提前录取），由于是微机实验班，学习比较轻松，有很多时间来做一些自己喜欢的事情。而对我自己来说，除了摆弄一些电脑的事情，就是看各种体育新闻、看科比的新闻。那时候班里同学们会经常一起买篮球报、当代体育、篮球先锋报，然后换着看。当然，青春时代，少不了的就是“比”，经常和同学争论是科比厉害还是艾佛森、卡特、麦迪厉害。而2003年的科比闹出了鹰郡性侵案，迎来了人生的谷底，自己看到了他的各种无助和无奈，感觉全世界都开始抛弃他。不过最终他还是挣脱了出来，有了单场62分、单场81分、赛季场均35.4分的神迹，也把自己的球衣号码换成了24号，那意味着每天每个小时都要努力，也意味着他蜕变成了一个领袖。那时候的我也已经正式开始了高中生涯，和以前不一样的是，学习压力开始变得巨大，每天就是做题考试，生活也开始变得枯燥，一周半天假，一个月一天半假，休息时间也开始变得多余，而且我们班还禁止打篮球。。。自己只能靠去看科比的各种新闻作为调节剂，他每一次表现好，我也就状态好，也就考的好。那时真的以为自己和他有某种关联了。。。也会和同学见缝插针的去打球，即使是课间休息的那十分钟。和他这段经历类似的是，我小学初中一直是年级第一第二，但高中在班级里一直处于十几名的位置，是包括我后面大学的所有学生生涯的谷底，但高考我发挥还不错，第一次考了班级第一，虽然是因为班里几个学神发挥不太好，但是分数我也是比较满意的。</p>

<p>后来上了大学，依然热情不减，宿舍的墙上都是科比的海报，鼠标也是湖人款的。也看着湖人慢慢组建齐了冠军阵容，直到09年夺冠，那一刻我当时就哭了。从巅峰到谷底再到巅峰，那种经历想想就令人动容。尤其是10年，还记得总决赛最后一场的上半场已经落后将近20分，当时我心灰意冷，再加上早起看比赛，实在忍不住困意倒头就睡了。在睡梦中突然听到全宿舍楼的人在欢呼，我心想不会逆转了吧，打开电视看到科比在欢呼，那一刻就感觉自己拿了总冠军一样。那年的我正式本科毕业，专业第一保送了研究生，也算是和科比的巅峰关联吧。</p>

<p>再后面，湖人的夺冠班底逐渐散了，从此一蹶不振。科比也一次次遭遇伤病从而无奈退役。我自己也从研究生毕业开始走上社会，也慢慢变得没时间没兴趣看nba比赛，尤其是科比退役之后，真的是觉得nba这些比赛没啥意思。科比退役后的各种新闻还是会让我激动，他拿了奥斯卡最佳短片动画奖，他开公司，他和马云在企业峰会上高谈阔论，他来中国参加综艺节目，他参加雪碧慈善邀请赛，我真觉得他退役后的成就有可能超越他的篮球成就。记得离他最近的一次就是14年科比受马云的邀请来阿里，虽然是在隔壁的公司里，虽然自己还是没见到。。。我自己一直以来的梦想之一就是有一天可以变得足够优秀能够和他成为朋友，能够在洛杉矶做他的邻居。可惜这一切再也不可能实现。。。也可能成为我这一生最大的遗憾之一。</p>

<p>就是这个人，凌晨四点的洛杉矶、对队友的严格要求、右手受伤就把左手投篮练出来、手指扭了硬生生掰回去继续比赛，他的好胜心、偏执和努力激励我的进步，他是我的青春。这就是科比对一个20年科蜜的意义。</p>

<p>谢谢你，科比！祝福你在天堂里可以继续你的精彩。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[我的2019]]></title>
    <link href="http://www.rowkey.me/blog/2020/01/23/my2019/"/>
    <updated>2020-01-23T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2020/01/23/my2019</id>
    <content type="html"><![CDATA[<p>和去年一样，本文来自自己给部门的公开信。内容经过脱敏。</p>

<hr />

<p>2020年已经过去了快一个月。回顾2019年，真的感谢大家，总体来看，部门的全年产出是符合预期的，也获得了其他需求部门的高度好评。不仅仅支撑了微鲤看看、广告平台、用户增长等业务相关系统的快速迭代，也不断地在探索运维基础设施、前端基础设施、大数据平台、推荐系统、公共组件、技术中间件并取得了一些令人印象深刻的成果。</p>

<p>要求了大家做全年的总结和新的一年的规划，我自己也从工作、学习和生活三个方面来总结一下我自己的2019年。</p>

<!--more-->


<h2>工作</h2>

<p>说到工作，特别想跟大家说一下加班的问题。由于公司战略的要求，公司在年底的几个月开始了大小周，目的是为了增加产出，也是为了让大家能够有一种创业公司的心气。也有部门的同事跟我反映过说部门不怎么加班，感受不到创业公司的气氛。这一点非常值得称赞。我在这里再讲一下我对加班的看法。</p>

<ul>
<li>加班的目的并不是加班，而是提高产出，那么产出是由效率和时间决定的。如果时间增加，但是效率下降，大部分情况下，产出也是下降的。</li>
<li>对于脑力工作者，每天能够高效工作5、6小时就很了不起了，再多的时间其实是低效劳动，太过疲劳反而容易出错。</li>
<li>很多人工作散漫，干活拖拖拉拉，心想着干不完就加会儿班。在合理的时间内干不完活而加班，是工作能力低的表现，这种行为并不值得提倡。</li>
<li>根据我自己的经验看，长期加班，根源问题基本都是“项目失控”。由于技术中心的特殊性，很多项目都是没有产品经理也基本面向的都是内部人员，项目的排期安排一直以来都是让每个人来定的。只要合理，我一般都不会有什么意见，有问题也一直欢迎大家跟我提意见。如果你定了deadline，却经常需要加班来赶进度，明显的就是在评估工时、项目管控上有问题。当然，我过去做的不好的一点就是只给进度要求，不给资源，这一点我会注意改进。</li>
<li>死守自己的deadline-高标准、准时、保质保量、不给其他同事挖坑。最好的团队合作，不是你整天对别人的工作指手画脚，整天看着各种客观原因，而是把自己的事情做到位，做到极致。这也是我今年讲的最多的要具有“owner意识”：把交给自己的任务当成自己的东西，追求极致，最后受益的不仅仅是公司，你自己也会得到最大的成长和他人的认可。</li>
<li>少加班，多动脑。和我之前听到过的说法“脑子要比手快”是一个道理。做事之前，先想想有没有更好的办法，比立即就闷头苦干，最终带来的效果可能是千差万别的。而且，作为一个公司、一个商业组织来说，最终看的只能是功劳，不会是苦劳。</li>
<li>脑力工作者想要划水摸鱼，很难被发现。我并不想给大家营造一种加班的氛围，非得大家每天在公司待到九点十点才行。我希望的是大家都是志同道合的人，是即使不加班，也会在业余时间思考、学习的人。</li>
</ul>


<p>还有一点需要提的是一个概念叫“情绪自由”。怎么说呢？之前，有同事跟我讨论了这个“情绪自由”的问题。就是说你所处的位置有时候决定了你敢不敢发泄你的情绪？比如说，你是一个没有管理职权的开发工程师，那么大部分情况下，即使你心里有情绪也不会发泄出来，因为你知道发泄出来也没用。而如果你是一个Leader，在你团队成员面前，很多时候就会随意让情绪宣泄出来。这个其实非常不好，尤其是对于一个公司的管理层来说，如果总是“情绪自由”，那么大家就会越来越不敢提问题，隐藏在看不到的地方的问题也就越来越多，累积起来一旦爆发那么后果也会严重的多。</p>

<p>接下来，从部门管理、架构、技术团队管理三个部分来讲一下2019年我完成的工作。</p>

<h3>部门管理</h3>

<p>2019年部门发生了一些组织架构改动，组织架构的改动服务于公司的整体目标，随之而来的则是人员的变动，再加上持续的有人加入有人离开，人员的变动带来了一系列问题：如何让大家知道并深刻理解部门的文化，如何融入部门，如何更有凝聚力。对于这些，做的一些工作包括：</p>

<ul>
<li>重新定义了部门的文化：<strong>极客创新、及时反馈</strong>，对之前的“件件有着落、事事有回音”做了简化的同时，还增加了极客创新，目的就是让大家意识到“技术中心”应该是一个创新部门，是一个用创新提升业务的部门。</li>
<li>重新梳理了部门的月度例会流程，包括：

<ul>
<li>不断念经，让大家能够深刻理解并贯彻部门文化</li>
<li>同步OKR进度，让大家随时了解部门的OKR进度，知道关键目标在哪</li>
<li>增加了“每月分享”环节，让大家分享自己工作、生活中的心得，给大家带来启发</li>
</ul>
</li>
<li>探索除了聚餐之外的团建形式，实践形式包括：switch游戏比赛、组队知识竞赛、巅峰故事会等。</li>
</ul>


<p>部门的梯队建设也有了一定程度的起色，在各个团队Leader的共同努力之下，每个团队都有增员。</p>

<p>此外，今年由于某些原因，自己承担了行政人事事务决策的工作，帮助行政人事部门做了一些工作。</p>

<h3>架构</h3>

<p>架构组是今年才正式成立的。也引入了公司第一个专职架构师，从最终的结果来看，大大分担了我自己在架构方面的工作，在业务的保障上也达到了预期，证明了架构师机制的有效性。此外，在公共组件、技术中间件的引入和开发上，相比之前在速度和效果上都有提升。我自己这方面的工作主要集中于上半年。</p>

<p>此外，针对目前公司的技术Leader架构能力欠缺的问题，聘请了外部的技术顾问来做架构方面的培训。</p>

<h3>技术团队管理</h3>

<p>随着业务的增长，2019年公司的技术团队规模也在激增。2019年自己的重心是在技术团队的整体管理上。</p>

<p>首先，一直困扰我的是，做为公司的CTO，职责是什么？重点工作是什么？如果换成一个人来代替我，他会做什么？针对这个，我看了不少书，也问了不少朋友和前同事。最后基本上是扫清了自己的困惑，明确了自己的重点工作。可以分为四个部分：</p>

<ol>
<li>业务支撑：公司是一个产品驱动的公司，因此业务肯定是最重要的。保证业务的稳定性，支撑业务的快速迭代，这些都是重点工作。</li>
<li>工程效率提升：技术团队的规模增大，带来的并不一定是产出提高。必须有相应的配套研发流程、基础设施才能使得人员规模的增大带来整体产能的提高。今年组织技术Leader学习了《持续交付2.0》一书，并结合公司目前的实际情况，针对持续交付流水线进行了升级优化。也针对工程效率专门成立了“工程效率”小组，来识别研发流程的瓶颈，进行针对性优化。此外，今年也着重强调了全端工程化的问题，尤其全端监控体系的建设。</li>
<li>科技能力提升：和第一点有所关联。需要去识别公司业务发展上的一些技术瓶颈，做技术预研。</li>
<li>梯队建设：针对2018年的梯队现状，2019年定的招人基调是“资深带队、高级为主、中级可成长”，主要招聘高级开发，初中级招实习生培养。年底梳理了新的研发岗位职级要求，从最终的定级结果来看，研发梯队的层次基本达到了目标。此外，由于公司的很多技术Leader都是在公司成长起来的，缺乏成熟的管理经验，下半年举办了几次技术管理的培训课，以加强技术管理者对管理的认知和管理技能的掌握。</li>
</ol>


<p>此外，2019年公司强调了横向委员会的横向协同职能。年初正式确认了技术委员会的运行机制，并切实推行了起来。自己也加强了对各个技术方向的工作把控。</p>

<h2>学习</h2>

<p>2019年年初定了将近30本书的阅读计划，到年底完成了大约14本。</p>

<ul>
<li><p><a href="https://book.douban.com/subject/26760576/">清教徒的礼物</a></p>

<blockquote><p>同学推荐的一本管理书籍，主要是讲的美国的管理文化在世界各地的普及，尤其是日本和中国。阐述了清教徒（第一批欧洲移民，起源于英国，在北美殖民地得以实践与发展）的一些特质，也是美国能够打赢两次世界大战的原因，包括：建造“人间天国”的坚定信念；亲力亲为的技师精神；集体主义；组织能力：善于协调各种财力、物力和人力的组织能力。并且在书的最后给出了管理黄金时代优秀实务背后的25条原理。看完这本书，对于其中的一些东西很有共鸣，比如：自下而上的管理、专家（职业经理人）崇拜的危害等。</p></blockquote></li>
<li><p><a href="https://book.douban.com/subject/30419555/">持续交付2.0</a></p>

<blockquote><p>作者乔梁是《持续交付: 发布可靠软件的系统方法》的译者，同时也是此书作者在thoughtworks的同事，目前是腾讯等很多互联网公司的高级管理顾问。这本书称为2.0是在上述一书中加入了精益创业部分，形成双环模型。阐述了持续交付的概念以及具体到部署流水线各个环节的建立、优化等，涵盖了产品、研发、测试、运维等诸多方面。对于提高产研效率有非常大的帮助。</p></blockquote></li>
<li><p><a href="https://book.douban.com/subject/30333919/">架构简洁之道</a></p>

<blockquote><p>作者是鼎鼎大名的Uncle Bob，自己之前一直在看此书的英文原版。此书虽然讲的是传统单体软件架构的一些设计模式、原则等，但是本质上和现在的SOA、微服务是一样的。阐述了什么是架构、如何衡量架构、三大编程范式的本质、架构设计原则、组件原则等。并着重阐述了区别与传统的MVC分层架构的简洁架构是如何解决无法展现具体的业务领域、不能防止跨层调用等问题的。</p></blockquote></li>
<li><p><a href="https://book.douban.com/subject/30254993/">稻盛和夫哲学精要</a></p>

<blockquote><p>稻盛和夫是“盛和塾”（向企业家塾生义务传授经营哲学）的创始人，被称为日本经营之圣。他曾经创办过两家世界五百强企业，并曾经把日航从破产重建带到扭亏为盈。此书主要汇集了他的一些经营哲学。令我印象较深的有：小善大恶，大善小恶；仔细思考直到“看到结果”的状态；乐观构思，悲观计划，乐观实行；付出不亚于任何人的努力；现金与票据一一对应原则；时刻怀有谦卑之心；为别人的成就叫好。书的内容不多，就是一个小册子，时常翻阅能够不断有新的启发和认识。</p></blockquote></li>
<li><p><a href="https://book.douban.com/subject/6749832/">复杂</a></p>

<blockquote><p>什么是复杂科学？其中包括哪些知识。这本书就是对复杂科学的一些讲解。横跨生物、技术和社会学等领域，并探寻复杂系统的普遍规律，此外还探讨了复杂性与进化、人工智能、计算、遗传、信息处理等领域的关系。令我印象深刻的包括遗传算法的普遍形式、自相似分形的意义、冯诺依曼的冯诺依曼计算机体系以及元胞自动机、无尺度网络幂次定律。其中适用于互联网领域的幂次定律能够揭示不少东西。</p></blockquote></li>
<li><p><a href="https://book.douban.com/subject/26895988/">学习之道</a></p>

<blockquote><p>阐述了学习并且能够让学习到的东西成为自己知识的一些高效方法和思维模式。令我印象深刻的有发散思维的3B方法: Bus、Bed、Bath。即专注思维下容易陷入思维定式，这时候试着转换到这三种场景下，能够切换到发散思维，有时候会有意想不到的思路。</p></blockquote></li>
<li><p><a href="https://book.douban.com/subject/34812013/">中台战略：中台建设与数字商业</a>&amp;&amp;<a href="https://book.douban.com/subject/27039508/">企业IT架构转型之道</a>&amp;&amp;<a href="https://time.geekbang.org/column/intro/234">极客时间《说透中台》</a></p>

<blockquote><p>这三本书/课程放在一起，主要都是对中台这个2019年技术圈最流行的词的讲述，第一本是云栖科技基于这些年它们支撑过的企业中台建设经验沉淀出的方法论和实践，第二本则是阿里巴巴的共享业务中台的构建之路以及具体的实现策略，最后一个课程则是来源于thoughtworks的一些企业中台落地场景。综合对比其他各种博文、书籍来看，这三本书讲的比较符合我自己的理解。总体概括：中台是企业级能力复用平台，相比起平台，其更注重自助化、可配置、运营和业务；中台也不是银弹，并非所有企业都需要。对中台的概念以及中台的具体实施感兴趣的可以参考这三本书/课程。</p></blockquote></li>
<li><p><a href="https://book.douban.com/subject/27040502/">CTO说</a></p>

<blockquote><p>此书来自于51CTO举办的CTO训练营的讲师们的课程。通过阅读此书，进一步提升了我对CTO这个角色的认知，包括职责、需要做好的事情、需要具有的能力等。也从中得到了不少可以在公司落地的想法，包括如何更好的做绩效管理、如何建立优秀技术团队、建立自己的管理仪表盘来密切关注数据、把事故复盘会改成宕机培训学校、建立新晋技术管理者的管理模板等等。总体来看，非常值得新的CTO们一读。</p></blockquote></li>
<li><p><a href="https://book.douban.com/subject/26901342/">管理的常识</a></p>

<blockquote><p>作者是陈春花，既是企业管理教授也有企业高管经历，是国内管理大师级的人物，写了非常多的管理著作，其公众号“春暖花开”会经常分享她对管理的一些思考，非常值得订阅。《管理的常识》此书引用了其他经典管理书籍/理论阐述了管理理论中的一些常识，包括了管理、组织、组织结构、领导、激励、决策等。让自己印象深刻的包括：管理最终只以成就做为衡量标准；有效的管理就是帮助同事（上级和下属）发挥长处并避免用到他们的短处；职能部门是不能具有权利的；没有不好的士兵，只有不好的将军，需要针对不同员工选用不同的领导风格；群体决策并不是最好的决策方式，而是风险较小的决策方式。推荐企业管理者阅读此书。</p></blockquote></li>
<li><p><a href="https://book.douban.com/subject/26953606/">人类简史</a></p>

<blockquote><p>认知革命使人类成为想象的共同体，农业革命使人类陷入奢侈生活的陷阱，科技革命终将使人类成为神一样的存在。人类通过想象和虚构的能力将彼此连接、有效合作，国家、宗教、企业都是想象和虚构的现实，人类依靠这种想象来寻找认同、开展合作，由此一步步登上食物链的顶端，抵达其他生物无法企及的地位。这本书从智人的角度回顾并理清影响人类发展的重大脉络，视角很广。概括起来就是人类和其他动物本质没任何区别，甚至基因复杂度还不如一些动物，需要在大历史中重新审视人类自己。宗教那一部分佛教主张在痛苦的时候，去想问题的本质忽略感受就能让自己不痛苦，让自己有所启发。</p></blockquote></li>
<li><p><a href="https://book.douban.com/subject/33424487/">时间的秩序</a></p>

<blockquote><p>这本书主要讲述的是时间的本质，内容不多，但看完的感觉真是不明觉厉。包括：时间不是统一的，区别于海拔高度和速度，时间的快慢都不一样；微观世界不同于宏观世界，很多事情都反常识。感觉需要多看几遍才能不断有所理解。</p></blockquote></li>
<li><p><a href="https://book.douban.com/subject/26910621/">六项思考帽</a></p>

<blockquote><p>这本书讲的是一种简单高效的思考方式，只允许思考者同一时间做一件事情，学会将逻辑与情感、创造与信息区分开来。六项不同颜色的代表不同的思考方式，戴上某一项帽子，那么就要遵循当前的思考方式来思考问题，从而避免大家讨论问题时的各种冲突，以更好地引导集体智慧，从而解决问题，提高生产力。使用这种方法时，团队需要学会怎样把思考过程分为六个不同的方向。</p></blockquote></li>
</ul>


<p>以上是已经完成阅读的书籍，目前包括了2019年未完成以及新加入的待读书籍列表如下：</p>

<h3>工作</h3>

<ul>
<li>极客时间《研发效率破局之道》</li>
<li>持续交付: 发布可靠软件的系统方法</li>
<li>数据即未来</li>
</ul>


<h3>管理</h3>

<ul>
<li>我读管理经典</li>
<li>人月神话</li>
</ul>


<h3>技术</h3>

<ul>
<li>程序员的三门课</li>
<li>许世伟的架构课</li>
<li>未来架构</li>
<li>分布式系统概念与设计</li>
<li>分布式Java应用</li>
<li>大数据日知录</li>
<li>数据密集型系统设计</li>
</ul>


<h3>企业</h3>

<ul>
<li>公司进化论</li>
<li>闪电式扩张</li>
<li>创新者的窘境</li>
<li>良性增长</li>
<li>定位：有史以来对美国营销影响最大观念</li>
<li>刷新：重新发现商业与未来</li>
<li>超级版图：全球供应链、超级城市与新商业文明的崛起</li>
</ul>


<h3>其他</h3>

<ul>
<li>少有人走的路：每天十分钟，一学就会的心灵疗愈法</li>
<li>极简宇宙史</li>
</ul>


<p>需要额外说一下的是，这些书我以前倾向于看纸质书的，但2019年能够在微信读书APP上找到的基本都在上面看了。其中最大的好处就是当某个知识点记不太清楚的时候，很容易就可以搜索到，这个比纸质书籍方便太多了。但不好的就是缺少阅读纸质书的那种感觉，并且很多新书开始只有纸质版。</p>

<h2>生活</h2>

<p>生活上，上半年依然在坚持健身，下半年由于健身房的变动而停止。但是重新开启了篮球运动，基本上能够做到一周两个小时的运动量，自己也会隔几天在家里做俯卧撑、仰卧起坐等运动。整体状态上还算不错，但年底的体检还是一些小毛病，有点郁闷。so，开始从饮食方面来控制。最近感觉体重开始有所下降了。希望能坚持下去。</p>

<h2>总结</h2>

<p>以上就是2019年自己的总结。整体来看，是满意中夹杂着失望的。新的一年，自己的计划如下：</p>

<ul>
<li>加强自己的情绪管理，能够更理性地处理事情、解决问题。</li>
<li>继续弥补自身在业务和数据Sense、成本意识、商业谈判能力、产品管理能力这些方面能力的短板。</li>
<li>完成中台架构（组织和技术）在公司的落地或者不落地。</li>
<li>继续完善整个技术团队的顶层技术体系建设。</li>
<li>重点跟进企业效能提升工作，包括工程效率和内部IT系统建设。</li>
<li>全面优化技术成本，包括提高资源利用率、降低无效成本。</li>
<li>进一步探索并完善架构师机制，保证业务稳定性和技术先进性。</li>
<li>建立客户端架构组，统一把控客户端基础技术体系建设。</li>
<li>推进数据团队的融合，有效完成几个数据相关项目的开发和上线。</li>
<li>推进Devops平台的开发和上线。</li>
<li>完成2019年读书计划中剩下的书籍。</li>
<li>坚持锻炼，身体是最重要的。</li>
</ul>


<p>最后，最近武汉肺炎的事情正在愈演愈烈。大家务必注意自己和家人的安全，少出门，出门记得戴口罩。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[《管理的常识》学习笔记]]></title>
    <link href="http://www.rowkey.me/blog/2019/12/20/manage-notes/"/>
    <updated>2019-12-20T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2019/12/20/manage-notes</id>
    <content type="html"><![CDATA[<blockquote><p>作者是陈春花教授，既是企业管理教授也有企业高管经历，是国内管理大师级的人物，写了非常多的管理著作，其公众号“春暖花开”会经常分享她对管理的一些思考，非常值得订阅。《管理的常识》此书主要讲了管理理论中的一些常识，包括了管理的概念、组织、组织结构、领导、激励、决策等。让自己印象深刻的包括管理最终只以成就做为衡量标准；职能部门是不能具有权利的；群体决策并不是最好的决策方式，而是风险较小的决策方式。推荐企业管理者阅读此书。</p></blockquote>

<p>今年随着公司人员规模的不断扩大，自己越发意识到了管理的重要性。尤其对于技术管理者来说，程序员的思维和管理者的思维有很多地方是截然不同的，如果不做好认知的改变和思维的转变，很容易用惯性思维来做事，那么一个非常优秀的研发工程师很可能会成为一个非常不合格的管理者。所以，自己一直在寻找管理的书籍、课程来学习。其中，《管理的常识》这本书是极客邦TGO寄来的礼物，仔细阅读了一下，还是有不少启发的。</p>

<!--more-->


<p>先给出自己笔记的思维导图，如下：</p>

<p><a href="http://www.rowkey.me/post_images/manage-notes.png" target="_blank"><img src="http://www.rowkey.me/post_images/manage-notes.png"/></a></p>

<p>其中让自己印象比较深刻的几点：</p>

<ul>
<li>管理最终只以成就做为衡量标准，需要知行合一</li>
<li>职能部门不能具有权利，因为其并不直接与业务相关</li>
<li>群体决策并不是最好的决策方式，而是风险较小的决策方式。当品质比成员接受程度高时，独断式决策；当接受程度比品质重要时，群体决策（共识）；品质和接受程度都高时，咨询式决策；品质和成员接受程度都不高时，哪个方便选择哪个</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[技术琐话]]></title>
    <link href="http://www.rowkey.me/blog/2019/12/18/tech-talk/"/>
    <updated>2019-12-18T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2019/12/18/tech-talk</id>
    <content type="html"><![CDATA[<p>日常的工作学习中，经常会看到好的知识点，对自己有提示的一句话，或者是自己突然想通了一件事情。这里以“技术琐话”作为主题来聚合：<a href="https://www.rowkey.me/blog/talks/">技术琐话</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[中台简谈]]></title>
    <link href="http://www.rowkey.me/blog/2019/11/23/middle-talk/"/>
    <updated>2019-11-23T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2019/11/23/middle-talk</id>
    <content type="html"><![CDATA[<blockquote><p>面对新事物，先接纳，再判断。不要轻易就否定，即使经过自己的思考后确实没啥价值，这期间的思考过程也是一种知识梳理和思维锻炼。</p></blockquote>

<p>2019年技术圈最火的一个词非“中台”莫属了。联想到公司已经在持续做的平台化，其实会让人感到混乱。平台和中台有啥区别？有了中台，那么前台和后台又指的什么？本文是自己在调研中台概念中沉淀出来的一些思考。</p>

<!--more-->


<h2>中台是什么</h2>

<p>一种特殊形式的平台，抽象业务/系统的共性，支撑业务快速发展，是<strong>企业级共享能力平台</strong>。其核心在于对业务、数据、技术的抽象，对服务能力进行复用。解决重复开发、数据分散、试错成本高的问题。中台突出的是规划控制和协调的能力，前台强调的是创新和灵活多变。</p>

<ul>
<li>业务中台：多个前台业务应用共享的需求，关注如何支撑在线主营业务。一般来说业务中台由多个中心系统组成。</li>
<li>数据中台: 专用的数据处理平台，用技术连接大数据计算存储能力，用业务连接数据应用场景能力的平台。</li>
<li>技术中台：整合和包装了云基础设施以及在其上的各种技术中间件，并在此基础上建设和封装了简单易用的能力接口，提供了基础设施重用的能力。</li>
<li>研发中台：关注应用研发效率的管理平台，为应用的开发提供了流程、质量管控和持续交付的能力。</li>
<li>移动中台：平台级的移动端开发支持</li>
<li>AI中台：数据中台之上，模型的训练、发布，智能服务的构建自动化，统一的元数据管理体系，模型的全生命周期管理。</li>
<li>组织中台：与中台技术架构相匹配的组织架构</li>
</ul>


<p>众多的可复用能力只是中台的形，<strong>核心的业务数据和业务流程</strong>才是中台存在的本质。</p>

<h2>为什么要有中台</h2>

<p><strong>传统的烟囱式架构面临的问题</strong></p>

<ul>
<li>重复性建设对人力物力的浪费</li>
<li>系统间交互的集成和协作成本昂贵</li>
<li>不利于业务沉淀和持续发展</li>
</ul>


<p><strong>共享服务带来的优势</strong></p>

<ul>
<li>提高研发效能，赋予业务快速创新和试错能力</li>
<li>打通数据，真正发挥大数据的威力，共享数据价值</li>
<li>中台组织结构提升组织效能</li>
</ul>


<h2>怎么实现中台战略</h2>

<h3>思路的改变</h3>

<ul>
<li>提升自己的研发效率->提升别人的研发效率</li>
<li>从代码->需求，到代码->组件->需求，到代码->组件->可配置->需求</li>
<li>业务逻辑和平台逻辑分离，业务逻辑和业务逻辑隔离</li>
<li>集中配置，分布式运行</li>
</ul>


<h3>总体架构</h3>

<p><img src="http://www.rowkey.me/post_images/middle-office-arch.png" alt="" /></p>

<h3>建设思路</h3>

<ol>
<li><p>中台化改造</p>

<blockquote><p>对已有平台的中台化改造</p></blockquote>

<ul>
<li>平台不断对于自身治理演进、打破技术边界、逐渐拥抱业务、容纳业务、具备更强的业务属性的过程。</li>
<li>通过业务抽象以及可配置化和白屏化（给平台产品做一个配置界面实现自助式服务，没有UI要求，一般是一个白页面加一些配置项）的改造升级</li>
<li>技术平台->技术中台：对于技术平台的治理、安全、可用性和自助式的产品化包装，打造自助服务平台，关注业务的用户使用体验，让业务可以更快速更方便体验更好的使用企业内部的技术能力</li>
</ul>
</li>
<li><p>中台化：利用平台化的思维和手段梳理、识别、沉淀与复用企业级核心能力的过程。根据业务演进逐渐积累而成，<strong>分阶段逐步实施</strong>。多于一个前台业务需要某一种能力，那么此能力即可沉淀为中台能力。切忌大而全的建设中台。</p>

<ul>
<li><strong>资源集中管理->能力抽象->灵活性</strong></li>
<li><strong>共享服务：普通的服务能力->组件化服务，并提供良好的服务治理支持</strong>

<ul>
<li>找到一个合适的服务化对象：API as service，存量API升级成服务化平台的组件服务</li>
<li>建设对象服务化的基础设施：Product as Service，封装API服务</li>
<li>服务化实施阶段: Solution as Service</li>
<li>增强服务和基础设施实现服务的精细治理</li>
</ul>
</li>
</ul>
</li>
<li><p>运营</p>

<ul>
<li>运营前置：制定迭代计划及接入计划。中台产品推广、前台（用户）接入计划以及接入后的运营支持</li>
<li>根据用户分层制定SLA：不同的需求响应机制、不同的沟通管理机制、不同的服务质量控制机制、不同的问题处理及升级机制</li>
</ul>
</li>
<li><p>演进</p>

<ul>
<li>各种中台的逐渐建设</li>
<li>共享服务中心的不断增加</li>
</ul>
</li>
</ol>


<h3>建设要点</h3>

<ul>
<li>在“工具”与“完全为业务服务”之间寻找平衡点，既需要满足业务的需求，又不能过度参与业务。</li>
<li>重视中台的运营、持续治理以及演进</li>
<li>拆分整体应用形成业务组件：抽象程度越高，中台对业务的适配度越高。</li>
<li>可配置，自助白屏化</li>
<li>足够灵活的扩展点，支持定制化扩展</li>
<li>服务文档化</li>
<li>开放体系：对内对外</li>
</ul>


<h2>参考资料</h2>

<ul>
<li>《中台战略》</li>
<li>《企业IT架构转型之道》</li>
<li>极客时间《说透中台》</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何进行有效的技术分享（演讲）]]></title>
    <link href="http://www.rowkey.me/blog/2019/10/23/how-to-tech-share/"/>
    <updated>2019-10-23T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2019/10/23/how-to-tech-share</id>
    <content type="html"><![CDATA[<p>讲述如何准备一次技术分享（演讲）以及演讲中的注意事项。来自内部分享PPT，后续会发布<strong>详细版</strong>。</p>

<!--more-->


<h2>What-什么是有效的技术分享</h2>

<ul>
<li>演讲

<ul>
<li>知识/技能培训</li>
<li>组件/平台/系统使用培训</li>
<li>工作实践经验/教训</li>
</ul>
</li>
<li>写博客？</li>
</ul>


<p><strong>有效->满足听众的诉求</strong></p>

<h2>Why-存在的问题</h2>

<ul>
<li>语速太快</li>
<li>图解太少</li>
<li>缺乏实践案例</li>
<li>内容太多</li>
<li>内容都在ppt上</li>
</ul>


<h2>How-如何准备技术分享</h2>

<h3>目的</h3>

<ul>
<li>开阔眼界</li>
<li>培训</li>
<li>讨论</li>
</ul>


<p><strong>听众的组成；听众对领域的了解程度；听众的诉求</strong></p>

<h3>结构</h3>

<ul>
<li>Who</li>
<li>What</li>
<li>Why</li>
<li>How：重点选3、4点</li>
<li>Future</li>
<li>Recap</li>
</ul>


<h3>内容</h3>

<ul>
<li><strong>backlog</strong>: 收集、积累信息</li>
<li><strong>逐字稿</strong></li>
<li><strong>形式</strong>：

<ul>
<li>报告：精确的信息和枯燥的细节、事实和图表</li>
<li>故事：具体；强调说服和感染；<strong>赋比兴</strong></li>
<li>演讲：介于报告和故事之间</li>
</ul>
</li>
<li><strong>实践案例</strong>、经验 > 说教

<pre><code>  - Situation: 当时的情况
  - Target: 面临的任务/目标
  - Action: 采取的行动
  - Results: 取得的结果
</code></pre></li>
<li>内容量适可而止</li>
<li><strong>Demo</strong>: 关键特点、容错处理</li>
</ul>


<h3>PPT</h3>

<blockquote><p>烘托效果和提醒，<strong>配角</strong></p></blockquote>

<ul>
<li>How的几个重点，每一个点2-3页，共15-20页</li>
<li>精简文字+图表，多图少字</li>
<li><strong>简洁、干净、一致、跳脱</strong></li>
<li><strong>忌</strong>：交互式幻灯片、大片文字</li>
</ul>


<h3>练习</h3>

<hr />

<blockquote><p>多练出奇迹</p></blockquote>

<ul>
<li>自我练习</li>
<li>让别人听：公司/团队内部试讲</li>
<li>冥想：站在听众的角度去接受信息</li>
</ul>


<p><strong>根据反馈不断进行迭代改进</strong></p>

<h2>分享Tips</h2>

<ul>
<li>紧张

<ul>
<li>觉察：“只要不被听众察觉到紧张，那就不是紧张”。</li>
<li>充分准备</li>
<li>内容量适可而止</li>
<li>简洁PPT：留有自由发挥余地</li>
<li>练习</li>
</ul>
</li>
<li>节奏

<ul>
<li>语速放缓</li>
<li>多准备点内容：演讲时间固定的情况下讲不完比冷场要好</li>
<li>规划要点、时间</li>
</ul>
</li>
<li>目光：面对听众并熟视无睹；巡视听众</li>
<li>语调：有感情；抑扬顿挫</li>
<li>手势：忌手足无措</li>
<li>演讲设备/PPT的备份</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[数据传输之RESTful]]></title>
    <link href="http://www.rowkey.me/blog/2019/09/28/restful/"/>
    <updated>2019-09-28T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2019/09/28/restful</id>
    <content type="html"><![CDATA[<p>REST，全称表现层状态转移（Representational State Transfer）, 指的是资源在网络中以某种表现形式进行状态转移，是一种架构风格。其描述的是在网络中Client和Server的一种交互形式。简单来说就是用HTTP URL来定位资源，用HTTP的各种method来描述操作。其关键的三个概念如下：</p>

<ul>
<li>Resource: 资源，主要指的是数据。</li>
<li>Representational：数据的表现形式，如JSON、XML、HTML等。</li>
<li>State Transfer：状态变化, 通过HTTP method来描述。</li>
</ul>


<p>REST经常被用来规范API的设计以及数据传输的格式，可以统一给各种客户端提供接口,包括Web、iOS、Android和其他的服务。REST不需要显式的前端页面，只需要按照格式返回数据即可。符合REST风格的API称为RESTful API，符合RESTFul规范的架构称为RESTful架构。如下图所示：</p>

<p><img src="http://www.rowkey.me/post_images/restful/restful.png" alt="" /></p>

<!--more-->


<h2>一. 操作</h2>

<p>RESTful是基于HTTP协议的，其主要依赖于HTTP协议的几种method来表示CRUD（create、read、update和delete,即数据的增删查改）操作：</p>

<ul>
<li>GET: 从服务器上获取资源</li>
<li>POST: 创建新的资源</li>
<li>PUT： 更新服务器资源</li>
<li>DELETE： 删除服务器资源</li>
</ul>


<p>这里需要注意两点：</p>

<ul>
<li>GET、PUT和DELETE应该是幂等的，即相同的数据和参数下，执行一次或多次产生的效果是一样的。</li>
<li>对于POST和PUT操作，应该返回最新的资源，删除操作则一般不必要。</li>
<li>所有的操作都是无状态的，即所有的资源，都可以通过URL定位，这个定位与其他资源无关，也不会因为其他资源的变化而改变。</li>
</ul>


<p>除了上述方法之外，还有一个PATCH方法也用于更新资源的部分属性，但并用的并不多，用POST即可。</p>

<p>此外，HTTP 1.1的几个头部也是应该注意的：</p>

<ul>
<li>Accept: 客户端要求服务器返回什么样表现形式的数据。RESTFul API需要根据此头部返回合适的数据。</li>
<li>If-Match: 在对资源做更新和删除操作时，客户端提供If-Match头，值为服务端上次对此资源返回的Etag, 服务端对比Etag如果一致才做更新和删除，否则返回412。</li>
<li>If-None-Match: 和If-Match相反，如果不匹配上次的Etag才返回数据，匹配的话则返回304，多用于Get请求。</li>
<li>If-Modified-Since：值为时间，如果请求的部分在指定时间之后被修改则请求成功，未被修改则返回304，多用于Get请求。</li>
</ul>


<h2>二. 返回码</h2>

<p>HTTP本身已经提供了很多StatusCode来表示各种状态。RESTFul接口需要遵循这些定义，返回合适的状态码和数据。当然，如果是内部使用，统一返回200，在返回数据里自定义一套status code也是可以的。</p>

<p>HTTP的状态码大体分为几个区间：</p>

<ul>
<li>2XX：请求正常处理并返回。</li>
<li>3XX：重定向，请求的资源位置发生变化。</li>
<li>4XX：客户端发送的请求有错误。</li>
<li>5XX：服务器端错误。</li>
</ul>


<p>在自己设计返回码的时候最好也遵循此范围设计，以下是其中几个常用的状态码：</p>

<ul>
<li>200：表示请求成功。</li>
<li>301：资源已经永久移动到新的地址，新的URL会在响应头中返回。</li>
<li>302：资源临时被移动到新的地址，新的URL会在响应头中返回。</li>
<li>304：表明资源未改变。主要配合请求头中的If-None-Match和If-Modified-Since使用。</li>
<li>400：错误请求，表示请求中有语法错误。</li>
<li>401：请求的资源需要认证，请求没有提供认证信息或者认证错误。</li>
<li>403：资源被禁止访问。</li>
<li>404：资源不存在。</li>
<li>502：错误的网关，通常是作为代理的服务器无法收到远程服务器的正确响应。</li>
<li>503：服务不可用。</li>
</ul>


<h2>三. 资源</h2>

<p>资源是RESTful API的核心，其以URI（统一资源标识符）标识，而URL则不仅能够标识一个资源，还能够定位资源。RESTful中使用HTTP URL标识并定位一个资源。原则上只使用名词来指定资源，而且推荐使用复数。以对记事的CRUD API的设计为例：</p>

<ul>
<li>获取所有记事列表：GET /api/notes?page=1&amp;per_page=20</li>
<li>获取某人的所有记事列表：GET /api/users/{uid}/notes</li>
<li>获取标记为星的记事：GET /api/users/{uid}/notes?star=1</li>
<li>创建记事：POST /api/notes</li>
<li>删除某一个记事：DELET /api/notes/{note_id}</li>
<li>更新某一个记事：PUT /api/notes/{note_id}</li>
</ul>


<p>可知：</p>

<ul>
<li>资源分为单个资源和资源集合，尽量使用复数来表示资源，单个资源通过添加ID等标识符来表示。</li>
<li>资源使用嵌套结构，类似于目录路径的方式，可以体现出之间的关系。</li>
<li>一个资源可以有不同的URL，如上可以获取所有的记事列表，也可以获取某人的所有记事列表。</li>
<li>对于GET方法，一定不能设计为可以改变资源的操作。如get /api/deleteNote?id=xx。</li>
<li>URL是对大小写敏感的，尽量使用小写字母，单词间用下划线连接。</li>
<li>使用Query参数来控制返回结果，如上面返回星标记事的接口。此外，像排序方向、排序使用的字段都是可以放在query参数中的。</li>
<li>分页参数使用Query参数（page、per_page）控制，在返回数据中返回当前页、下一页、上一页、总页数等分页相关信息。</li>
</ul>


<p>如果需要区分版本号，可以放在路径中，如/api/v2/**，也可以放在header的Accept字段或者Query参数中:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Accept: version=2.0;...</span></code></pre></td></tr></table></div></figure>


<p>对于一些很难设计为CRUD操作的URL, 如登录、送礼物等，有以下处理方式：</p>

<ul>
<li>使用POST，如POST /api/login。</li>
<li>把动作转换成资源: 登录就是创建了一个Session或者Token，那么就可以设计为 POST /api/sessions。</li>
</ul>


<p>此外，对于数据的提交格式和返回格式，目前以JSON格式为主，其可读性、紧凑性、多语言支持都较好；数据提交的方式也应该使用application/JSON的内容格式并在body里放置JSON数据。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>...
</span><span class='line'>Content-type: application/json
</span><span class='line'>Accept: application/json
</span><span class='line'>...
</span><span class='line'>
</span><span class='line'>{
</span><span class='line'>    'title':'xxx',
</span><span class='line'>    'content':'xxx'
</span><span class='line'>    ...
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<h2>四. 安全性</h2>

<p>HTTP本身是对数据不做任何安全处理的，因此建议首先从根本上使用HTTPS加强数据的安全性。此外，这里的安全性还要保证数据的完整性；保证接口的授权访问，保证接口只提供给授权过的应用访问以及过滤掉不必要的请求；保证数据的授权访问，只允许资源拥有者删除、更新自己的资源。</p>

<h3>数据的完整性</h3>

<p>数据完整性主要是指在对数据进行修改时，要保证要修改的数据和服务器数据是一致的。可以通过Etag这个HTTP中的头部字段来解决。</p>

<p>Etag表示的是资源的唯一版本号, 请求资源时，RESTful api应该把资源数据以及资源的Etag一起返回。api请求方修改资源时应该提交If-Match头，这样服务器通过对比Etag可以防止数据被错误修改，类似于并发中CAS的原理。但是要绝对保证数据的完整性，还得需要配合严格的并发控制才能做到。</p>

<h3>接口访问控制</h3>

<p>接口访问控制可以保证接口的授权访问，拒绝不合法的请求。可以通过以下几种方式：</p>

<ul>
<li>在Request headers中添加特殊的标识符，如果不含有此header的请求直接拒绝。这可以做简单的接口访问控制。</li>
<li>过滤Requst query和body, 做白名单验证，即只允许出现哪些参数，如果有非法参数，可以抛弃或者直接拒绝请求。</li>
</ul>


<p>上面只是比较简单的接口访问控制策略，无法彻底拒绝未授权的请求。我们可以通过为每一个授权应用分配app_secret（私有的，不公开），访问时对请求进行签名验证的方式实现更为严格的接口访问控制，这种方法也叫做HMAC。请求签名生成的一个例子如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>app_sign = MD5(METHOD & PATH & timestamp & app_secret)</span></code></pre></td></tr></table></div></figure>


<p>其中，METHOD指的是此次请求的方法，PATH指的URL中的path部分，timestamp是请求时间戳，app_secret是分配请求方的私钥，此外还有一个分配给请求方的app_id。这样，app_id、timestamp、app_sign随着请求一起发送（可以作为query参数也可以作为header），服务器接收到请求后使用同样的算法计算出app_sign进行对比，如果相同则正常请求，否则返回401 Unauthorized。由此既可以保证接口的授权访问，还能够基于时间戳防止重放攻击。当然，app_sign的生成算法可以加入更多的因子，如request_body、query等。但需要注意的是这个算法越复杂，对接口的性能影响就越大，需要做权衡。</p>

<h3>数据的授权访问-OAuth</h3>

<p>数据的授权访问其实也是接口访问控制的一部分。主要关注点在于对资源的操作权限做控制。基于HTTP做授权访问的核心就是验证一个请求是否是合法用户发起的，主要的有HTTP Basic Auth、OAuth。其中Basic Auth会把用户的用户名和密码直接暴露在网络中并不安全，因此RESTful api主要使用OAuth做数据的授权访问控制。</p>

<p>OAuth2.0的验证流程如下图所示：</p>

<p><img src="http://www.rowkey.me/post_images/restful/oauth.png" alt="" /></p>

<ul>
<li>得到授权码code。</li>
<li>使用授权码换取access_token和refesh_token，通常refresh_token比access_token有效期长。</li>
<li>使用access_token获取用户openid。</li>
<li>使用access_token和用户openid调用用户授权接口。</li>
<li>使用refresh_token获取新的access_token。</li>
</ul>


<p>当然，如果是提供给内部应用的API，可以做适当简化，比如用户登录直接返回access_token，凭借此access_token调用授权接口即可。</p>

<h2>五. 限流</h2>

<p>RESTful api应该有限流机制，否则会造成API被滥用甚至被DDOS攻击。可以根据不同的授权访问做不同的限流，以减少服务器压力。</p>

<p>限流的情况可以通过下面几个头部字段返回给请求方：</p>

<ul>
<li>X-RateLimit-Limit: 用户每个小时允许发送请求的最大值。</li>
<li>X-RateLimit-Remaining：当前时间窗口剩下的可用请求数目。</li>
<li>X-RateLimit-Rest: 时间窗口重置的时候，到这个时间点可用的请求数量就会变成 X-RateLimit-Limit 的值。</li>
</ul>


<p>对于未登录的用户根据IP或者设备ID来限流，对于登录用户根据用户标识。对于超过流量的请求，返回403 forbiden或者429 Too many requests都可以。</p>

<h2>六. 超文本API</h2>

<p>RESTful还有一个非常关键的特性就是超文本API（Hypermedia API），指的是服务器需要在每一个API接口的返回结果中都要提供与下一步操作相关的资源链接, 客户端借助这些实现表现层状态转移。这种设计也被称为 HATEOAS（Hypermedia as the Engine of Application State）。</p>

<p>除此之外，这样做还能够让客户端和服务端解耦，客户端只需要依次遍历返回结果中的超链接就能完成一系列业务逻辑；当服务端做了业务逻辑改动后，也只需要修改服务器返回的资源链接即可。</p>

<h2>七. 编写文档</h2>

<p>RESTful API一般是对接第三方的，因此，文档说明是非常必要的。因此对每一个接口都详细的说明参数含义、数据返回格式和字段意义并举出实际的例子都是非常关键的。</p>

<p>Java Web开发中，我们可以使用Swagger UI + Spring Fox来基于注释生成RESTful API文档。</p>

<h2>八. RESTful API实现</h2>

<p>Spring MVC、Jersey、Play Framework等主流的Web开发框架都支持RESTful的接口编写。这里我们以Spring MVC为例。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>@RequestMapping(value = "/api/notes/{noteId}", method = RequestMethod.GET, headers = "Accept=application/json")
</span><span class='line'>@ResponseBody
</span><span class='line'>public UserNote getUserNoteInfo(@PathVariable long noteId) {
</span><span class='line'>
</span><span class='line'>   return ...;
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>此外，OAuth的实现可以使用Spring Security OAuth, 其基于Spring Secutiry实现了OAuth服务。不过，Spring Security OAuth使用稍显复杂，完全可按照OAuth2.0的流程使用Spring MVC + Redis进行实现。</p>

<blockquote><p>本文节选自《Java工程师修炼之道》一书。</p></blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何培养解决问题的意识]]></title>
    <link href="http://www.rowkey.me/blog/2019/08/23/solve-problem/"/>
    <updated>2019-08-23T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2019/08/23/solve-problem</id>
    <content type="html"><![CDATA[<p>解决问题其实并不是最终的目的，需要加一个修饰词成为有效地解决问题，这才是最终的目的。那么如何有效地解决问题呢？这是有一些方法论做指导的。要培养解决问题的能力，需要首先掌握这些方法论。解决问题分为三步走：识别问题、分析问题、解决问题。</p>

<!--more-->


<ul>
<li>所谓识别问题，这一点尤其重要，因为很多时候提需求的人提的只是方案而非真正的问题，这时候如果不加思索就开始去做，最后反而达不到需求方的期望，举一个可能很多人听过的段子，程序员的妻子跟程序员说：把这些土豆削一半儿放到锅里，程序员很快就做完了，结果妻子发现所有土豆都下了锅，不过每一个土豆都被削掉了一半。哈哈一笑的同时，很多人觉得这是沟通的问题，其实从另一个角度来看，还是因为没有识别出真正的问题是什么。平时的工作中，也会有很多人在遇到问题和接到需求时，为了赶时间，想都不想就开始做，结果最终的结果解决不了问题或者满足不了需求方，这都是因为没有真正的识别问题而造成的。脑子总是比手慢也说的是这个意思。在识别问题的时候则可以通过5W2H提问来理解真正的问题，What，问题时什么；Why，为什么会发生问题；Who，谁造成的问题；When，何时发生的问题； Where，哪里的问题；How，问题时怎样发生的；How much，问题发生的频率，影响程度如何。</li>
<li>分析问题，需要依靠专业能力或者经验来找到所有可能的原因，然后可以通过冰山分析法、鱼骨法来分析问题的根本原因，这一点也特别重要，很多时候如果识别不出根本原因，那么只会是治标不治本，当然对于一些紧急事故，解决事故是紧急首要的，后续的问题管理则需要找出问题的根本原因，以防止后续问题的重复发生。</li>
<li>解决问题，需要根据分析出来的问题原因，给出解决方案，这个也需要专业能力和经验的支撑，如果有多个方案则可以使用理性决策的比较矩阵和决策矩阵支撑最终的方案的选择。</li>
</ul>


<p>以上是解决问题的三步走。支撑这个方法论的除了上面提到过的专业能力和经验支撑，我觉得还需要具有owner意识，即把问题当做自己的问题，主动积极的去寻求能更好解决问题的方案。</p>

<p>掌握了这些方法论后，则需要不断的模仿学习、实践，并且最重要的是多总结，要把平时工作中自己实践的、看到别人实践的不断的总结梳理，形成自己的知识体系，这样才能真正成为自己的技能，才能在遇到问题时做到有条不紊，从容应对，同时也能进一步完善自己解决问题的方法论、专业能力和经验，形成良性闭环。例如在很多公司都会有故障解决的一套指导流程，比如在碰到服务器响应变慢时，先通知受影响方，然后组织相关人员，如果有经验则第一时间修复，无经验则需要从最近的变动着手，先排查哪几方面问题，再排查哪几方面问题，这个流程即在实践过程中不断沉淀下来的知识体系。</p>

<p>总结来说，就是掌握解决问题的方法论，带着Owner意识多去实践解决问题，多去模范学习别人如何解决问题，多去总结沉淀成自己的知识体系和方法论形成闭环。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用Spring Boot快速开发]]></title>
    <link href="http://www.rowkey.me/blog/2019/07/27/springboot/"/>
    <updated>2019-07-27T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2019/07/27/springboot</id>
    <content type="html"><![CDATA[<p>Java开发中常用的Spring现在变得越来越复杂，越来越不好上手。这一点Spring Source自己也注意到了，因此推出了Spring Boot，旨在简化使用Spring的门槛，大大降低Spring的配置工作，并且能够很容易地将应用打包为可独立运行的程序（即不依赖于第三方容器，可以独立以jar或者war包的形式运行）。其带来的开发效率的提升使得Spring Boot被看做至少近5年来Spring乃至整个Java社区最有影响力的项目之一，也被人看作是Java EE开发的颠覆者。另一方面来说，Spring Boot也顺应了现在微服务（MicroServices）的理念，可以用来构建基于Spring框架的可独立部署应用程序。</p>

<!--more-->


<h2>一. 使用</h2>

<p>一个简单的pom配置示例如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;parent&gt;        
</span><span class='line'>   &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        
</span><span class='line'>   &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;        
</span><span class='line'>   &lt;version&gt;1.4.7.RELEASE&lt;/version&gt;
</span><span class='line'>&lt;/parent&gt;
</span><span class='line'>    
</span><span class='line'>...
</span><span class='line'>    
</span><span class='line'>&lt;dependencies&gt;        
</span><span class='line'>   &lt;dependency&gt;                
</span><span class='line'>       &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                
</span><span class='line'>       &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;        
</span><span class='line'>   &lt;/dependency&gt;
</span><span class='line'>&lt;/dependencies&gt;
</span><span class='line'>
</span><span class='line'>&lt;build&gt;
</span><span class='line'>    &lt;plugins&gt;
</span><span class='line'>       &lt;plugin&gt;
</span><span class='line'>           &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
</span><span class='line'>           &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
</span><span class='line'>           &lt;configuration&gt;
</span><span class='line'>               &lt;executable&gt;true&lt;/executable&gt;
</span><span class='line'>            &lt;/configuration&gt;
</span><span class='line'>       &lt;/plugin&gt;
</span><span class='line'>    &lt;/plugins&gt;
</span><span class='line'>&lt;/build&gt;</span></code></pre></td></tr></table></div></figure>


<p>使用spring-boot-starter-parent作为当前项目的parent将Spring Boot应用相关的一系列依赖（dependency）、插件（plugins）等等配置共享；添加spring-boot-starter-web这个依赖，是为了构建一个独立运行的Web应用；spring-boot-maven-plugin用于将Spring Boot应用以可执行jar包的形式发布出去。</p>

<p>接着可以添加相应的Controller实现：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>@RestController  
</span><span class='line'>public class MyController {
</span><span class='line'>@RequestMapping("/")
</span><span class='line'>   public String hello() {
</span><span class='line'>      return "Hello World!";
</span><span class='line'>   }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>这里的RestController是一个复合注解，包括@Controller和@ResponseBody。</p>

<p>最后，要让Spring Boot可以独立运行和部署，我们需要一个Main方法入口， 比如：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>@SpringBootApplication
</span><span class='line'>public class BootDemo extends SpringBootServletInitializer{    
</span><span class='line'>   public static void main(String[] args) throws Exception {        
</span><span class='line'>       SpringApplication.run(BootDemo.class, args);    
</span><span class='line'>   }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>使用mvn package打包后（可以是jar，也可以是war），java -jar xx.war/jar即可运行一个Web项目，而之所以继承SpringBootServletInitializer是为了能够让打出来的war包也可以放入容器中直接运行，其加载原理在3.4.4节的零XML配置中讲过。</p>

<p>这里需要注意上面spring-boot-maven-plugin这个插件将executable配置为了true，此种配置打出来的jar/war包其压缩格式并非传统的jar/war包，实际上是一个bash文件，可以作为shell脚本直接执行，解压的话需要使用unzip命令。</p>

<p>从最根本上来讲，Spring Boot就是一些库和插件的集合，屏蔽掉了很多配置加载、打包等自动化工作，其底层还是基于Spring的各个组件。</p>

<p>这里需要注意的是，Spring Boot推崇对项目进行零xml配置。但是就笔者看来，相比起注解配置是糅杂在代码中，每次更新都需要重新编译，XML这种和代码分离的方式耦合性和可维护性则显得更为合理一些，而且在配置复杂时也更清晰。因此，采用Java Config作为应用和组件扫描（component scan）入口，采用XML做其他的配置是一种比较好的方式。此外，当集成外部已有系统的时候， 通过XML集中明确化配置也是更为合理的一种方式。</p>

<h2>二. 原理浅析</h2>

<p><img src="http://www.rowkey.me/post_images/spring-boot-process.png" alt="" /></p>

<p>Spring Boot的基础组件之一就是4.1讲过的一些注解配置，除此之外，它也提供了自己的注释。其总体的运行流程如上图所示。</p>

<ol>
<li><p>@EnableAutoConfiguration</p>

<p> 这个Annotation就是Java Config的典型代表，标注了这个Annotation的Java类会以Java代码的形式（对应于XML定义的形式）提供一系列的Bean定义和实例，结合AnnotationConfigApplicationContext和自动扫描的功能，就可以构建一个基于Spring容器的Java应用了。</p>

<p> @EnableAutoConfiguration的定义信息如下 ：</p>

<pre><code class="`"> @Target(ElementType.TYPE)
 @Retention(RetentionPolicy.RUNTIME)
 @Documented
 @Inherited
 @AutoConfigurationPackage
 @Import(EnableAutoConfigurationImportSelector.class)
 public @interface EnableAutoConfiguration {
</code></pre>

<p> 标注了此注解的类会发生一系列初始化动作：</p>

<ul>
<li><p>SpringBoot扫描到@EnableAutoConfiguration注解时，就使用Spring框架的SpringFactoriesLoader去扫描classpath下所有META-INF/spring.factories文件的配置信息（META-INF/spring.providers声明了当前Starter依赖的Jar包）。其中包括一些callback接口（在前中后等不同时机执行）：</p>

<ul>
<li>org.springframework.boot.SpringApplicationRunListener</li>
<li>org.springframework.context.ApplicationContextInitializer</li>
<li>org.springframework.context.ApplicationListener</li>
</ul>
</li>
<li><p>然后Spring Boot加载符合当前场景需要的配置类型并供当前或者下一步的流程使用，这里说的场景就是提取以 org.springframework.boot.autoconfigure.EnableAutoConfiguration作为key标志的一系列Java配置类，然后将这些Java配置类中的Bean定义加载到Spring容器中。</p></li>
</ul>


<p> 此外，我们可以使用Spring3系列引入的@Conditional，通过像@ConditionalOnClass、@ConditionalOnMissingBean等具体的类型和条件来进一步筛选通过SpringFactoriesLoader加载的类。</p></li>
<li><p>Spring Boot启动</p>

<p> 每一个Spring Boot应用都有一个入口类，在其中定义main方法，然后使用SpringApplication这个类来加载指定配置并运行SpringBoot Application。如上面写过的入口类：</p>

<pre><code class="`   "> @SpringBootApplication
 public class BootDemo extends SpringBootServletInitializer{    
    public static void main(String[] args) throws Exception {        
        SpringApplication.run(BootDemo.class, args);    
    }
 }
</code></pre>

<p> @SpringBootApplication注解是一个复合注解，包括了@Configuraiton、@EnableAutoConfiguration以及@ComponentScan。通过SpringApplication的run方法，Spring就使用BootDemo作为Java配置类来读取相关配置、加载和扫描相关的bean。</p>

<p> 这样，基于@SpringBootApplication注解，Spring容器会自动完成指定语义的一系列工作，包括@EnableAutoConfiguration要求的东西，如：从SpringBoot提供的多个starter模块中加载Java Config配置（META-INF/spring.factories中声明的xxAutoConfiguration），然后将这些Java Config配置筛选上来的Bean定义加入Spring容器中，再refresh容器。一个Spring Boot应用即启动完成。</p></li>
</ol>


<h2>三. 模块组成</h2>

<p>Spring Boot是由非常多的模块组成的，可以通过pom文件引入进来。EnableAutoConfiguration机制会进行插件化加载进行自动配置，这里模块化机制的原理主要是通过判断相应的类/文件是否存在来实现的。其中几个主要的模块如下:</p>

<ol>
<li><p>spring-boot-starter-web</p>

<p> 此模块就是标记此项目是一个Web应用，Spring Boot会自动准备好相关的依赖和配置。</p>

<p> 这里Spring Boot默认使用Tomcat作为嵌入式Web容器，可以通过声明spring-boot-starter-jetty的dependency来换成Jetty。</p></li>
<li><p>spring-boot-starter-logging</p>

<p> Spring Boot对此项目开启SLF4J和Logback日志支持。</p></li>
<li><p>spring-boot-starter-redis</p>

<p>  Spring Boot对此项目开启Redis相关依赖和配置来做数据存储。</p></li>
<li><p>spring-boot-starter-jdbc</p>

<p>  Spring Boot对此项目开启JDBC操作相关依赖和配置来做数据存储。</p>

<p>  这里需要说明的是，Spring Boot提供的功能非常丰富，因此显得非常笨重复杂。其实依赖于模块插件化机制，我们可以只配置自己需要使用的功能，从而对应用进行瘦身，避免无用的配置影响应用启动速度。</p></li>
</ol>


<h2>四. 总结</h2>

<p>Spring Boot给大家使用Spring做后端应用开发带来了非常大的便利，能够大大提高搭建应用雏形框架的速度，只需要关注实现业务逻辑即可。其“黑魔法”一样的插件化机制使得能够根据自己的需要引入所需的组件，提供了非常好的灵活性。如果非遗留Spring项目，直接使用Spring Boot是比较好的选择；遗留项目也可以通过配置达到无缝结合。</p>

<blockquote><p>本文节选自《Java工程师修炼之道》一书。</p></blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Java开发框架之日志]]></title>
    <link href="http://www.rowkey.me/blog/2019/06/29/log/"/>
    <updated>2019-06-29T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2019/06/29/log</id>
    <content type="html"><![CDATA[<p>日志在应用开发中是一个非常关键的部分。有经验的工程师能够凭借以往的经验判断出哪里该打印日志、该以何种级别打印日志。这样就能够在线上发生问题的时候快速定位并解决问题，极大的减少应用的运维成本。</p>

<!--more-->


<p>使用控制台输出其实也算日志的一种，在容器中会打印到容器的日志文件中。但是，控制台输出过于简单，缺乏日志中级别控制、异步、缓冲等特性，因此在开发中要杜绝使用控制台输出作为日志（System.out.println）。而Java中已经有很多成熟的日志框架供大家使用：</p>

<ul>
<li>JDK Logging</li>
<li>Apache Log4j</li>
<li>Apache Log4j2</li>
<li>Logback</li>
</ul>


<p>此外，还有两个用于实现日志统一的框架：Apache Commons-Logging、SLF4j。与上述框架的不同之处在于，其只是一个门面，并没有日志框架的具体实现,可以认为是日志接口框架。</p>

<p>对于这些日志框架来说，一般会解决日志中的以下问题：</p>

<ul>
<li>日志的级别: 定义日志级别来区分不同级别日志的输出路径、形式等，帮助我们适应从开发调试到部署上线等不同阶段对日志输出粒度的不同需求。</li>
<li>日志的输出目的地：包括控制台、文件、GUI组件，甚至是套接口服务器、UNIX Syslog守护进程等。</li>
<li>日志的输出格式：日志的输出格式（JSON、XML）。</li>
<li>日志的输出优化：缓存、异步等。</li>
</ul>


<p>这里需要说的是，目前有几个框架提供了占位符的日志输出方式，然而其最终是用indexOf去循环查找再对信息进行拼接的，会消耗CPU。建议使用正确估算大小的StringBuilder拼装输出信息，除非是实在无法确定日志是否输出才用占位符。</p>

<h2>一. JDK Logging</h2>

<p>JDK Logging就是JDK自带的日志操作类，在java.util.logging包下面，通常被简称为JUL。</p>

<h3>配置</h3>

<p>JDK Logging配置文件默认位于$JAVA_HOME/jre/lib/logging.properties中，可以使用系统属性java.util.logging.config.file指定相应的配置文件对默认的配置文件进行覆盖。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>handlers= java.util.logging.FileHandler,java.util.logging.ConsoleHandler
</span><span class='line'>.handlers = java.util.logging.FileHandler,java.util.logging.ConsoleHandler #rootLogger使用的Handler
</span><span class='line'>.level= INFO #rootLogger的日志级别
</span><span class='line'>
</span><span class='line'>##以下是FileHandler的配置
</span><span class='line'>java.util.logging.FileHandler.pattern = %h/java%u.log
</span><span class='line'>java.util.logging.FileHandler.limit = 50000
</span><span class='line'>java.util.logging.FileHandler.count = 1
</span><span class='line'>java.util.logging.FileHandler.formatter =java.util.logging.XMLFormatter #配置相应的日志Formatter。
</span><span class='line'>
</span><span class='line'>##以下是ConsoleHandler的配置
</span><span class='line'>java.util.logging.ConsoleHandler.level = INFO
</span><span class='line'>java.util.logging.ConsoleHandler.formatter =java.util.logging.SimpleFormatter #配置相应的日志Formatter。
</span><span class='line'>
</span><span class='line'>#针对具体的某个logger的日志级别配置
</span><span class='line'>me.rowkey.pje.log.level = SEVERE
</span><span class='line'>
</span><span class='line'>#设置此logger不会继承成上一级logger的配置
</span><span class='line'>me.rokey.pje.log.logger.useParentHandlers = false </span></code></pre></td></tr></table></div></figure>


<p>这里需要说明的是logger默认是继承的，如me.rowkey.pje.log的logger会继承me.rowkey.pje的logger配置，可以对logger配置handler和useParentHandlers（默认是为true）属性, 其中useParentHandler表示是否继承父logger的配置。</p>

<p>JDK Logging的日志级别比较多，从高到低为：OFF(2<sup>31</sup>-1)—>SEVERE(1000)—>WARNING(900)—>INFO(800)—>CONFIG(700)—>FINE(500)—>FINER(400)—>FINEST(300)—>ALL(-2<sup>31</sup>)。</p>

<h3>使用</h3>

<p>JDK Logging的使用非常简单：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>public class LoggerTest{
</span><span class='line'>
</span><span class='line'>    private static final Logger LOGGER = Logger.getLogger(xx.class.getName());
</span><span class='line'>    
</span><span class='line'>    public static void main(String[] args){
</span><span class='line'>        LOGGER.info("logger info");
</span><span class='line'>    }
</span><span class='line'>}
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<h3>性能优化</h3>

<p>JDK Logging是一个比较简单的日志框架，并没有提供异步、缓冲等优化手段。也不建议大家使用此框架。</p>

<h2>二. Log4j</h2>

<p>Log4j应该是目前Java开发中用的最为广泛的日志框架。</p>

<h3>配置</h3>

<p>Log4j支持XML、Proerties配置，通常还是使用Properties：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>root_log_dir=${catalina.base}/logs/app/
</span><span class='line'>
</span><span class='line'># 设置rootLogger的日志级别以及appender
</span><span class='line'>log4j.rootLogger=INFO,default
</span><span class='line'>
</span><span class='line'># 设置Spring Web的日志级别
</span><span class='line'>log4j.logger.org.springframework.web = ERROR
</span><span class='line'>
</span><span class='line'># 设置default appender为控制台输出
</span><span class='line'>log4j.appender.default=org.apache.log4j.ConsoleAppender
</span><span class='line'>log4j.appender.default.layout=org.apache.log4j.PatternLayout
</span><span class='line'>log4j.appender.default.layout.ConversionPattern=[%-d{HH\:mm\:ss} %-3r %-5p %l] &gt;&gt; %m (%t)%n
</span><span class='line'>
</span><span class='line'># 设置新的logger，在程序中使用Logger.get("myLogger")即可使用
</span><span class='line'>log4j.logger.myLogger=INFO,A2
</span><span class='line'>
</span><span class='line'># 设置另一个appender为按照日期轮转的文件输出
</span><span class='line'>log4j.appender.A2=org.apache.log4j.DailyRollingFileAppender
</span><span class='line'>log4j.appender.A2.File=${root_log_dir}log.txt
</span><span class='line'>log4j.appender.A2.Append=true
</span><span class='line'>log4j.appender.A2.DatePattern= yyyyMMdd'.txt'
</span><span class='line'>log4j.appender.A2.layout=org.apache.log4j.PatternLayout
</span><span class='line'>log4j.appender.A2.layout.ConversionPattern=[%-d{HH\:mm\:ss} %-3r %-5p %l] &gt;&gt; %m (%t)%n
</span><span class='line'>
</span><span class='line'>log4j.logger.myLogger1 = INFO,A3
</span><span class='line'>
</span><span class='line'># 设置另一个appender为RollingFileAppender，能够限制日志文件个数
</span><span class='line'>log4j.appender.A3 = org.apache.log4j.RollingFileAppender
</span><span class='line'>log4j.appender.A3.Append = true
</span><span class='line'>log4j.appender.A3.BufferedIO = false
</span><span class='line'>log4j.appender.dA3.File = /home/popo/tomcat-yixin-pa/logs/pa.log
</span><span class='line'>log4j.appender.A3.Encoding = UTF-8
</span><span class='line'>log4j.appender.A3.layout = org.apache.log4j.PatternLayout
</span><span class='line'>log4j.appender.A3.layout.ConversionPattern = [%-5p]%d{ISO8601}, [Class]%-c{1}, %m%n
</span><span class='line'>log4j.appender.A3.MaxBackupIndex = 3 #最大文件个数
</span><span class='line'>log4j.appender.A3.MaxFileSize = 1024MB</span></code></pre></td></tr></table></div></figure>


<p>如果Log4j文件不直接在classpath下的话，可以使用PropertyConfigurator来进行配置：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>PropertyConfigurator.configure("...");
</span></code></pre></td></tr></table></div></figure>


<p>Log4j的日志级别相对于JDK Logging来说，简化了一些：DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL。</p>

<p>这里的logger默认是会继承父Logger的配置（rootLogger是所有logger的父logger），如上面myLogger的输出会同时在控制台和文件中出现。如果不想这样，那么只需要如下设置:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>log4j.additivity.myLogger=false</span></code></pre></td></tr></table></div></figure>


<h3>使用</h3>

<p>程序中对于Log4j的使用也非常简单：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>import org.apache.log4j.Logger;
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>private static final Logger LOGGER = Logger.getLogger(xx.class.getName());
</span><span class='line'>...
</span><span class='line'>LOGGER.info("logger info");
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p>这里需要注意的是，虽然Log4j可以根据配置文件中日志级别的不同做不同的输出，但由于字符串创建或者拼接也是耗资源的，因此，下面的用法是不合理的。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>LOGGER.debug("...");</span></code></pre></td></tr></table></div></figure>


<p>合理的做法应该是首先判断当前的日志级别是什么，再去做相应的输出，如：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>if(LOGGER.isDebugEnabled()){
</span><span class='line'>    LOGGER.debug("...");
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>当然，如果是必须输出的日志可以不做此判断，比如catch异常打印错误日志的地方。</p>

<h3>性能优化</h3>

<p>Log4j为了应对某一时间里大量的日志信息进入Appender的问题提供了缓冲来进一步优化性能：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>log4j.appender.A3.BufferedIO=true   
</span><span class='line'>#Buffer单位为字节，默认是8K，IO BLOCK大小默认也是8K 
</span><span class='line'>log4j.appender.A3.BufferSize=8192 </span></code></pre></td></tr></table></div></figure>


<p>以上表示当日志内容达到8k时，才会将日志输出到日志输出目的地。</p>

<p>除了缓冲以外，Log4j还提供了AsyncAppender来做异步日志。但是AsyncAppender只能够通过xml配置使用：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;appender name="A2"
</span><span class='line'>   class="org.apache.log4j.DailyRollingFileAppender"&gt;
</span><span class='line'>   &lt;layout class="org.apache.log4j.PatternLayout"&gt;
</span><span class='line'>       &lt;param name="ConversionPattern" value="%m%n" /&gt;
</span><span class='line'>   &lt;/layout&gt;
</span><span class='line'>   &lt;param name="DatePattern" value="'.'yyyy-MM-dd-HH" /&gt;        
</span><span class='line'>   &lt;param name="File" value="app.log" /&gt;
</span><span class='line'>   &lt;param name="BufferedIO" value="true" /&gt;
</span><span class='line'>   &lt;!-- 8K为一个写单元 --&gt;
</span><span class='line'>   &lt;param name="BufferSize" value="8192" /&gt;
</span><span class='line'>&lt;/appender&gt;
</span><span class='line'>
</span><span class='line'>&lt;appender name="async" class="org.apache.log4j.AsyncAppender"&gt;
</span><span class='line'>   &lt;appender-ref ref="A2"/&gt;
</span><span class='line'>&lt;/appender&gt;</span></code></pre></td></tr></table></div></figure>


<h2>三. Log4j2</h2>

<p>2015年8月，官方正式宣布Log4j 1.x系列生命终结，推荐大家升级到Log4j2，并号称在修正了Logback固有的架构问题的同时，改进了许多Logback所具有的功能。Log4j2与Log4j1发生了很大的变化，并不兼容。并且Log4j2不仅仅提供了日志的实现，也提供了门面，目的是统一日志框架。其主要包含两部分：</p>

<ul>
<li>log4j-api： 作为日志接口层，用于统一底层日志系统</li>
<li>log4j-core : 作为上述日志接口的实现，是一个实际的日志框架</li>
</ul>


<h3>配置</h3>

<p>Log4j2的配置方式只支持XML、JSON以及YAML，不再支持Properties文件,其配置文件的加载顺序如下：</p>

<ul>
<li>log4j2-test.json/log4j2-test.jsn</li>
<li>log4j2-test.xml</li>
<li>log4j2.json/log4j2.jsn文件</li>
<li>log4j2.xml</li>
</ul>


<p>如果想要自定义配置文件位置，需要设置系统属性log4j.configurationFile。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>System.setProperty("log4j.configurationFile", "...");
</span><span class='line'>或者
</span><span class='line'>-Dlog4j.configurationFile="xx"</span></code></pre></td></tr></table></div></figure>


<p>配置文件示例：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;!--log4j2.xml--&gt;
</span><span class='line'>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
</span><span class='line'>&lt;Configuration status="WARN" monitorInterval="30"&gt;
</span><span class='line'>&lt;Appenders&gt;
</span><span class='line'>  &lt;Console name="Console" target="SYSTEM_OUT"&gt;
</span><span class='line'>    &lt;PatternLayout pattern="%d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n"/&gt;
</span><span class='line'>  &lt;/Console&gt;
</span><span class='line'>  &lt;File name="File" fileName="app.log" bufferedIO="true" immediateFlush="true"&gt;
</span><span class='line'>    &lt;PatternLayout&gt;
</span><span class='line'>      &lt;pattern&gt;%d %p %C{1.} [%t] %m%n&lt;/pattern&gt;
</span><span class='line'>    &lt;/PatternLayout&gt;
</span><span class='line'>  &lt;/File&gt;
</span><span class='line'>  &lt;RollingFile name="RollingFile" fileName="logs/app.log"
</span><span class='line'>                     filePattern="log/$${date:yyyy-MM}/app-%d{MM-dd-yyyy}-%i.log.gz"&gt;
</span><span class='line'>      &lt;PatternLayout pattern="%d{yyyy-MM-dd 'at' HH:mm:ss z} %-5level %class{36} %L %M - %msg%xEx%n"/&gt;
</span><span class='line'>      &lt;SizeBasedTriggeringPolicy size="50MB"/&gt;
</span><span class='line'>      &lt;!-- DefaultRolloverStrategy属性如不设置，则默认为最多同一文件夹下7个文件，这里设置了20 --&gt;
</span><span class='line'>      &lt;DefaultRolloverStrategy max="20"/&gt;
</span><span class='line'>  &lt;/RollingFile&gt;
</span><span class='line'>&lt;/Appenders&gt;
</span><span class='line'>&lt;Loggers&gt;
</span><span class='line'>  &lt;logger name="myLogger" level="error" additivity="false"&gt;
</span><span class='line'>    &lt;AppenderRef ref="File" /&gt;
</span><span class='line'>  &lt;/logger&gt;
</span><span class='line'>  &lt;Root level="debug"&gt;
</span><span class='line'>    &lt;AppenderRef ref="Console"/&gt;
</span><span class='line'>  &lt;/Root&gt;
</span><span class='line'>&lt;/Loggers&gt;
</span><span class='line'>&lt;/Configuration&gt;</span></code></pre></td></tr></table></div></figure>


<p>上面的monitorInterval使得配置变动能够被实时监测并更新，且能够在配置发生改变时不会丢失任何日志事件;additivity和Log4j一样也是为了让Looger不继承父Logger的配置；Configuration中的status用于设置Log4j2自身内部的信息输出，当设置成trace时，你会看到Log4j2内部各种详细输出。</p>

<p>Log4j2在日志级别方面也有了一些改动：TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL, 并且能够很简单的自定义自己的日志级别。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;CustomLevels&gt;
</span><span class='line'>    &lt;CustomLevel name="NOTICE" intLevel="450" /&gt;
</span><span class='line'>    &lt;CustomLevel name="VERBOSE" intLevel="550" /&gt;
</span><span class='line'>&lt;/CustomLevels&gt;</span></code></pre></td></tr></table></div></figure>


<p>上面的intLevel值是为了与默认提供的标准级别进行对照的。</p>

<h3>使用</h3>

<p>使用方式也很简单：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>private static final Logger LOGGER = LogManager.getLogger(xx.class);
</span><span class='line'>
</span><span class='line'>LOGGER.debug("log4j debug message");</span></code></pre></td></tr></table></div></figure>


<p>这里需要注意的是其中的Logger是log4j-api中定义的接口，而Log4j1中的Logger则是类。</p>

<p>相比起之前我们需要先判断日志级别，再输出日志，Log4j2提供了占位符功能：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>LOGGER.debug("error: {} ", e.getMessage());</span></code></pre></td></tr></table></div></figure>


<h3>性能优化</h3>

<p>在性能方面，Log4j2引入了基于LMAX的Disruptor的无锁异步日志实现进一步提升异步日志的性能：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;AsyncLogger name="asyncTestLogger" level="trace" includeLocation="true"&gt;
</span><span class='line'>    &lt;AppenderRef ref="Console"/&gt;
</span><span class='line'>&lt;/AsyncLogger&gt;</span></code></pre></td></tr></table></div></figure>


<p>需要注意的是，由于默认日志位置信息并没有被传给异步Logger的I/O线程，因此这里的includeLocation必须要设置为true。</p>

<p>和Log4j一样，Log4j2也提供了缓冲配置来优化日志输出性能。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;Appenders&gt;
</span><span class='line'>  &lt;File name="File" fileName="app.log" bufferedIO="true" immediateFlush="true"&gt;
</span><span class='line'>    &lt;PatternLayout&gt;
</span><span class='line'>      &lt;pattern&gt;%d %p %C{1.} [%t] %m%n&lt;/pattern&gt;
</span><span class='line'>    &lt;/PatternLayout&gt;
</span><span class='line'>  &lt;/File&gt;
</span><span class='line'>&lt;/Appenders&gt;</span></code></pre></td></tr></table></div></figure>


<h2>四. Logback</h2>

<p>Logback是由Log4j创始人设计的又一个开源日志组件，相对Log4j而言，在各个方面都有了很大改进。</p>

<p>Logback当前分成三个模块：</p>

<ul>
<li>logback-core是其它两个模块的基础模块。</li>
<li>logback-classic是Log4j的一个改良版本。logback-classic完整实现SLF4J API使你可以很方便地更换成其它日志系统如Log4j或JDK Logging。</li>
<li>logback-access访问模块与Servlet容器集成提供通过HTTP来访问日志的功能。</li>
</ul>


<h3>配置</h3>

<p>Logback的配置文件如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;!--logback.xml--&gt;
</span><span class='line'>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
</span><span class='line'>&lt;configuration&gt;
</span><span class='line'>
</span><span class='line'>    &lt;property name="root_log_dir" value="${catalina.base}/logs/app/"/&gt;
</span><span class='line'>
</span><span class='line'>    &lt;appender name="ROLLING_FILE_APPENDER" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt;
</span><span class='line'>       &lt;File&gt;${root_log_dir}app.log&lt;/File&gt;
</span><span class='line'>       &lt;Append&gt;true&lt;/Append&gt;
</span><span class='line'>       &lt;encoder&gt;
</span><span class='line'>           &lt;pattern&gt;%date [%level] [%thread] %logger{80} [%file : %line] %msg%n&lt;/pattern&gt;
</span><span class='line'>       &lt;/encoder&gt;
</span><span class='line'>       &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt;
</span><span class='line'>           &lt;fileNamePattern&gt;${root_log_dir}app.log.%d{yyyy-MM-dd}.%i&lt;/fileNamePattern&gt;
</span><span class='line'>           &lt;maxHistory&gt;30&lt;/maxHistory&gt; #只保留最近30天的日志文件
</span><span class='line'>           &lt;TimeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"&gt;#每天的日志按照100MB分割
</span><span class='line'>                &lt;MaxFileSize&gt;100MB&lt;/MaxFileSize&gt;
</span><span class='line'>            &lt;/TimeBasedFileNamingAndTriggeringPolicy&gt;
</span><span class='line'>            &lt;totalSizeCap&gt;20GB&lt;/totalSizeCap&gt;#日志总的大小上限，超过此值则异步删除旧的日志
</span><span class='line'>       &lt;/rollingPolicy&gt;
</span><span class='line'>    &lt;/appender&gt;
</span><span class='line'>    
</span><span class='line'>    &lt;appender name="ROLLING_FILE_APPENDER_2" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt;
</span><span class='line'>       &lt;File&gt;${root_log_dir}mylog.log&lt;/File&gt;
</span><span class='line'>       &lt;Append&gt;true&lt;/Append&gt;
</span><span class='line'>       &lt;encoder&gt;
</span><span class='line'>           &lt;pattern&gt;%date [%level] [%thread] %logger{80} [%file : %line] %msg%n&lt;/pattern&gt;
</span><span class='line'>       &lt;/encoder&gt;
</span><span class='line'>       #下面的日志rolling策略和ROLLING_FILE_APPENDER的等价，保留最近30天的日志，每天的日志按照100MB分隔，日志总的大小上限为20GB
</span><span class='line'>       &lt;rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy"&gt;
</span><span class='line'>            &lt;fileNamePattern&gt;mylog.log-%d{yyyy-MM-dd}.%i&lt;/fileNamePattern&gt;
</span><span class='line'>            &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt;
</span><span class='line'>            &lt;maxHistory&gt;30&lt;/maxHistory&gt;
</span><span class='line'>            &lt;totalSizeCap&gt;20GB&lt;/totalSizeCap&gt;
</span><span class='line'>        &lt;/rollingPolicy&gt;
</span><span class='line'>    &lt;/appender&gt;
</span><span class='line'>    
</span><span class='line'>     &lt;appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender"&gt;
</span><span class='line'>       &lt;encoder&gt;
</span><span class='line'>         &lt;pattern&gt;%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n&lt;/pattern&gt;
</span><span class='line'>       &lt;/encoder&gt;
</span><span class='line'>     &lt;/appender&gt;
</span><span class='line'>        
</span><span class='line'>    &lt;logger name="myLogger" level="INFO" additivity="false"&gt;
</span><span class='line'>        &lt;appender-ref ref="ROLLING_FILE_APPENDER" /&gt;
</span><span class='line'>    &lt;/logger&gt;
</span><span class='line'>        
</span><span class='line'>     &lt;root level="DEBUG"&gt;          
</span><span class='line'>       &lt;appender-ref ref="STDOUT" /&gt;
</span><span class='line'>     &lt;/root&gt;  
</span><span class='line'>
</span><span class='line'>&lt;/configuration&gt;</span></code></pre></td></tr></table></div></figure>


<p>Logback的配置文件读取顺序（默认都是读取classpath下的）：logback.groovy -> logback-test.xml -> logback.xml。如果想要自定义配置文件路径，那么只有通过修改logback.configurationFile的系统属性。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>System.setProperty("logback.configurationFile", "...");
</span><span class='line'>或者
</span><span class='line'>-Dlogback.configurationFile="xx"</span></code></pre></td></tr></table></div></figure>


<p>Logback的日志级别：TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR。如果logger没有被分配级别，那么它将从有被分配级别的最近的祖先那里继承级别。root logger 默认级别是 DEBUG。</p>

<p>Logback中的logger同样也是有继承机制的。配置文件中的additivit也是为了不去继承rootLogger的配置，从而避免输出多份日志。</p>

<p>为了方便Log4j到Logback的迁移，官网提供了log4j.properties到logback.xml的转换工具：<a href="https://logback.qos.ch/translator/">https://logback.qos.ch/translator/</a>。</p>

<h3>使用</h3>

<p>Logback由于是天然与SLF4J集成的，因此它的使用也就是SLF4J的使用。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>import org.slf4j.LoggerFactory;
</span><span class='line'>
</span><span class='line'>private static final Logger LOGGER=LoggerFactory.getLogger(xx.class);
</span><span class='line'>
</span><span class='line'>LOGGER.info(" this is a test in {}", xx.class.getName())</span></code></pre></td></tr></table></div></figure>


<p>SLF4J同样支持占位符。</p>

<p>此外，如果想要打印json格式的日志（例如，对接日志到Logstash中），那么可以使用logstash-logback-encoder做为RollingFileAppender的encoder。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;encoder class="net.logstash.logback.encoder.LogstashEncoder" &gt;
</span><span class='line'>...
</span><span class='line'>&lt;/encoder&gt;</span></code></pre></td></tr></table></div></figure>


<h3>性能优化</h3>

<p>Logback提供了AsyncAppender进行异步日志输出，此异步appender实现上利用了队列做缓冲，使得日志输出性能得到提高。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;appender name="FILE_APPENDER" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt;
</span><span class='line'>      &lt;File&gt;${root_log_dir}app.log&lt;/File&gt;
</span><span class='line'>      &lt;Append&gt;true&lt;/Append&gt;
</span><span class='line'>      &lt;encoder&gt;
</span><span class='line'>          &lt;pattern&gt;%date [%level] [%thread] %logger{80} [%file : %line] %msg%n&lt;/pattern&gt;
</span><span class='line'>      &lt;/encoder&gt;
</span><span class='line'>      &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt;
</span><span class='line'>          &lt;fileNamePattern&gt;${root_log_dir}app.log.%d&lt;/fileNamePattern&gt;
</span><span class='line'>      &lt;/rollingPolicy&gt;
</span><span class='line'>&lt;/appender&gt;
</span><span class='line'>&lt;appender name ="ASYNC" class= "ch.qos.logback.classic.AsyncAppender"&gt;  
</span><span class='line'>       &lt;discardingThreshold &gt;0&lt;/discardingThreshold&gt;  
</span><span class='line'>       
</span><span class='line'>       &lt;queueSize&gt;512&lt;/queueSize&gt;  
</span><span class='line'>       
</span><span class='line'>       &lt;appender-ref ref ="FILE_APPENDER"/&gt;  
</span><span class='line'>&lt;/appender&gt;  
</span><span class='line'>       </span></code></pre></td></tr></table></div></figure>


<p>这里需要特别注意以下两个参数的配置：</p>

<ul>
<li>queueSize：队列的长度,该值会影响性能，需要合理配置。</li>
<li>discardingThreshold：日志丢弃的阈值，即达到队列长度的多少会丢弃TRACT、DEBUG、INFO级别的日志，默认是80%，设置为0表示不丢弃日志。</li>
</ul>


<p>此外，由于是异步输出，为了保证日志一定会被输出以及后台线程能够被及时关闭，在应用退出时需要显示关闭logback。有两种方式：</p>

<ul>
<li><p>在程序退出的地方（ServletContextListener的contextDestroyed方法、Spring Bean的destroy方法）显式调用下面的代码。</p>

<pre><code class="``">  LoggerContext loggerContext = (LoggerContext) LoggerFactory.getILoggerFactory();
  loggerContext.stop();
</code></pre></li>
<li><p>在logback配置文件里，做如下配置。</p>

<pre><code class="``">  &lt;configuration&gt;

      &lt;shutdownHook class="ch.qos.logback.core.hook.DelayingShutdownHook"/&gt;
      .... 
  &lt;/configuration&gt;
</code></pre></li>
</ul>


<h2>五. 日志门面</h2>

<p>前面的四个框架是实际的日志框架。对于开发者而言，每种日志都有不同的写法。如果我们以实际的日志框架来进行编写，代码就限制死了，之后就很难再更换日志系统，很难做到无缝切换。</p>

<p>Java开发中经常提到面向接口编程，所以我们应该是按照一套统一的API来进行日志编程，实际的日志框架来实现这套API，这样的话，即使更换日志框架，也可以做到无缝切换。</p>

<p>这就是Commons-Logging与SLF4J这种日志门面框架的初衷。</p>

<h3>Apache Commons-Logging</h3>

<p>Apache Commons-Logging经常被简称为JCL，是Apache开源的日志门面框架。Spring中使用的日志框架就是JCL，使用起来非常简单。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>import org.apache.commons.logging.LogFactory;
</span><span class='line'>
</span><span class='line'>private static final Log LOGGER = LogFactory.getLog(xx.class);
</span><span class='line'>
</span><span class='line'>LOGGER.info("...");</span></code></pre></td></tr></table></div></figure>


<p>使用JCL需要先引入JCL的依赖：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;dependency&gt;
</span><span class='line'>    &lt;groupId&gt;commons-logging&lt;/groupId&gt;
</span><span class='line'>    &lt;artifactId&gt;commons-logging&lt;/artifactId&gt;
</span><span class='line'>    &lt;version&gt;xx&lt;/version&gt;
</span><span class='line'>&lt;/dependency&gt;</span></code></pre></td></tr></table></div></figure>


<p>再来看一下如何让JCL使用其他日志实现框架:</p>

<ol>
<li>这里当没有其他日志jar包存在的时候，JCL有自己的默认日志实现，默认的实现是对JUL的包装，即当没有其他任何日志包时，通过JCL调用的就是JUL做日志操作。</li>
<li>使用Log4j作为日志实现框架，那么只需要引入Log4j的jar包即可。</li>
<li><p>使用Log4j2作为日志实现，那么除了Log4j2的jar包，还需要引入Log4j2与Commons-Logging的集成包（使用SPI机制提供了自己的LogFactory实现）：</p>

<pre><code class="`"> &lt;dependency&gt;
     &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;
     &lt;artifactId&gt;log4j-jcl&lt;/artifactId&gt;
     &lt;version&gt;xx&lt;/version&gt;
 &lt;/dependency&gt;
</code></pre></li>
<li><p>使用Logback作为日志实现，那么由于Logback的调用是通过SLF4J的，因此需要引入jcl-over-slf4j包（直接覆盖了JCL的类），并同时引入SLF4J以及Logback的jar包。</p>

<pre><code class="`"> &lt;dependency&gt;
     &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
     &lt;artifactId&gt;jcl-over-slf4j&lt;/artifactId&gt;
     &lt;version&gt;xx&lt;/version&gt;
 &lt;/dependency&gt;
</code></pre></li>
</ol>


<h3>SLF4J</h3>

<p>SLF4J（Simple Logging Facade for Java）为Java提供的简单日志Facade。允许用户以自己的喜好，在工程中通过SLF4J接入不同的日志实现。与JCL不同的是，SLF4J只提供接口，没有任何实现（可以认为Logback是默认的实现）。</p>

<p>SLF4J的使用前提是引入SLF4J的jar包:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;!-- SLF4J --&gt;
</span><span class='line'>&lt;dependency&gt;
</span><span class='line'>   &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
</span><span class='line'>   &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;
</span><span class='line'>   &lt;version&gt;xx&lt;/version&gt;
</span><span class='line'>&lt;/dependency&gt;</span></code></pre></td></tr></table></div></figure>


<p>再看一下SLF4J如何和其他日志实现框架集成。</p>

<ol>
<li><p>使用JUL作为日志实现，需要引入slf4j-jdk14包。</p>

<pre><code class="`"> &lt;dependency&gt;
     &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
     &lt;artifactId&gt;slf4j-jdk14&lt;/artifactId&gt;
     &lt;version&gt;xx&lt;/version&gt;
 &lt;/dependency&gt;
</code></pre></li>
<li><p>使用Log4j作为日志实现，需要引入slf4j-log4j12和log4j两个jar包。</p>

<pre><code class="`"> &lt;!-- slf4j-log4j --&gt;
 &lt;dependency&gt;
     &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
     &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;
     &lt;version&gt;xx&lt;/version&gt;
 &lt;/dependency&gt;

 &lt;!-- log4j --&gt;
 &lt;dependency&gt;
     &lt;groupId&gt;log4j&lt;/groupId&gt;
     &lt;artifactId&gt;log4j&lt;/artifactId&gt;
     &lt;version&gt;xx&lt;/version&gt;
 &lt;/dependency&gt;
</code></pre></li>
<li><p>使用Log4j2作为日志实现，需要引入log4j-slf4j-impl依赖。</p>

<pre><code class="`"> &lt;!-- log4j2 --&gt;
 &lt;dependency&gt;
     &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;
     &lt;artifactId&gt;log4j-api&lt;/artifactId&gt;
     &lt;version&gt;xx&lt;/version&gt;
 &lt;/dependency&gt;
 &lt;dependency&gt;
     &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;
     &lt;artifactId&gt;log4j-core&lt;/artifactId&gt;
     &lt;version&gt;xx/version&gt;
 &lt;/dependency&gt;
 &lt;!-- log4j-slf4j-impl （用于log4j2与slf4j集成） --&gt;
 &lt;dependency&gt;
     &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt;
     &lt;artifactId&gt;log4j-slf4j-impl&lt;/artifactId&gt;
     &lt;version&gt;xx&lt;/version&gt;
 &lt;/dependency&gt;
</code></pre></li>
<li><p>使用Logback作为日志实现，只需要引入logback包即可。</p></li>
</ol>


<h2>六. 日志集成</h2>

<p>上面说到了四种日志实现框架和两种日志门面框架。面对这么多的选择，即便是一个刚刚开始做的应用，也会由于依赖的第三方库使用的日志框架五花八门而造成日志配置和使用上的烦恼。得益于JCL和SLF4J，我们可以很容易的把日志都统一为一种实现，从而可以进行集中配置和使用。这里就以用Logback统一日志实现为例：</p>

<ol>
<li><p>配置好Logback的依赖：</p>

<pre><code class="`"> &lt;!-- slf4j-api --&gt;
 &lt;dependency&gt;
     &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
     &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;
     &lt;version&gt;xx&lt;/version&gt;
 &lt;/dependency&gt;
 &lt;!-- logback --&gt;
 &lt;dependency&gt; 
     &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; 
     &lt;artifactId&gt;logback-core&lt;/artifactId&gt; 
     &lt;version&gt;xx&lt;/version&gt; 
 &lt;/dependency&gt;
 &lt;!-- logback-classic（已含有对slf4j的集成包） --&gt; 
 &lt;dependency&gt; 
     &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; 
     &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; 
     &lt;version&gt;xx&lt;/version&gt; 
 &lt;/dependency&gt;
</code></pre></li>
<li><p>切换Log4j到SLF4J</p>

<pre><code class="`"> &lt;dependency&gt;
    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
    &lt;artifactId&gt;log4j-over-slf4j&lt;/artifactId&gt;
    &lt;version&gt;xx&lt;/verison&gt;
&lt;/dependency&gt;
</code></pre></li>
<li><p>切换JUL到SLF4J</p>

<pre><code class="`"> &lt;dependency&gt;
    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
    &lt;artifactId&gt;jul-to-slf4j&lt;/artifactId&gt;
    &lt;version&gt;xx&lt;/verison&gt;
 &lt;/dependency&gt;
</code></pre></li>
<li><p>切换JCL到SLF4J</p>

<pre><code class="`"> &lt;dependency&gt;
    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
    &lt;artifactId&gt;jcl-over-slf4j&lt;/artifactId&gt;
    &lt;version&gt;xx&lt;/verison&gt;
 &lt;/dependency&gt;
</code></pre></li>
</ol>


<p>这里需要注意的是，做了以上配置后，务必要排除其他日志包的存在，如Log4j。此外，在日常开发中经常由于各个依赖的库间接引入了其他日志库，造成日志框架的循环转换。比如同时引入了log4j-over-slf4j和slf4j-log4j12的情况，当使用SLF4J调用日志操作时就会形成循环调用。</p>

<p>笔者目前比较推崇的是使用SLF4J统一所有框架接口，然后都转换到Logback的底层实现。但这里需要说明的是Logback的作者是为了弥补Log4j的各种缺点而优化实现了SLF4J以及Logback，但不知为何作者又推出了Log4j2以期取代Log4j和Logback。所以，如果是一个新的项目，那么直接跳过Log4j和Logback选择Log4j2也是一个不错的选择, 官网也提供了Log4j到Log4j2的迁移说明。</p>

<blockquote><p>本文节选自《Java工程师修炼之道》一书。</p></blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[微服务杂谈]]></title>
    <link href="http://www.rowkey.me/blog/2019/05/30/msa/"/>
    <updated>2019-05-30T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2019/05/30/msa</id>
    <content type="html"><![CDATA[<p>这几年在Java工程师招聘时，会看到很多人的简历都写着使用了Spring Cloud做微服务实现，使用Docker做自动化部署，并且也会把这些做为自己的亮点。而比较有趣的这其中以小公司出来的人为绝大多数，大的公司出来的人简历上倒是很少提这些东西。</p>

<p>对于我自己来说，从15年就开始关注这一块，看过马丁.福勒最开始的关于微服务的论文、也看过不少对微服务的论证的英文文章和书，也研究过Spring Cloud、Sofa等开源实现以及Service mesh。考虑到我们公司研发团队人力不足、基础设施不完善，当初是没有推行微服务的。但随着看到上述的那种简历越来越多，有时候我也会疑问：难道真的不用微服务就落后了吗？公司的同事如果不掌握这些就真的没有竞争力了吗。而随着最近公司业务的逐步提升，研发人员越来越多，借着在梳理公司的微服务落地计划时，也梳理了一下微服务的相关知识点，也是本文的主要内容。</p>

<p>开篇之前先声明我对微服务的几点态度:</p>

<blockquote><ol>
<li>架构模式有很多，微服务不是唯一的选择也不是什么银弹。国内很多中小公司引入微服务都是在盲目追新，也能看出做此种技术选型的工程师基础架构素质的不足。</li>
<li>“你必须长的足够高才能使用微服务”。微服务基础设施，尤其是容器技术、自动化部署、自动化测试这些不完备，微服务形同虚设，不会带来什么质的提升。</li>
<li>微服务架构的关键不在于具体的实现，而在于如何合理地划分服务边界以及组织架构是否相匹配。不考虑研发团队的规模和组成就盲目上微服务是不良的技术选型。</li>
<li>Spring Boot是Spring全家桶的上层封装，并不是什么崭新的技术，也不是什么值得觉得成为自己杀手锏的技术。</li>
<li>Spring Cloud中Spring Cloud Netflix的组件是经过生产环境验证的，其他的则建议慎重选择。</li>
</ol>
</blockquote>

<!--more-->


<h2>微服务是什么</h2>

<p>微服务起源于2005年Peter Rodgers博士在云端运算博览会提出的微Web服务(Micro-Web-Service)，根本思想类似于Unix的管道设计理念。2014年，由Martin Fowler 与 James Lewis共同提出了微服务的概念，定义了微服务架构风格是一种通过一套小型服务来开发单个应用的方法，每个服务运行在自己的进程中，并通过轻量级的机制进行通讯（HTTP API）。关键的三点是<strong>small、automated以及lightweight</strong>。</p>

<p>对比SOA，微服务可以看做是SOA的子集，是轻量级的SOA，粒度更细的服务，独立进程、数据分离，更注重<strong>敏捷、持续交付、DevOps以及去中心化实践</strong>。其共同的<strong>架构原理</strong>：</p>

<ul>
<li>单一职责</li>
<li>关注分离：控制与逻辑相分离</li>
<li>模块化和分而治之</li>
</ul>


<p><strong>特点</strong>：</p>

<ul>
<li>用服务进行组件化</li>
<li>围绕业务能力进行组织</li>
<li>是产品而非项目</li>
<li>端点智能化和哑管道: 控制逻辑都在端点，管道仅仅是传输</li>
<li>全自动化部署</li>
<li>语言和数据的去中心化控制</li>
<li>面向失败设计</li>
<li>渐进式设计</li>
</ul>


<p>综合来看，其优缺点如下：</p>

<p><strong>优点</strong>：</p>

<ul>
<li>模块的强边界</li>
<li>独立部署</li>
<li>技术选型的多样性</li>
</ul>


<p><strong>缺点</strong>：</p>

<ul>
<li>分布式带来编程复杂度，远程调用的消耗</li>
<li>舍弃强一致性，实现最终一致性</li>
<li>操作复杂性要求有一个成熟的运维团队或者运维基础设施</li>
</ul>


<h2>为什么要采用微服务</h2>

<p>是否选择微服务取决于你要设计的系统的复杂度。微服务是用来把控复杂系统的，但是随之而来的就是引入了微服务本身的复杂度。需要解决包括自动化部署、监控、容错处理、最终一致性等其他分布式系统面临的问题。即使已经有一些普遍使用的解决方案，但是仍然是有不小的成本的。</p>

<p><img src="http://www.rowkey.me/post_images/msa/productivity.png" alt="" /></p>

<p>生产力和复杂度的关系如图所示，可见系统越复杂，微服务带来的收益越大。此外，无论是单体应用还是微服务，团队的技能都需要能够把控住。</p>

<p>马丁.福勒的一个观点是：除非管理单体应用的成本已经太复杂了（太大导致很难修改和部署），否则都不要考虑微服务。大部分应用都应该选择单体架构，做好单体应用的模块化而不是拆分成服务。</p>

<p>因此，<strong>系统一开始采用单体架构，做好模块化，之后随着系统变得越来越复杂、模块/服务间的边界越来越清晰，再重构为微服务架构是一个合理的架构演化路径。</strong></p>

<p><strong>四个可以考虑上微服务的情况</strong>：</p>

<ol>
<li>多人开发一个模块/项目，提交代码频繁出现大量冲突。</li>
<li>模块间严重耦合，互相依赖，每次变动需要牵扯多个团队，单次上线需求太多，风险大。</li>
<li>主要业务和次要业务耦合，横向扩展流程复杂。</li>
<li>熔断降级全靠if-else。</li>
</ol>


<p><strong>微服务的三个阶段</strong>：</p>

<ol>
<li>微服务1.0：仅使用注册发现，基于SpringCloud或者Dubbo进行开发。</li>
<li>微服务2.0：使用了熔断、限流、降级等服务治理策略，并配备完整服务工具和平台。</li>
<li>微服务3.0：Service Mesh将服务治理作为通用组件，下沉到平台层实现，应用层仅仅关注业务逻辑，平台层可以根据业务监控自动调度和参数调整，实现AIOps和智能调度。</li>
</ol>


<h2>微服务架构</h2>

<h3>先决条件</h3>

<ul>
<li>快速的环境提供能力：依赖于云计算、容器技术，快速交付环境。</li>
<li>基本的监控能力：包括基础的技术监控和业务监控。</li>
<li>快速的应用部署能力：需要部署管道提供快速的部署能力。</li>
<li>Devops文化：需要具有良好的持续交付能力，包括全链路追踪、快速环境提供和部署等，还需要快速的反应能力（对问题、故障的快速响应），开发和运维的协同工作。</li>
</ul>


<p>此外，根据康威定律和逆康威定律（技术架构倒逼组织架构改进），组织架构也是一个很关键的因素。对应于微服务架构，组织架构需要遵循以下原则：</p>

<ol>
<li>一个微服务由一个团队维护，团队成员以三人为宜。</li>
<li>单个团队的任务和发展是独立的，不受其他因素影响。</li>
<li>团队是功能齐全、全栈、自治的，扁平、自我管理。</li>
</ol>


<h3>基础设施</h3>

<p>微服务的推行需要依赖于很多底层基础设施，包括提供微服务的编译、集成、打包、部署、配置等工作，采用PaaS平台解决微服务从开发到运行的全生命周期管理，同时提供异构环境管理、容器资源隔离与互通、服务伸缩漂移、服务升级与回退、服务熔断与降级、服务注册与发现。</p>

<ol>
<li><p>最基本的基础设施</p>

<ul>
<li>进程间通讯机制：微服务是独立进程的，需要确定之间的通讯方式。</li>
<li>服务发现+服务路由: 提供服务注册中心，服务提供者和消费者通过服务发现获取服务的信息从而调用服务，实现服务的负载均衡等。</li>
<li>服务容错：微服务架构中，由于服务非常多，往往是一个服务挂了，整个请求链路的服务都受到影响，因此需要服务容错，在服务调用失败的时候能够处理错误或者快速失败，包括熔断、fallback、重试、流控和服务隔离等。</li>
<li>分布式事务支持：随着业务拆分为服务，那么有时候不可避免的就是跨服务的事务，即分布式事务的问题。原则是尽量避免分布式事务，如果无法避免那么可以使用消息系统或者CQRS和Event Sourcing方案来实现最终一致性。如果需要强一致性，则有两阶段提交、三阶段提交、TCC等分布式事务解决方案。</li>
</ul>
</li>
<li><p>提升外部服务对接效率和内部开发效率</p>

<ul>
<li>API网关: 负责外部系统的访问，负责跨横切面的公共层面的工作，包括安全、日志、权限控制、传输加密、请求转发、流量控制等。典型的网关功能即对外暴露一个域名xx.com，根据第一级目录做反向路由xx.com/user，xx.com/trade。每一级目录，如user、trade对应一个服务的域名。此外，API网关也可以有服务编排的功能（不推荐）。</li>
<li>接口框架: 规范服务之间通讯使用的数据格式、解析包、自解释文档，便于服务使用方快速上手等。</li>
</ul>
</li>
<li><p>提升测试和运维效率</p>

<ul>
<li>配置中心: 运行时配置管理能够解决动态修改配置并批量生效的问题。包括配置版本管理、配置项管理、节点管理、配置同步等。</li>
<li>持续交付：包括持续集成、自动化部署等流程。目的就是小步迭代，快速交付。

<ul>
<li>持续集成：这一部分并非是微服务特定的，对于之前的单体应用，此部分一般来说也是必要的。主要是指通过自动化手段，持续地对代码进程编译构建、自动化测试，以得到快速有效的质量反馈，从而保证代码的顺利交付。自动化测试包括代码级别的单元测试、单个系统的集成测试、系统间的接口测试。</li>
<li>自动化部署：微服务架构，节点数动辄上百上千，自动化部署能够提高部署速度和部署频率，从而保证持续交付。包括版本管理、资源管理、部署操作、回滚操作等功能。而对于微服务的部署方式，包括<strong>蓝绿部署、滚动部署以及金丝雀部署</strong>。</li>
</ul>
</li>
</ul>
</li>
<li><p>进一步提升运维效率</p>

<ul>
<li>服务监控: 微服务架构下节点数目众多，需要监控的机器、网络、进程、接口等的数量大大增加，需要一个强大的监控系统，能够提供实时搜集信息进行分析以及实时分析之上的预警。包括监控服务的<strong>请求次数、响应时间分布、最大/最小响应值、错误码分布</strong>等</li>
<li>服务跟踪：跟踪一个请求的完整路径，包括<strong>请求发起时间、响应时间、响应码、请求参数、返回结果</strong>等信息，也叫做全链路跟踪。通常的服务监控可以和服务监控做在一起，宏观信息由服务跟踪呈现，微观单个服务/节点的信息由服务监控呈现。服务跟踪目前的实现理论基本都是Google的Dapper论文。</li>
<li>服务安全：内网之间的微服务调用原则上讲应该是都可以互相访问写，一般并不需要权限控制，但有时候限于业务要求，会对接口、数据等方面有安全控制的要求。此部分可以以配置的方式存在于服务注册中心中，和服务绑定，在请求时由做为服务提供者的服务节点进行安全策略控制。配置则可以存储在配置中心以方便动态修改。</li>
</ul>
</li>
</ol>


<p>在微服务数量很少的情况下，以上基础设施的优先级自上而下降低。否则，仅仅依赖人工操作，则投入产出比会很低。</p>

<p>还需要提到的是Docker容器技术。虽然这个对于微服务并不是必须的，但是容器技术<strong>轻量级、灵活、与应用依存、屏蔽环境差异</strong>的特性对于持续交付的实现是至关重要的，即使对于传统的单体应用也能够给其带来交付效率的大幅提升。</p>

<h3>架构设计模式</h3>

<p>在引入微服务之后，传统的单体应用变为了一个一个服务，之前一个应用直接提供接口给客户端访问的架构不再适用。微服务架构下，针对不同设备的接口做为BFF层（Backend For Frontend），也叫做用户体验适配层，负责聚合、编排微服务的数据转换成前端需要的数据。服务之间的调用则在允许的情况下（允许延迟）尽可能使用异步消息传递方式，如此形成<strong>面向用户体验的微服务架构设计模式</strong>。如下图所示：</p>

<p><img src="http://www.rowkey.me/post_images/msa/msa-arch.png" alt="" /></p>

<p><strong>Client -> API Gateway -> BFF（Backend For Frontend） -> Downstream Microservices</strong></p>

<ul>
<li>后台采用微服务架构，微服务可以采用不同的编程语言和不同的存储机制。</li>
<li>前台采用BFF模式对不同的用户体验（如桌面浏览器，Native App，平板响应式Web）进行适配。</li>
<li>BFF、API Orchestration Layer，Edge Service Layer，Device Wrapper Layer是相同的概念。</li>
<li>BFF不能过多，过多会造成代码逻辑重复冗余。</li>
<li>可以将网关承担的功能，如Geoip、限流、安全认证等跨横切面功能和BFF做在同一层，虽然增加了BFF层的复杂性，但能够得到性能优势。</li>
</ul>


<h3>服务拆分</h3>

<p>微服务架构最核心的环节，主要是对服务的<strong>横向拆分</strong>。服务拆分就是讲一个完整的业务系统解耦为服务，<strong>服务需要职责单一，之间没有耦合关系，能够独立开发和维护</strong>。</p>

<p>服务拆分不是一蹴而就的，需要在开发过程中不断地理清边界。在完全理清服务之前，尽量推迟对服务的拆分，尤其是对数据库的拆分。</p>

<p><strong>拆分方法</strong>如下：</p>

<ul>
<li>基于业务逻辑拆分</li>
<li>基于可扩展拆分</li>
<li>基于可靠性拆分</li>
<li>基于性能拆分</li>
</ul>


<p>其中，对于无法修改的遗留系统，采用绞杀者模式：在遗留系统外面增加新的功能做成微服务方式，而不是直接修改原有系统，逐步的实现对老系统替换。</p>

<p><strong>拆分过程需要遵守的规范</strong>如下：</p>

<ul>
<li>先少后多、先粗后细（粒度）</li>
<li>服务纵向拆分最多三层，两次调用：Controller、组合服务、基础服务</li>
<li>仅仅单向调用，禁止循环调用</li>
<li>串行调用改为并行调用或者异步化</li>
<li>接口应该幂等</li>
<li>接口数据定义严禁内嵌，透传</li>
<li>规范化工程名</li>
<li>先拆分服务，等服务粒度确定后再拆分数据库。</li>
</ul>


<h3>微服务框架</h3>

<p>上面讲述了微服务架构的众多基础设施，如果每一个基础设施都需要自己开发的话是非常巨大的开发工作。目前市面上已经有不少开源的微服务框架可以选择。</p>

<ol>
<li><p>Spring Boot</p>

<p> Spring Boot是用来简化新Spring应用的初始搭建以及开发过程的。其虽然不是微服务框架，但其设计的初衷本质就是微应用的底层框架，因此非常适合用于微服务基础设施的开发以及微服务的应用开发。尤其对于Spring技术栈的团队来说，基于Spring Boot开发微服务框架和应用是自然而然的一个选择。</p></li>
<li><p>Dubbo&amp;&amp;Motan</p>

<p> Dubbo阿里开源的服务治理框架。其出现在微服务理念兴起之前，可以看做是SOA框架的集大成之作。但其仅仅包含了微服务基础设施的部分功能，诸如熔断、服务跟踪、网关等都没有实现。</p>

<ul>
<li>服务发现 ：服务发布、订阅、通知</li>
<li>高可用策略 ：失败重试（Failover）、快速失败（Failfast）、资源隔离 - 负载均衡 ：最少活跃连接、一致性 Hash、随机请求、轮询等</li>
<li>扩展性 ：支持 SPI 扩展（service provider interface）</li>
<li>其他 ：调用统计、访问日志等</li>
</ul>


<p>Motan则是微博开源的类似Dubbo的RPC框架，与Dubbo相比更轻量级。</p></li>
<li><p>Spring Cloud</p>

<p> Spring Cloud是基于Spring Boot实现的微服务框架，也可以看做一套微服务实现规范。基本涵盖了微服务基础设施的方方面面，包括配置管理、服务发现、断路器、智能路由、微代理、控制总线、全局锁、决策竞选、分布式会话和集群状态管理等。其基于Spring生态，社区支持非常好。但其很多组件都没有经过生产环境验证，需要慎重选择。</p>

<p> Spring Cloud Netflix是Spring Cloud的一个子项目，是Spring对Netflix OSS的集成实现。基于Netflix的大规模使用，其中的已经被广泛使用的组件包括：</p>

<ul>
<li>Eureka： 服务注册和服务发现</li>
<li>Ribbon：弹性而智能的进程间和服务通讯机制，客户端负载均衡</li>
<li>Hystrix： 熔断器，在运行时提供延迟和容错的隔离</li>
<li>Zuul: 服务网关</li>
</ul>


<p>此外，另一个子项目Spring Cloud Alibaba则是Alibaba开源的基于Spring Boot的微服务框架，主要是对阿里云服务的支持。</p></li>
<li><p>Service Mesh</p>

<p> 上述的微服务框架都是侵入式的，服务化的过程都需要进行代码改造。Service Mesh则是下一代微服务架构，最明显的特征就是无入侵。采用sidecar模式来解决系统架构微服务化后的服务间通信和治理问题。如下图所示：</p>

<p> <img src="http://www.rowkey.me/post_images/msa/sm.png" alt="" /></p>

<p> 目前主流的开源实现包括：</p>

<ul>
<li>Linkerd和Envoy：以 sidecar 为核心，关注如何做好proxy，并完成一些通用控制平面的功能。缺乏对这些sidecar的管理和控制。</li>
<li>Istio和Conduit：目前最为流行的Service Mesh实现方案，集中在更加强大的控制平面(sidecar被称为数据平面)功能。前者由Google和IBM合作，并使用了Envoy作为sidecar部分的实现；后者则是Linkerd作者的作品。相比起来，Istio有巨头背景，功能强大，但可用性和易用性一直不高，Conduit则相对简单、功能聚焦。</li>
</ul>


<p>限于Service Mesh带来的性能延迟的开销以及sidecar对分布复杂性的增加，其对大规模部署(微服务数目多)、异构复杂(交互协议/开发语言类型多)的微服务架构带来的收益会更大。</p></li>
<li><p>Sofastack</p>

<p> 蚂蚁金服开源的构建金融级分布式架构的一套中间件。包括微服务开发框架、RPC框架、服务注册中心、全链路追踪、服务监控、Service Mesh等一整套分布式应用开发工具。</p>

<p> 特别值得一提的是SOFAMesh。其是对下一代微服务架构Service Mesh的大规模落地方案实践，基于 Istio改进和扩展而来，应该是国内最为成熟的开源Service Mesh方案。</p></li>
</ol>


<p>此外，需要提到<strong>Kubernetes(K8s)</strong>，其本身提供了部分的微服务特性支持（通过域名做服务发现），对代码无侵入。但服务调用、熔断这些都需要自己实现。</p>

<p>综上，目前公司技术团队技术栈是Spring，并且已有服务的实现都是基于Dubbo，因此选择Spring Cloud Netflix做为基础的微服务框架，对其中不成熟或者缺乏的组件，选择业界更为成熟的组件替代即可。</p>

<p><img src="http://www.rowkey.me/post_images/msa/msa-basic.png" alt="" /></p>

<ul>
<li>API网关：Zuul</li>
<li>服务注册中心：Dubbo</li>
<li>配置中心：disconf</li>
<li>服务监控&amp;&amp;全链路追踪：CAT</li>
<li>服务开发框架：Spring Boot</li>
<li>日志监控、告警：ELK + Elasalert</li>
<li>流量控制：Sentinel</li>
<li>消息队列：Kafka</li>
</ul>


<h2>参考资料</h2>

<ul>
<li><a href="https://www.ben-morris.com/whats-so-bad-about-monoliths-anyway/">What’s so bad about monoliths anyway…?!</a></li>
<li><a href="https://martinfowler.com/articles/microservices.html">Microservice</a></li>
<li><a href="https://martinfowler.com/bliki/MicroservicePremium.html">MicroservicePremium</a></li>
<li><a href="https://martinfowler.com/articles/microservice-trade-offs.html">Microservice Trade-Offs</a></li>
<li><a href="https://martinfowler.com/bliki/MicroservicePrerequisites.html">MicroservicePrerequisites</a></li>
<li><a href="https://martinfowler.com/bliki/MonolithFirst.html">MonolithFirst</a></li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzI2MzM3MzkyMg==&amp;mid=2247486544&amp;idx=1&amp;sn=999be8b4f06150b96d9a46ada6bb9ded&amp;chksm=eabd995dddca104bd3c6262d491572f7be9b2a763a43a388f66bd0e90e4bd60e5037727107e4&amp;mpshare=1&amp;scene=1&amp;srcid=0201lT7ZBVBGmTki8bYnmDgl%23rd">服务怎么拆？</a></li>
<li><a href="https://www.thoughtworks.com/insights/blog/bff-soundcloud">BFF@SoundCloud</a></li>
<li><a href="http://www.importnew.com/28798.html">Service Mesh 及其主流开源实现解析</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[这些知识决定了程序员的上限（PPT版）]]></title>
    <link href="http://www.rowkey.me/blog/2019/04/22/upforprogrammer/"/>
    <updated>2019-04-22T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2019/04/22/upforprogrammer</id>
    <content type="html"><![CDATA[<p>讲述决定程序员上限的一些知识技能点，包括如何学习、如何阅读源码、计算机科学基础知识体系等。来自内部分享PPT，后续会发布<strong>详细版</strong>。</p>

<!--more-->


<h2>什么是程序员？</h2>

<ul>
<li>码农、程序猿、程序媛</li>
<li>使用<strong>程序</strong>实现价值</li>
<li>程序=数据+算法</li>
<li>软件=程序+软件工程</li>
<li>程序员=工程师？</li>
</ul>


<h2>程序员金字塔</h2>

<p><img src="http://www.rowkey.me/post_images/ufp/programmer-pyramid.png" width="500"/></p>

<h2>程序员知识结构</h2>

<p><img src="http://www.rowkey.me/post_images/ufp/knowledge.png" alt="" /></p>

<ul>
<li>面试造火箭，工作拧螺丝</li>
<li>会什么是你的下限，能够会什么是你的上限</li>
<li>越底层的东西越决定上限</li>
</ul>


<h2>学习欲望</h2>

<blockquote><p>杜绝<strong>1</strong>年工作经验重复<strong>N</strong>年</p></blockquote>

<ul>
<li>如果自己遇到这种问题会怎么解决，与资料中的解决方案相比优劣如何？</li>
<li>别人为什么会想到这种解决方案？</li>
<li>自己是由于经验欠缺还是技能点欠缺才导致没有想到好的解决方案？</li>
<li>解决这类问题的根本思路是什么样的？</li>
</ul>


<h2>学习能力</h2>

<blockquote><p>不是懂得多，而是学得快</p></blockquote>

<ul>
<li><strong>知其然更要知其所以然</strong>：技术以深度优先</li>
<li><strong>类比现实</strong>：对现实世界的模拟</li>
<li><strong>更好地接受信息</strong>：建立自己的知识体系；阅读并记笔记，纳入知识体系</li>
<li><strong>深度思考</strong>：阅读书籍</li>
<li><strong>动手实践、频繁练习</strong>：项目驱动型学习；主动思考</li>
<li><strong>自我总结</strong>：完善知识体系；笔记、博客、分享</li>
<li><strong>持续学习</strong>：逃离舒适区；学到老，活到老</li>
</ul>


<h2>如何学习新技术</h2>

<p><img src="http://www.rowkey.me/post_images/ufp/study-new-tech.png" width="500"/></p>

<h2>如何阅读源码</h2>

<ol>
<li>阅读该技术的架构文档，了解其总体架构和组成</li>
<li>根据总体架构，将源码文件以模块或者上下层级进行分类。</li>
<li>从未阅读过的模块中选择最独立（依赖性最小）的模块代码读起。</li>
<li>阅读此模块的功能介绍文档。</li>
<li>阅读此模块的源代码：<strong>运行程序，断点调试</strong>。</li>
<li>一边阅读一边整理调用关系图。</li>
<li>转到第三步。</li>
</ol>


<blockquote><p>参考<strong>官方文档或者经典书籍</strong></p></blockquote>

<h2>计算机思维</h2>

<ul>
<li><strong>冯.诺依曼体系</strong>：程序存储，顺序执行。</li>
<li><strong>二进制存储</strong>：用比特解决问题</li>
<li><strong>位运算</strong>：位运算的高效</li>
<li><strong>逻辑分支</strong>：条件判断、循环、迭代、递归</li>
</ul>


<h2>个人规划</h2>

<ul>
<li><strong>长期规划</strong>：职业规划；高瞻远瞩</li>
<li><strong>短期规划</strong>：具体技能、晋升、学习方面的规划；优先级排序</li>
</ul>


<h2>基础学科</h2>

<ul>
<li><strong>物理</strong>：电路原理；量子计算机</li>
<li><strong>数学</strong>：工程优化；线性代数；微积分</li>
<li><strong>英语！！</strong>：阅读英文文献；计算机术语</li>
</ul>


<h2>计算机组成原理</h2>

<blockquote><p>计算机的硬件组成和运行原理</p></blockquote>

<ul>
<li><strong>冯诺依曼体系</strong>、<strong>摩尔定律</strong>、<strong>阿曼达定律</strong></li>
<li><strong>数据的机器表示</strong>：原码、补码、反码、浮点数/定点数</li>
<li><strong>指令系统</strong>：复杂指令集、简单指令集</li>
<li><strong>存储器</strong>：分类、缓存</li>
<li><strong>CPU</strong>: 流水线、伪共享、缓存</li>
<li><strong>IO设备</strong>：IO总线、DMA、中断</li>
</ul>


<h2>计算机操作系统</h2>

<blockquote><p>屏蔽计算机硬件的中间层</p></blockquote>

<ul>
<li><strong>作业调度</strong>: 调度策略、优先级</li>
<li><strong>进程管理</strong>：进程和线程、进程间通信</li>
<li><strong>存储管理</strong>：内存、虚拟内存、文件系统、页、页缓存</li>
<li><strong>IO管理</strong>：IO设备读写操作</li>
<li>Linux操作系统</li>
</ul>


<h2>计算机网络</h2>

<blockquote><p>单个计算机之间的互连</p></blockquote>

<ul>
<li><strong>TCP/IP协议栈</strong>：四层/七层</li>
<li>TCP连接状态</li>
<li>TCP与UDP的区别</li>
<li>HTTP协议、RESTful规范</li>
<li>网络安全</li>
<li><strong>下一代互联网</strong>：IPv6、物联网、5G</li>
</ul>


<h2>编译原理</h2>

<blockquote><p>将代码转换成机器可理解的二进制，有助于实现DSL</p></blockquote>

<ul>
<li>词法分析、语法分析</li>
<li>类型检查</li>
<li>运行时环境、中间代码</li>
<li>代码生成、代码优化</li>
</ul>


<h2>数据结构和算法</h2>

<blockquote><p>程序=数据+算法</p></blockquote>

<ul>
<li><strong>基本数据结构</strong>：数组、链表、栈、队列、哈希表</li>
<li><strong>最大堆、最小堆</strong>：TopN问题</li>
<li><strong>树</strong>：平衡二叉树、B树、B+树、红黑树</li>
<li><strong>跳跃表</strong>: 简单可实现</li>
<li><strong>经典排序算法</strong>：快速排序、归并排序、插入排序、冒泡排序</li>
<li><strong>经典查找算法</strong>：顺序查找、二分查找</li>
<li><strong>高级算法</strong>：贪心、分治、回溯、动态规划</li>
<li><strong>大数据处理</strong>：Bitmap、Bloomfilter、Hyperloglog、MapReduce、MPP</li>
</ul>


<h2>设计模式</h2>

<blockquote><p>软件可复用、可扩展、可维护。善用而不滥用。</p></blockquote>

<ul>
<li><strong>面向对象SOLID设计原则</strong>：单一职责、开闭原则、里氏代换、接口隔离、依赖倒转</li>
<li><strong>常用设计模式</strong>：单例模式、工厂模式、代理模式、适配器模式、观察者模式</li>
<li><strong>常用框架中的设计模式</strong>：Spring</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[技术 in Netflix]]></title>
    <link href="http://www.rowkey.me/blog/2019/04/13/netflix/"/>
    <updated>2019-04-13T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2019/04/13/netflix</id>
    <content type="html"><![CDATA[<p>综合市面上的公开资料总结了Netflix在技术上面的一些实践和创新，从中能够得到不少启发和提示。</p>

<p><strong>来自公司内部分享</strong></p>

<!--more-->


<p><img src="http://www.rowkey.me/post_images/netflix/arch-2.jpeg" alt="" />
<img src="http://www.rowkey.me/post_images/netflix/arch-3.jpeg" alt="" />
<img src="http://www.rowkey.me/post_images/netflix/arch-4.jpeg" alt="" />
<img src="http://www.rowkey.me/post_images/netflix/arch-5.jpeg" alt="" />
<img src="http://www.rowkey.me/post_images/netflix/arch-6.jpeg" alt="" />
<img src="http://www.rowkey.me/post_images/netflix/arch-7.jpeg" alt="" />
<img src="http://www.rowkey.me/post_images/netflix/arch-8.jpeg" alt="" />
<img src="http://www.rowkey.me/post_images/netflix/arch-9.jpeg" alt="" />
<img src="http://www.rowkey.me/post_images/netflix/arch-10.jpeg" alt="" />
<img src="http://www.rowkey.me/post_images/netflix/arch-11.jpeg" alt="" />
<img src="http://www.rowkey.me/post_images/netflix/arch-12.jpeg" alt="" />
<img src="http://www.rowkey.me/post_images/netflix/arch-13.jpeg" alt="" />
<img src="http://www.rowkey.me/post_images/netflix/arch-14.jpeg" alt="" />
<img src="http://www.rowkey.me/post_images/netflix/arch-15.jpeg" alt="" />
<img src="http://www.rowkey.me/post_images/netflix/arch-16.jpeg" alt="" />
<img src="http://www.rowkey.me/post_images/netflix/arch-17.jpeg" alt="" />
<img src="http://www.rowkey.me/post_images/netflix/arch-18.jpeg" alt="" />
<img src="http://www.rowkey.me/post_images/netflix/arch-19.jpeg" alt="" />
<img src="http://www.rowkey.me/post_images/netflix/arch-20.jpeg" alt="" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[技术面试的应该与不应该]]></title>
    <link href="http://www.rowkey.me/blog/2019/03/08/interview-basic/"/>
    <updated>2019-03-08T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2019/03/08/interview-basic</id>
    <content type="html"><![CDATA[<p>进入软件开发这个行业差不多10年，做为候选人被面试过，也做为面试官面试过别人。这几年做为后者的角色越来越多，慢慢总结出来了一些技术面试的原则，也是自己在实践的一些原则。</p>

<!--more-->


<h3>Should</h3>

<ul>
<li>让候选人介绍自己拿手的项目或者模块，考察其问题描述能力、沟通能力。</li>
<li>根据简历上写的的项目经验，考察候选人对用过的东西有没有消化、掌握的深度，判断其是否是一个善于思考、主动学习的人。</li>
<li>计算机科学基础知识，考察候选人的计算机基本功，能达到的上限有多高。尤其是对于实习生或者应届生来说是最最重要的一点。社招可以适当放宽要求，但起码要对常用的计算机基础知识有大概的印象。</li>
<li>实际工作中需要的知识，考察候选人能否胜任职位要求的工作。</li>
<li>开放性问题（算法或者实际场景下的问题，是候选人没有接触过或者接触不深的）考察候选人是否聪明，思路是否活跃。</li>
<li>问候选人觉得自己相比其他人的优点是什么，具体的实例。可以基于这个优点出一些题目。从而考察候选人对自己是否有明确的自我认知。</li>
</ul>


<h3>Shouldn&rsquo;t</h3>

<ul>
<li>不要抱着证明自己比候选人强的心理进行面试。包括一直试图找候选人的缺点、问自己拿手的而候选人没有接触过或者接触很浅的点（除非是职位的关键技能点）。面试的目的是看候选人是否能够胜任职位，而不是挑剔候选人。</li>
<li>不要问候选人没有接触过的RTFM问题。这类问题，查阅手册/文档就能知晓，并不是什么核心竞争力。</li>
<li>不要问脑筋急转弯式的问题。</li>
<li>不要太看重面试人已经会的，多看一下候选人的基础素质、学习能力、学习欲望、上进心等决定上限的点。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[缓存这些事]]></title>
    <link href="http://www.rowkey.me/blog/2019/02/25/cache/"/>
    <updated>2019-02-25T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2019/02/25/cache</id>
    <content type="html"><![CDATA[<p><strong>最新版本可见:<a href="https://github.com/superhj1987/pragmatic-java-engineer/blob/master/book/chapter5-datastore/cache.md">https://github.com/superhj1987/pragmatic-java-engineer/blob/master/book/chapter5-datastore/cache.md</a></strong></p>

<p>缓存是为了弥补持久化存储服务如数据库的性能缓慢而出现的一种将数据存储在内存中，从而大大提高应用性能的服务。如缓存五分钟法则所讲：如果一个数据频繁被访问，那么就应该放内存中。这里的缓存就是一种读写效率都非常高的存储方案，能够应对高并发的访问请求，通常情况下也不需要持久化的保证。但相对其他存储来说，缓存一般是基于内存的，成本比较昂贵，因此不能滥用。</p>

<p>缓存可以分为：本地缓存和分布式缓存。</p>

<!--more-->


<h2>本地缓存</h2>

<p>本地缓存指的是内存中的缓存机制，适用于尺寸较小、高频的读取操作、变更操作较少的存储场景。在Java开发中常用的本地缓存实现有：</p>

<ol>
<li><p>ConcurrentHashMap</p>

<p> 这是JDK自带的线程安全map实现，适合用户全局缓存。其get、put的操作比较简单，不用赘述。如果想要实现缓存的失效、淘汰策略则需要自定义实现。</p></li>
<li><p>LinkedHashMap</p>

<p> LinkedHashMap也是JDK的实现。其简单的用途是一个可以保持插入或者访问顺序的HashMap，但其实其配置好是可以当做LRU cache的。这里的LRU即least recently used, 指的是固定容量的缓存，当缓存满的时候，优先淘汰的是最近未被访问的数据。</p>

<pre><code class="`"> int cacheSize = 1000; //最大缓存1000个元素

 LinkedHashMap cache = new LinkedHashMap&lt;String, String&gt;(16, 0.75f, true) {
     @Override
     protected boolean removeEldestEntry(Map.Entry&lt;String, String&gt; eldest) {
         return size() &gt; cacheSize;
     }
 };
</code></pre>

<p> 需要注意的是，LinkedHashMap是非线程安全的，如果是全局使用，需要做并发控制。</p></li>
<li><p>Guava Cache</p>

<p> Guava Cache来自于Google开源的Guava类库中，是一个实现的比较完全的本地缓存，包括缓存失效、LRU都做了支持。</p>

<pre><code class="`"> final int MAX_ENTRIES = 1000; //最大元素数目
 LoadingCache&lt;String, String&gt; cache = CacheBuilder.newBuilder()
     .maximumSize(MAX_ENTRIES)
     .concurrencyLevel(Runtime.getRuntime().availableProcessors())//并行度
     .expireAfterWrite(2, TimeUnit.SECONDS) //写入2秒后失效
     .build(new CacheLoader&lt;String, String&gt;() { 
         @Override
         public String load(String key) throws Exception {
             return ...;//异步加载数据到缓存
         }

         @Override
         public ListenableFuture&lt;String&gt; reload(String key, String oldValue) throws Exception {
             return ...;
         }
     }); 

 //Using the cache
 String value= cache.getUnchecked("testKey");
</code></pre>

<p> 上面的load方法是第一次加载对应的key的缓存时调用的方法,重载此方法可以实现单一线程回源，而reload方法的重载，则可以在后台定时刷新数据的过程中，依然使用旧数据响应请求，不会造成卡顿，这里默认的实现是load方法的代理，是同步的，建议重新用异步方式实现。此外，里面并行度指的是允许并行修改的线程数，此值建议根据当前机器的CPU核数来设置。</p>

<p> 上述的例子中使用了基于maximumSize和基于时间expireAfterWrite的缓存剔除，除此之外，还可以通过：</p>

<ol>
<li><p>基于权重的缓存剔除</p>

<pre><code class="`"> CacheBuilder.newBuilder()
     .maximumWeight(10000)             
     .weigher(new Weigher&lt;String, Object&gt;() {  
         @Override  
         public int weigh(String key, Object value) {  
             return key.length();  
         }  
     })
     .build();
</code></pre>

<p> 这样当cache中put一个key时，都会计算它的weight值并累加，当达到maximumWeight阀值时，会触发剔除操作。</p></li>
<li><p>制定key和value使用的引用类型来做缓存剔除</p>

<pre><code class="`"> CacheBuilder.newBuilder().weakKeys();
 CacheBuilder.newBuilder().weakValues();
 CacheBuilder.newBuilder().softValues();
</code></pre></li>
</ol>


<p> 还需要指明的一点是，Guava Cache中的缓存失效并非立即生效的，通常是延迟的, 在各种写入数据时都去检查并cleanUp。</p>

<p> 此外，Guava Cache还提供了asMap视图，可以获取保存数据使用的ConcurrentMap形式。使用此视图时需要注意读写操作会重置相关缓存项的访问时间，包括asMap().get()方法和Cache.asMap().put()方法，但asMap().containsKey()方法和遍历asMap().entrySet()除外。</p>

<p> 这里还需要提到的一点是，缓存框架Caffeine使用Java8对Guava进行了重写，包括驱逐策略、过期策略和并发机制，使得缓存性能得到了显著提升，并且使用上可以兼容Guava的API。如果是在Java8上的开发，推荐直接使用Caffeine作为本地缓存实现。</p>

<pre><code class="`"> LoadingCache&lt;String, String&gt; cache = CaffeinatedGuava.build(
            Caffeine.newBuilder().maximumSize(MAX_ENTRIES),
            new CacheLoader&lt;String, String&gt;() { // Guava's CacheLoader
                @Override
                public String load(String key) throws Exception {
                    return "";
                }
            });
</code></pre></li>
<li><p>Ehcache</p>

<p> Ehcache是一个纯Java的进程内缓存框架，具有快速、精干等特点，是Hibernate中默认的CacheProvider，使用比较广泛，支持多级存储，可以将数据存储到磁盘上。其最新版本为3.x，但使用不多，且兼容性也不好，推荐使用其2.x版本即可。</p></li>
</ol>


<h2>分布式缓存</h2>

<p>分布式缓存指的是单独的缓存服务，独立部署，通过协议、接口等提供缓存服务。相比起本地缓存，能够支持更大的容量。</p>

<p>几年前最流行的分布式缓存软件是Memcached，但其支持的数据结构太少，现在已经基本被Redis所取代。Redis能够支持丰富的数据结构，基于事件驱动的单线程非阻塞IO也能够应对高并发的业务场景。这里主要针对Redis来讲述，Redis版本为3.2.10。</p>

<p>Redis是非常强大的，既可以作为数据库又可以作为缓存，还能当做队列。总体概括来讲，其有以下用途：</p>

<ol>
<li>最简单的String,可以作为Memcached的替代品，用作缓存系统。</li>
<li>使用SetNx可以实现简单的分布式锁(如果需要对锁设置失效期，建议使用SET key value [EX|PX] NX xx命令以保证原子性),也可参考Redis作者的RedLock算法实现分布式锁（<a href="http://redis.cn/topics/distlock.html%EF%BC%89%E3%80%82">http://redis.cn/topics/distlock.html%EF%BC%89%E3%80%82</a></li>
<li>使用List的pop和push功能可以作为阻塞队列/非阻塞队列。</li>
<li>使用SUBSCRIBE和PUBLISH可以实现发布订阅模型。</li>
<li>对数据进行实时分析，如可以累加统计等。</li>
<li>使用Set做去重的计数统计。</li>
<li>使用SortedSet可以做排行榜等排序场景。</li>
<li>使用getbit、setbit、bitcount做大数据量的去重统计，允许误差的情况下可使用HyperLogLog。</li>
<li>使用GEO可以实现位置定位、附近的人。</li>
</ol>


<p>以上场景基本上涵盖了Redis支持的各种存储结构：</p>

<ul>
<li>Key: 可以是任意类型，但最终都会存储为byte[]。</li>
<li>String: 简单的(key,value)存储结构，支持数据的自增、支持BitSet结构。</li>
<li>Hash：哈希表数据结构，支持对field的自增等操作。</li>
<li>List：列表，支持按照索引、索引范围获取元素以及pop、push等堆栈操作。</li>
<li>Set：集合，去重的列表。</li>
<li>SortedSet：有序集合。</li>
<li>HyperLogLog：可对大数据进行去重，有一定的误差率。</li>
<li>GEO：地理位置的存储结构，支持GEOHASH。</li>
</ul>


<h3>内存压缩</h3>

<p>Redis的存储是以内存为主的，因此如何节省内存是使用的时候一个非常关键的地方。毕竟一个String类型的存储即使key和value是简单的1字节，其占用空间也达到了差不多64字节（估算近似值，包括了dictEntry、redisObject、key、value以及内存对齐等）。</p>

<p>首先，key越短越好，可以采取编码或者简写的方式。如用户的笔记数目缓存key可以使用u:{uid}:n_count作为Key。同时,key的数量也要控制，可以考虑使用hash做二级存储来合并类似的key从而减少key的数量。</p>

<p>其次，value也是越小越好，尤其是存储序列化后的字节时，要选择最节省内存的序列化方式, 如Kryo、Protobuf等。</p>

<p>此外，Redis支持的数据结构的底层实现会对内存使用有很大的影响，如：缓存用户的头像时，可以根据用户ID做分段存储，每一段使用hash结构进行存储:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>//第一段 1-999
</span><span class='line'>hset u:avatar:1 1 http://xxxx
</span><span class='line'>hset u:avatar:1 2 http://xxxx
</span><span class='line'>
</span><span class='line'>//第二段 1000-1999
</span><span class='line'>hset u:avatar:2 1000 http://xxxx
</span><span class='line'>hset u:avatar:2 1999 http://xxxx</span></code></pre></td></tr></table></div></figure>


<p>这样，相比起使用String存储，hash底层会使用ziplist做存储，极大地节省内存使用。但这里需要注意的是Redis有一个hash-max-ziplist-entries的参数，默认是512，如果hash中的field数目超过此值，那么hash将不再使用ziplist存储，开始使用hashtable。但是，此值设置过大，那么在查询的时候就会变慢。从实践来看，此值设置为1000，hash分段大小也为1000，此时的修改和查询性能最佳。此外，还有一个hash-max-ziplist-value参数，默认是64字节，value的最大字符串字节大小如果大于此值，那么则不会使用ziplist。</p>

<p>除了hash之外，其他数据结构也有类似的内存编码变化，使用的时候也需要注意。如下所示：</p>

<table>
<thead>
<tr>
<th>数据结构 </th>
<th> 编码 </th>
<th> 条件</th>
</tr>
</thead>
<tbody>
<tr>
<td>hash</td>
<td> ziplist</td>
<td> 最大value大小 &lt;= hash-max-ziplist-value &amp;&amp; field个数 &lt;= hash-max-ziplist-entries</td>
</tr>
<tr>
<td>hash</td>
<td> hashtable </td>
<td> 最大value大小 > hash-max-ziplist-value || field个数 > hash-max-ziplist-entries</td>
</tr>
<tr>
<td>list</td>
<td> ziplist</td>
<td> 最大value大小 &lt;= list-max-ziplist-value &amp;&amp; field个数 &lt;= list-max-ziplist-entries</td>
</tr>
<tr>
<td>list</td>
<td> linkedlist</td>
<td> 最大value大小 > list-max-ziplist-value || 列表长度 > list-max-ziplist-entries</td>
</tr>
<tr>
<td>set</td>
<td> intset</td>
<td> 元素都为整数 &amp;&amp; 集合长度 &lt;= set-max-intset-entries</td>
</tr>
<tr>
<td>set</td>
<td> hashtable</td>
<td> 元素非整数类型 || 集合长度 > set-max-intset-entries</td>
</tr>
<tr>
<td>sortedSet </td>
<td> ziplist</td>
<td> 最大value大小 &lt;= zset-max-ziplist-value &amp;&amp; 集合长度 &lt;= zset-max-ziplist-entries</td>
</tr>
<tr>
<td>sortedSet </td>
<td> skiplist </td>
<td> 最大value大小 > zset-max-ziplist-value || 集合长度 > zset-max-ziplist-entries</td>
</tr>
</tbody>
</table>


<p>此外，对于list来说，Redis 3.2使用了新的数据结构quicklist来编码实现，废弃了list-max-ziplist-value和list-max-ziplist-entries配置，使用list-max-ziplist-size（负数表示最大占用空间或者正数表示最大压缩长度）和list-compress-depth（最大压缩深度）这俩参数进行配置。</p>

<p>还有一点需要注意的是内存碎片，所谓内存碎片指的是小的非连续的内存，这种内存无法得到充分使用，会造成浪费。我们可以通过info命令获取mem_fragmentation_ratio（used_memory_rss/used_memory）此值来观察内存碎片的程度。</p>

<ul>
<li>此值通常在1左右，越大表示表示存在（内部或外部的）内存碎片。</li>
<li>小于1时表示Redis的部分内存被换出到了交换空间，会降低操作性能。</li>
</ul>


<h3>Redis Lua</h3>

<p>一般情况下，Redis提供的各种操作命令已经能够满足我们的需求。如果需要一次将多个操作请求发送到服务端，可以通过Jedis客户端的pipeline接口批量执行。但如果有以下三种需求，就需要使用Redis Lua：</p>

<ul>
<li>需要保证这些命令做为一个整体的原子性。</li>
<li>这些命令之间有依赖关系、</li>
<li>业务逻辑除了Redis操作还包括其他逻辑运算。</li>
</ul>


<p>Redis从2.6后内置对Lua Script的支持，通过eval或者evalsha执行Lua脚本。其脚本的执行具有原子性，因此适用于秒杀、签到等需要并发互斥且有一些业务逻辑的业务场景。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>String REDIS_SCRIPT_GRAB_GIFT =
</span><span class='line'>            "local giftLeft = tonumber(redis.call('get',KEYS[1])) or 0;" //读取礼物剩余数量
</span><span class='line'>                    + "if(giftLeft &lt;= 0) then return 0; end;" //抢购失败
</span><span class='line'>                    + "redis.call('decr',KEYS[1]);" //减少礼物数量
</span><span class='line'>                    + "return 1;";
</span><span class='line'>
</span><span class='line'>...
</span><span class='line'>Object grabResutl = jedis.eval(REDIS_SCRIPT_GRAB_GIFT, Lists.newArrayList("test:gifts:" + giftId + ":left"),null);
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p>使用Redis Lua需要注意的是：</p>

<ul>
<li>Lua脚本里涉及的所有key尽量用变量，从外面传入，使Redis一开始就知道你要改变哪些key，尤其是在使用redis集群的时候。</li>
<li>建议先用SCRIPT LOAD载入script，返回哈希值。然后用EVALHASH执行脚本，可以节省脚本传输的成本。</li>
<li>如果想从Lua返回一个浮点数，应该将它作为一个字符串（比如ZSCORE命令）。因为Lua中整数和浮点数之间没有什么区别，在返回浮点数据类型时会转换为整数。</li>
</ul>


<h3>数据失效和淘汰</h3>

<p>如果某些数据并不需要永远存在，可以通过Expire设置其失效时间，让其在这段时间后被删除。这里设置了失效时间之后可以通过SET 和 GETSET 命令覆写失效期或者使用PERSIST去掉失效期。需要注意的是如果一个命令只是更新一个带生存时间的 key 的值而不是用一个新的 key 值来代替它的话，那么生存时间不会被改变。如INCR、DECR、LPUSH、HSET等命令就不改变key的失效时间。此外，设置了失效期的key其ttl是大于0的，直至被删除会变为-2, 未设置失效期的key其ttl为-1。</p>

<p>和大部分缓存一样，过期数据并非立即被删除的。在Redis中，其采取的方式如下：</p>

<ul>
<li>消极方法：主动get或set时触发失效删除</li>
<li>积极方法：后台线程周期性（每100ms一次）随机选取100个设置了有效期的key进行失效删除，如果有1/4的key失效，那么立即再选取100个设置了有效期的key进行失效删除。</li>
</ul>


<p>这里需要注意的是当使用主从模式时，删除操作只在Master端做，在Slave端做是无效的。</p>

<p>此外，当对Redis设置了最大内存maxmemory, 那么当内存使用达到maxmemory后，会触发缓存淘汰。Redis支持以下几种淘汰策略：</p>

<ul>
<li>volatile-lru：从已设置过期时间的数据集中挑选最近最少使用的数据淘汰。</li>
<li>volatile-ttl：从已设置过期时间的数据集中挑选将要过期的数据淘汰。</li>
<li>volatile-random：从已设置过期时间的数据集中任意选择数据淘汰。</li>
<li>allkeys-lru：从数据集中挑选最近最少使用的数据淘汰。</li>
<li>allkeys-random：从数据集中任意选择数据淘汰。</li>
<li>noeviction：禁止驱逐数据。</li>
</ul>


<p>其中，volatile-lru是3.0版本之前的默认淘汰策略，之后的版本默认策略改成了noeviction。</p>

<p>为了配合LRU的淘汰策略，Redis的内部数据结构中有一个lru字段记录了对象最后一次被访问的时间。可以通过object idletime [key]来在不更新lru字段的情况下查看相应key的空闲时间。进一步的可以结合使用scan+object idletile [key]来查询哪些健长时间未被访问，以判定热点key和冷key。</p>

<p>这里需要注意的是Redis中为了节省内存占用使用了整数对象池（即共享整数对象），但当淘汰策略为LRU时，由于无法对对象池的同一个对象设置多个访问时间戳，因此不再会使用整数对象池。</p>

<h3>持久化</h3>

<p>Redis支持对内存中的数据进行持久化，包括两种实现方式：</p>

<ol>
<li><p>RDB</p>

<p> RDB是基于二进制快照的持久化方案，其在指定的时间间隔内（默认触发策略是60秒内改了1万次或300秒内改了10次或900秒内改了1次）生成数据集的时间点快照（point-in-time snapshot),从而实现持久化。基于快照的特性，使其会丢失一些数据，比较适用于对Redis的数据进行备份。此外，RDB进行时，Redis会fork()出一个子进程，并由子进程来遍历内存中的所有数据进行持久化。在数据集比较庞大时，由于fork出的子进程需要复制内存中的数据，因此这个过程会非常耗时，会造成服务器停止处理客户端，停止时间可能会长达一秒。</p>

<p> 可配置RDB对数据进行压缩存储，支持字符串的LZF算法和String形式的数字变回int形式。</p></li>
<li><p>AOF</p>

<p> AOF是基于日志的持久化方案，记录服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集。这些命令全部以 Redis 协议的格式来保存（纯文本文件），新命令会被追加到文件的末尾。此外，为了避免AOF的文件体积超出保存数据集状态所需的实际大小，Redis在AOF文件过大时会fork出一个进程对AOF文件进行重写（将历史AOF记录中的命令合并替换成key-value的插入命令）。AOF这种方案，默认是每隔1秒进行一次fsync（将日志写入磁盘），因此与RDB相比，其最多丢失1秒钟的数据，当然如果配置成每次执行写入命令时 fsync（执行命令成功后进行aof，非常慢），甚至可以避免任何数据的丢失。但其文件的体积是明显大于RDB的，将日志刷到磁盘和从AOF恢复数据的过程也是慢于RDB的。</p></li>
</ol>


<p>如果想要保证数据的安全性，建议同时开启AOF和RDB，此时由于RDB有可能丢失文件，Redis重启时会优先使用AOF进行数据恢复。</p>

<p>此外，可以通过save或者bgsave命令来手动触发RDB持久化，通过bgrewriteaof触发aof重写。如此可以将rdb或者aof文件传到另一个Redis结点进行数据迁移。</p>

<p>需要注意的是，如果通过kill -9或者Ctrl+c来关闭redis,那么RDB和AOF都不会触发，会造成数据丢失，建议使用redis-cli shutdown或者kill优雅关闭Redis。</p>

<h3>分布式</h3>

<p>Redis对分布式的支持有三种：</p>

<ol>
<li><p>Master-Slave</p>

<p> 简单的主从模式，通过执行slaveof命令来启动，一旦执行， Slave会清掉自己的所有数据，同时Master会bgsave出一个RDB文件并以Client的方式连接Slave发送写命令给Slave传输数据（多个slave连接时，只要在master的bgsave完成之前，那么就不会多次bgsave）。2.8版本后，Redis提供了PSYNC协议，支持主备间的增量同步，类似于断点续传，不会每次连接Master都全量同步数据。</p>

<p> Redis提供了Redis Sentinel做上述方案的fail-over，能够对 Redis 主从复制进行监控，并实现主挂掉之后的自动故障转移。</p>

<p> 首先，Sentinel会在Master上建一个pub/sub channel，通告各种信息。所有Sentinel通过接收pub/sub channel上的+sentinel的信息发现彼此（Sentinel每5秒会发送一次<strong>sentinel</strong>:hello消息)。然后，Seneinel每秒钟会对所有Master、Slave和其他Sentinel执行ping，这些redis-server会响应+PONG、-LOADING或者-MASTERDOWN告知其存活状态等。如果一台Sentinel在30s中内没有收到Master的应答，会认为Master已经处于SDOWN状态同时会询问其他Sentinel此Master是否SDOWN,如果quonum台Sentinels认为Master已经SDOWN,那么认为Master是真的挂掉（ODOWN），此时会选出一个状态正常且与Master的连接没有断开太久的Slave作为新的Master。</p>

<p> Redis Sentinel提供了notify脚本机制可以接受任何pub/sub消息，以便于发出故障告警等信息；提供了reconfig脚本机制在Slave开始提升成Master、所有Slave都已指向新Master、提升被终止等情况下触发对此类脚本的调用，可以实现一些自定义的配置逻辑。</p></li>
<li><p>Redis Cluster</p>

<p> Redis 3.0后内置的集群方案。此方案没有中心节点的，每一个Redis实例都负责一部分slot（存储一部分key），业务应用需要通过Redis Cluster客户端程序对数据进行操作。客户端可以向任一实例发出请求，如果所需数据不在该实例中，则该实例引导客户端去对应实例读写数据。Redis Cluster的成员管理（节点名称、IP、端口、状态、角色）等，都通过节点之间两两通讯，基于Gossip协议定期交换并更新。是一种比较重的集群方案。</p>

<p> Redis的集群方案除了内置的Redis Cluster之外，很多公司都采用基于代理中间件的思路做了一些实现，Twemproxy、Codis是其中用的比较多的软件。相比起官方的集群方案，其使用方式和单点Redis是一模一样的，原有的业务改动很少（个别命令会不支持），且其数据存储和分布式逻辑是分离的便于扩展和升级。</p></li>
<li><p>客户端分片</p>

<p> 除了上述集群方案之外，在客户端做分片也是一种常用的Redis集群实现方式，不依赖于第三方分布式中间件，实现方法和代码都自己掌控，相比代理方式少了中间环节。但是此方式数据迁移、合并等都不够灵活，建议慎用。Jedis2.0开始就提供了ShardedJedis实现客户端分片，但实际应用并不多见。</p></li>
</ol>


<h3>使用提示</h3>

<h3>Redis数据操作</h3>

<ul>
<li>不同业务共用同一Redis实例时，务必使用前缀来区分各个key，以防止key冲突覆盖。</li>
<li>尽量减少字符串频繁修改操作如append，setrange, 改为直接使用set修改字符串，可以降低预分配带来的内存浪费和内存碎片化。</li>
<li>不要在大数据量线上环境中使用keys命令，很容易造成Redis阻塞。</li>
<li>缓存的失效时间不要集中在同一时刻，会导致缓存占满内存触发内存淘汰（占用CPU）或者直接导致缓存雪崩。</li>
<li>String类型在1KB（Redis官方测试）是一个吞吐量性能拐点，因此String类型的大小以1KB以内为宜（局域网环境下，1KB以内吞吐性能基本一致），最大不超过10KB。</li>
<li>SortedSet中元素的score使用双精度64位浮点数，取值范围为-(2<sup>53</sup>)到+(2<sup>53</sup>)。更大的整数在内部用指数形式表示，因此如果为分数设置一个非常大的整数，其本质是一个近似的十进制数。</li>
<li>尽量使用mset、hmset等做批量操作，以节省网络IO消耗。此外，lpush、rpush、sadd也支持一次输入多个value，同样可以节省网络IO。但需要注意单次请求操作的数量尽量控制在500以内，从而避免慢查询。</li>
<li>使用Redis的事务命令（multi、exec、discard）, 其事务级别类似于Read Committed，即事务无法看到其他事务未提交的改动。还可以使用watch对某一个key做监控，当key对应的值被改变时，事务会被打断，能够达到CAS的效果。但需要注意的是Redis的事务和关系型数据库的事务不同，并非严格的ACID事务，仅仅能达到Isolation。</li>
<li>在Java中使用Jedis的pipeline一次执行多条互相没有依赖关系的命令可以节省网络IO的成本，但pipeline和事务不同，其只是一种批量写批量读的多命令流水线机制，Redis服务器并不保证这些命令的原子性。</li>
<li>可以使用SortedSet做范围查询，如：使用日期作为score,那么就可以根据日期来查询。此外，还可以在范围数据中进行查询，例如：IP定位库的数据一般是某一段IP范围属于哪一个城市,那么可以使用SortedSet存储每一段范围的最小IP和最大IP做为score，城市做为memeber。当给定一个IP时，根据score先找出大于这个IP的最小值，再找出小于这个IP的最大值，如果两者对应的城市相同，即完成定位，否则，无法获取到位置信息。</li>
<li>使用List做队列时，如果需要ack, 可以考虑再使用一个SortedSet，每次队列中pop出一个元素则按照访问时间将其存储到SortedSet中，消费完后进行删除。</li>
<li>控制集合键数据（list、set、zset、hash）的元素个数在5000以内，防止造成大key的查询阻塞其他请求的处理。可以使用zsan、hsan、sscan进行渐进操作或者分拆key来处理。</li>
<li>当无法避免对大集合键数据（元素非常多）进行全量读取时，可以通过搭建多个slave来提升性能，也可以使用Memcached作为Redis前面全量读取的缓存，从而利用MC的多线程实现方式以及对二进制KV的高效读取来获得性能的提升。</li>
<li><p>对大集合键数据的删除避免使用del，会造成Redis阻塞。</p>

<ul>
<li>hash: 通过hscan命令，每次获取一部分字段，再用hdel命令，每次删除1个字段。</li>
<li>list： 使用ltrim命令每次删除少量元素。</li>
<li>set: 使用sscan命令，每次扫描集合中一部分元素，再用srem命令每次删除一个键。</li>
<li>zset: 使用zremrangebyrank命令,每次删除top 100个元素。</li>
</ul>
</li>
<li><p>在Java开发中一般选择直接使用Jedis即可。如果需要诸如分布式锁、主从等分布式特性或者应用层级的Redis操作封装（布隆过滤器、队列），可以选择使用Redisson库来操作Redis。此外，Spring Data Redis也是一种选择，在4.2.2中做过讲述。</p></li>
</ul>


<h3>配置与监控</h3>

<ul>
<li>可以通过monitor命令监测Redis上命令执行的情况。</li>
<li>使用redis-cli &ndash;bigkeys可以扫描出每种数据类型最大的key。</li>
<li>由于Redis自身单线程的原因，切忌慢查询会阻塞住整个Redis, 可以通过slowlog get来查看慢查询日志。</li>
<li>设置Redis最大内存，以防内存用爆。</li>
<li>使用redis-rdb-tools对rdb文件进行分析，如每条key对应value所占的大小，从而做量化分析。</li>
<li>可以使用Redis Sampler，统计Redis中的数据分布情况。</li>
<li>Redis的最大连接数默认为10000（通过命令CONFIG GET maxclients得到），可以在redis.conf配置（maxclients: 10000）。如果还是有限制，需要考虑修改系统的单个进程可打开的最大文件个数（ulimit -n）以及网络的并发连接数。</li>
<li>单点Redis的性能一般能够达到10万QPS左右。</li>
</ul>


<h2>缓存设计</h2>

<p>在使用缓存系统的时候，还需要考虑缓存设计的问题，重点在于缓存失效时的处理和如何更新缓存。</p>

<p>缓存失效是在使用缓存时不得不面对的问题。在业务开发中，缓存失效由于找不到整个数据，一般会出于容错考虑，从存储层再进行查询，如果有则放入缓存。如果查找的数据压根在存储层就不存在，缓存失去意义，还给后端服务带来了巨大的请求压力，会进一步引起雪崩效应。这种现象又称为缓存穿透。</p>

<p>目前常用的解决缓存穿透问题的方案如下：</p>

<ol>
<li>在底层存储系统之上加一层布隆过滤器，将所有可能存在的数据哈希到一个足够大的BitMap中，一个一定不存在的数据会被这个BitMap拦截掉，从而避免了对底层存储系统的查询压力。</li>
<li>如果数据在存储层查询也为空，那么对此空结果也进行缓存，但要设置合适的失效时间。</li>
</ol>


<p>更进一步的，解决缓存穿透的问题其实是和缓存的更新机制是相关的。缓存更新的常用三种模式如下：</p>

<ul>
<li>Cache Aside Pattern: 应用程序以数据库为准，失效则从底层存储更新，更新数据先写入数据库再更新缓存。是最常用的缓存更新模式。</li>
<li>Read/Write Through Pattern: 以缓存为准，应用只读写缓存，但是需要保证数据同步更新到了数据库中。</li>
<li>Write Behind Caching Pattern: 以缓存为准，应用只读写缓存，数据异步更新到数据库，不保证数据正确写回，会丢数据。可以采用Write Ahead Logging等机制避免丢数据。</li>
</ul>


<p>如上，在缓存失效时采用何种策略去更新缓存直接决定了能否解决缓存穿透的问题。Cache Aside Pattern中缓存失效则从底层存储更新无法避免缓存穿透的问题。基于以上三种模式采用下面更为细化的更新机制可以在一定程度上避免缓存穿透的问题：</p>

<ol>
<li>缓存失效时，用加锁或者队列的方式单线程/进程去更更新缓存并等待结果。</li>
<li>缓存失效时，先使用旧值，同时异步（控制为同时只有一个线程/进程）更新缓存，缓存更新失败则抛出异常。</li>
<li>缓存失效时，先使用旧值，同时异步（控制为同时只有一个线程/进程）更新缓存，缓存更新失败延续旧值的有效期。</li>
<li>数据写入或者修改时，更新数据存储后再更新缓存。缓存失效时即认为数据不存在。</li>
<li>数据写入或者修改时，只更新缓存，使用单独线程周期批量刷新缓存到底层存储。缓存失效时即认为数据不存在。此种方案不能保障数据的安全性，有可能会丢数据。</li>
<li>采用单独线程/进程周期将数据从底层存储放到缓存中（MySQL可以基于binlog增量更新缓存）。缓存失效时即认为数据不存在。此种方案无法保证缓存数据和底层存储的数据强一致性。</li>
</ol>


<p>如果一开始设计缓存结构的时候注意切分粒度，把缓存力度划分的细一点，那么缓存命中率相对会越高，也能在一定程度上避免缓存穿透的问题。</p>

<p>此外，还可以在后端做流量控制、服务降级或者动态扩展，以应对缓存穿透带来的访问压力。</p>

<blockquote><p>本文节选自《Java工程师修炼之道》一书。</p></blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[我的2018]]></title>
    <link href="http://www.rowkey.me/blog/2019/01/26/my2018/"/>
    <updated>2019-01-26T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2019/01/26/my2018</id>
    <content type="html"><![CDATA[<p>此文是我在部门内的一次公开信（经过脱敏），想法来自于《原则》和《谷歌是如何运营公司的》两本书。极度求真、 极度透明的原则是一个想要做出大事业的公司应该具有的气度，而对所有同事能够客观地陈述自己的得与失，并欢迎吐槽，这不仅仅是真诚文化、极度透明原则的体现，也是对自己的一种压力和驱动。</p>

<!--more-->


<hr />

<p>hi, 技术平台部的各位同学：</p>

<p>2018年，我们优化升级了我们的大数据基础设施、运维平台以及推荐引擎，保障了业务的稳步前进；进一步发挥了数据分析师的作用，为业务和商业的发展指明了方向；上线了广告DSP平台，加速了公司的商业变现&hellip;虽然期间出现了一些事故，但总体上还是受到了其他部门的一致好评。感谢大家一年的努力，让我们技术平台部发挥了该有的”平台“作用。希望大家在新的一年继续加油，贯彻“平台”理念，为业务发展提供强有力的保障。</p>

<p>之前安排了大家做每个人和每个团队2018年的工作总结和2019年的工作规划。看到大部分人都能认识到过去的一年自己的问题，也能做好新的一年的规划。现在我把自己的总结规划分享给你们，希望能给你们一些启发。当然，如果有我自己没觉察到的我自身存在的问题，欢迎私信给我。</p>

<p>自己今年的工作可以从四个大方面来讲：部门管理、技术委员会、架构、数据挖掘。</p>

<h3>部门管理</h3>

<p>2018年自己有了新的角色定位，需要对公司的整个技术团队负责，这也让18年成为了自己写代码最少的一年，也是让自己决心进行角色转变的一年。虽然之前也在对整个后端团队以及部门（平台事业部->后台技术中心->技术平台部）做管理工作，但对自己来说，很长一段时间心里对管理是排斥的，尤其是当管理杂事越来越多，写代码的时间越来越少。自己的性格也是属于偏情绪化的，很多时候会让潜意识占了上风，说一些错误的话，发一些没必要发的脾气。在之前的管理工作中，自己意识到管理的并不好，一直还处于研发工程师的角色上。这在18年开始自己就进行了刻意的改变，试着跳出工程师思维，多从团队整体考虑问题，多从对方角度看待问题。具体的事情包括：</p>

<ul>
<li>优化月度考核机制，强调考核的具体原则以及从团队角度进行评估的视角。最终形成了主管和员工两条线、优秀员工投票选举、优秀主管负责人指定的月度考核机制。</li>
<li>加强一对一沟通，建立反馈问题的模式。</li>
<li>确立部门月会&amp;&amp;Leader周会的会议机制。</li>
<li>建立部门的操作手册让流程公开透明，提高做事效率。</li>
<li>带领大家学习并切实的开始实践OKR。建立部门的OKR流程，做到季度末部门月度会议复盘上一季度OKR、制定下一季度OKR。</li>
<li>强调“件件有着落，事事有回音”的团队文化，旨在解决很多人对交待的任务不主动响应、不主动汇报进度的非职业素养问题。</li>
</ul>


<p>此外，年初新业务的突击上线自己担任了项目管理和架构师的角色，后续自己也花了一些时间协助业务部门定位排查故障。日常的简历筛选、面试也占用不少时间和精力。</p>

<p>在年度考核中，看到同事们对自己的一些意见，基本都符合我的自我认知，也是在管理方面自己需要改进的：</p>

<ul>
<li>说服力：有些时候会比较急，语气比较强烈，因此会让人有抵触的情绪，需要进一步提高自己的沟通技巧和说服力。此外，有时候并没有了解事情的来龙去脉就下结论，这个需要竭力避免自己的主观臆断。</li>
<li>应变能力：转变为管理角色后，需要培养自己之前很抵触的审时度势、待人处事灵活的特质。</li>
<li>激励团队：目前对团队的激励的方式包括团队聚餐、项目奖励、月度奖励、技术书籍奖励等，并没有其他更加有效的激励措施。这一点需要改进，多想一些赋能方式来激励团队。</li>
<li>协作：和说服力那一点一样，在协作时有时候会太急，用职权影响力或者情绪化来影响结果。这个都是自己没有很好转变角色的问题。</li>
<li>高估团队：这个的本质问题还是观念改变，需要自己认识到目前团队成员的状况，对不同的人采取不同的领导策略，不能全部是放养状态，做好辅导和问题预估的协助。</li>
</ul>


<h3>技术委员会</h3>

<p>公司的技术委员会已经成立了三年，其一开始是为了评选“技术创新奖励”，后来随着公司的组织架构调整为按照业务为单位的敏捷式组织，技术委员会的横向管理职责越来越大。2018年限于业务迭代压力的问题，技术委员会的运行并没有走上正轨，但也做出了一些产出：</p>

<ul>
<li>确立了技术分享机制，大前端和后端都进行了系列分享。</li>
<li>制定了各个研发职位的能力模型，让技术团队成员都能够对自己的职业发展有清晰的认识。</li>
<li>完善了研发职位的学习计划，给入门的工程师提供学习指导。</li>
<li>制定了事故制度和研发高压线，规范事故处理流程，明确不可触碰的高压线。</li>
<li>制定技术选型原则，给技术团队做技术选型的指导。</li>
<li>制定实习生培养制度，规范化实习生转正流程。</li>
<li>进行“Hold住前后端系列分享”，提高资深以上工程师整体技术把控能力</li>
<li>带领各个技术Leader做了《技术管理实战三十六讲》的学习和沟通，解惑了很多程序员在转型管理时候面对的问题，让大家对“管理”有了更明确的认知。</li>
<li>例行的技术周刊、技术创新奖励继续得到有效执行。</li>
</ul>


<h3>架构</h3>

<p>架构方面，产出了一些公共组件和规范：</p>

<ul>
<li>制定了技术评审机制，强调对容器、中间件的容量预估和限流，从架构设计开始尽量规避性能故障。</li>
<li>梳理架构隐患分析流程，强调对架构的隐患分析和预防。</li>
<li>梳理系统稳定性原则，给系统设计时的稳定性予以指导。</li>
<li>制定架构设计文档模板：技术调研、技术方案分析、系统设计，规范系统设计流程。</li>
<li>研发公共组件：antares分布式调度中心。</li>
</ul>


<p>由于业务增长给后端带来了很大压力，在年底筹划并成立了架构组，由各个后端Leader组成，是一个虚拟的横向组织。其主要负责公司的架构规范梳理和制定以及公共组件/中间件的开发。目前基本上囊括了自己进入公司以来做的一些公共组件开发和架构规范工作，最近也产出了公共组件搜索平台供研发人员使用。</p>

<p>此外，为了进一步提高各个Leader的架构能力，给大家购买了极客时间《从0开始学架构》课程并组织了学习讨论会，在去年进行过一次架构学习的基础上再一次让大家讨论了对架构的认识和理解。并且做了《浅析区块链》、《后端基础设施》、《架构设计与原则》、《如何排查在线故障》的分享，提高大家的架构、故障排查等能力。</p>

<h3>数据挖掘</h3>

<p>数据挖掘这一方面，由于客观原因，自己一直在跟进。年初给自己定的目标是成为一个合格的机器学习调参工程师，能够熟知、理解和实现常用的机器学习算法。这一年也一直在看《机器学习》西瓜书、《机器学习实战》两本书。不过由于各种杂事以及架构工作的干扰，进度一直很慢。虽然最终阅读完了《机器学习实战》这本书，也实现了大部分算法，但数据挖掘有了更加合适的人来做具体工作，基本能Hold住目前的需求，自己也没有那么多时间专注这一块，在权衡了收益之后（把精力放在架构上给团队带来的收益会更大），最后决定放弃。毕竟，数据挖掘这一块入门需要花大量的时间来补充大量知识。如果没有那么多的时间专注做这件事情，入门都难，更难谈熟悉和精通。</p>

<p>所以，这一年参与了很小一部分推荐系统的开发工作，大部分是在担任推荐引擎的项目管理工作。本年度推荐系统最大的一个改进是做了架构的升级，引入了召回+CTR预估的推荐机制，合理划分了推荐引擎的分层架构。</p>

<h3>学习</h3>

<p>学习方面，平时会零零散散看一些微信和博客上的文章，并把其中自己觉得受到启发的点经过验证后纳入到自己的知识体系文档中。此外，自己今年包括在线课程一共学习了14本书/课程。如下：</p>

<ul>
<li><p>OKR: 源于英特尔和谷歌的目标管理利器</p>

<blockquote><p>此书是公司管理层进行统一学习的一本书，不厚，花了三个晚上大约6个小时就读完了。主要是对OKR这种目标管理方法的入门指导。不同于绩效的，OKR强调的是自驱力和挑战性，并不用来考核，是为了识别高绩效员工。O表示Objective，KR表示Key result。把周期内的事务分解为一个个目标，再把完成这个目标的衡量标准分解为一个个关键结果。周期结束复盘关键结果的完成度，也就相当于复盘了目标的完成度。</p></blockquote></li>
<li><p>尽在双11，阿里巴巴技术演进与超越</p>

<blockquote><p>此书讲述的是阿里巴巴为了支撑双十一技术上的一些演化。包括大数据平台、机器学习平台、数据中间件、容量规划、全链路压测、系统稳定性保障、流控方案、协同运维、移动端混合开发等技术。能够看到架构和技术是随着业务的发展而不断演进的，能够给我们这种小公司一个未来技术规划的路线图。</p></blockquote></li>
<li><p>深入分布式缓存</p>

<blockquote><p>集结各大公司技术网红的一本主要讲分布式缓存的书籍。包括缓存和分布式理论、Ehcache和Guava Cache本地缓存框架、Memcached、Redis、Tair、Evcache、Aerospike等集中式缓存，并讲述了这些技术在各大公司的实际应用案例。对自己最有启发的是此书对CAP的讲解，发现自己之前对这个理论的理解貌似有点偏差，就把相关的英文论文又看了几遍。此外，有一章讲述社交场景架构进化，虽然个别指标数字的来源比较模糊也没有说明，但是从数据库到缓存的设计和演进思路确实让我眼前一亮，比如通过前缀+保序压缩设计主键来使用覆盖索引。还值得一提的是在这里第一次看到了Aerospike在广告场景的使用，这个现在已经在我们公司的广告平台进行了实践并取得了较好的效果。</p></blockquote></li>
<li><p>增长黑客</p>

<blockquote><p>一本前几年非常火的书。也是这本书把“增长黑客”的概念引入国内。讲述了什么是增长黑客、增长在做什么、如何做增长等内容。由于工作中与增长并不密切相关，因此感触并不多。算是自己在增长方面的一个入门读物。</p></blockquote></li>
<li><p>Microservices AntiPatterns and Pitfalls</p>

<blockquote><p>微服务的反模式和陷阱。是O’Reilly的免费电子书，主要讲述了在做微服务设计和实现的时候经常会做错的一些事情。强烈推荐想要做微服务的同学看一下此书。我自己的翻译见：<a href="http://www.rowkey.me/blog/2018/06/02/microservice-pitfall/">http://www.rowkey.me/blog/2018/06/02/microservice-pitfall/</a>。</p></blockquote></li>
<li><p>Reactive Microservices Architecture</p>

<blockquote><p>响应式微服务架构-分布式系统设计原则。同样是O’Reilly的免费电子书，主要讲述了在做微服务设计的时候需要遵循的原则。结合上面的微服务的反模式和陷阱，能够更好地认识、设计和实现微服务。我自己的翻译见：<a href="http://www.rowkey.me/blog/2018/06/07/reactive-microservice/">http://www.rowkey.me/blog/2018/06/07/reactive-microservice/</a></p></blockquote></li>
<li><p>进化-运维技术变革与实践探索</p>

<blockquote><p>来自极客时间相关课程的一个书籍。主要讲述了运维技术的演进和实践。其中让我自己印象比较深的，一个地方是其讲述的架构师负责设计架构，运维则是负责管理架构；另一个地方是美丽说实践的一个办公室测试环境（小蘑菇环境），这个我们公司后来也进行了实践和推行。此外，这本书给出的事故定则维度和研发高压线也给了自己一些启发，进一步出台了公司的相关制度。</p></blockquote></li>
<li><p>推荐系统三十六计</p>

<blockquote><p>极客时间的一个课程。讲述的业界推荐系统主流的一些做法，包括各种召回策略/算法、融合排序方案、EE问题解决方案等，基本能够解决推荐系统80%的问题。此书给了自己不少启发，后续公司的推荐引擎的架构升级和团队规划的想法就来源于此。</p></blockquote></li>
<li><p>码农翻身</p>

<blockquote><p>花了差不多四个晚上大约4个小时阅读完此书。全书基本都是些基础知识，收获有一点（巩固了一些自己之前似是而非的点，比如Java动态代理为什么不能代理没有实现接口的类），但确实不太多。不过这种用故事讲技术的方式的确让自己有了一些启发，很多时候能够把技术和现实联系起来，既能够加深自己的理解，也能够更容易给别人讲明白。而最后作者给出的程序员需要<strong>克服内向心里，凡事必先上虎背</strong>，这个自己非常认同，人很多时候不逼自己一把是不知道自己有多少实力的。</p></blockquote></li>
<li><p>原则</p>

<blockquote><p>今年非常火的一本书，是桥水的创始人对自己生活以及工作的原则所做的总结。其中最让我印象深刻也注意后续实践的包括：头脑极度开放、极度求真和极度透明。第一点让自己突破了心里的一个坎，认识到人都有自我意识和思维盲点，会经常审视自己是否不敢接受自己在某些方面的欠缺，是否能够以开放的心态聆听别人的意见和看法，讨论问题时是否是抱着解决问题而不是论证自己的观点的态度。后面两点在公司里其实很难实现，但一旦实现，换来的是全员的目标一致、利益一致，随之而来的会是高效地产出。这个也是后续自己要在部门坚定推行的一种文化。此外，也注意到在评估一个工作业绩不突出的同事时要区分是其能力（包括学习能力）不够还是经验不够。经验不够可以学习弥补，但如果是能力不够则需要考虑淘汰。</p></blockquote></li>
<li><p>从0开始学架构</p>

<blockquote><p>来自极客时间的专栏课程，是对架构的一个入门讲解。其中的很多知识点都印证了自己之前的一些总结和实践。让自己受用的主要是其提供的几个架构设计文档模板：技术方案设计、技术方案评估和选择、详细方案设计。</p></blockquote></li>
<li><p>技术管理实战36讲</p>

<blockquote><p>同样是来自极客时间的专栏课程，给公司的所有技术Leader都购买并进行了学习讨论。主要就是解惑技术转管理面对的那些问题。如技术人的职业后期的方向有哪些？技术人适合做管理吗？管理到底做什么？管理能够成为自己的立身之本吗？其阐述的管理就是“看方向”、“带人”、“做事”，非常接地气的阐述了管理的职责。从公司几个技术Leader的反应来看，都觉得很受启发，尤其是角色认知这方面。相比起其他管理方法论，这个更加联系实际，更加干货。其讲述的团队规划方案、驱动力3.0等后来也运用在了实际工作中。</p></blockquote></li>
<li><p>机器学习实战</p>

<blockquote><p>这本书是入门机器学习的经典书籍之一，结合代码和原理讲解常用的机器学习算法。基本涵盖了机器学习常用的分类、预测、聚类、频繁项发现等算法。结合《机器学习》西瓜书，理论+实践，是入门机器学习的推荐方式。</p></blockquote></li>
<li><p>重新定义公司：谷歌是如何运营的</p>

<blockquote><p>这本书是在去参加年会的路上看完的，也就3个小时左右。主要讲述了Google特色的运营公司的方法。当然，Google能那么做并不代表你也可以这么做，毕竟人才的素养差距有点大。其中让自己感到受用的有两方面：会议的决策者应该亲力亲为，从通知议程、会议召开、保证质量、设立目标、确定与会人员到会议纪要都要亲自执行；要做好职业规划，想象自己五年后希望的职业，那个职位的JD是什么样子的，要求如何?并对照看自己的优势/劣势在哪，怎么去改进。</p></blockquote></li>
</ul>


<p>以上书籍/课程的学习笔记我都放在了Github(<a href="https://github.com/superhj1987/ToDo/issues/1">https://github.com/superhj1987/ToDo/issues/1</a>)上，通过issue的方式串联起来，确实提高了记录笔记的速度和学习的有效性。不过最近发现使用幕布（<a href="https://mubu.com">https://mubu.com</a>）这个软件思维导图的方式更加合适做学习笔记，也正在转移到这上面。当然，像marginnote则是更为强大的阅读笔记软件，感兴趣的可以使用。这里要再强调一下的是做读书笔记的重要性，之前有朋友特别喜欢购买书籍，书架上全是，咋看之下，绝对是啥都懂的超级大神，但其实大部分书都没有翻过，翻过的也基本看完就放在那里了。这样如果看书不注意记录笔记和学习心得并纳入到自己的知识体系中，效果是大打折扣的，尤其是当这本书的知识点和你实际的工作联系并不紧密时，很快你就会就把这本书讲的东西给忘了。我一直以来的做法是看书的过程会通过拍照、文字等形式记录笔记，并在完成阅读后，再概览一遍书的目录，把其中觉得有用的点都纳入到我的知识体系文档中。这样即使后来由于不经常使用而淡忘了也能够快速定位到相关的知识点。</p>

<p>18年也有一些计划的书并没有完成阅读，都纳入到了19年的学习计划中。目前计划的读书列表如下：</p>

<ul>
<li>Clean Architecture</li>
<li>分布式系统概念与设计</li>
<li>复杂</li>
<li>清教徒的礼物</li>
</ul>


<h3>工作之外</h3>

<p>工作之外，自己把2015年就有初步构想的书给出了，最近也收到了编辑寄来的2018年度优秀作者的奖杯。由于书的类型还算新颖，所以结果还不错，但自己其实挺遗憾的。出版前review了很多次，还是在出版后发现了不少错误，甚至一些自己怎么都想不明白为何会犯的错误。这也警醒了自己，不管东西多大多小，只要是输出的东西，务必保证准确性，不求能帮助所有人，但一定也不至于误导别人。与之关联的，自己也一直跟公司的技术团队强调，对于市面上的资料一定要学会甄别，国内的文章、书籍很多都是不可靠的，很多知识点都是copy来copy去，并没有经过作者亲自求证。如果要学习知识，最好的资料就是官方文档，之后是相关的英文书籍或者其权威翻译版本。毕竟，总是去看别人嚼过的知识，那么也就意味着你一直在follow别人，而无法获取技术的第一手资料，也就无法站在技术的前沿。计算机领域绝大多数第一手资料都是英文的，这造成了很多人觉得难以阅读而去看各种中文资料。一个外国朋友更是表达了他对中国技术人员的一个直观的印象就是英文不好，从来不看英文文档或者看的不够仔细，直接导致对技术的运用会有很大的偏差。他说的的确是中国大部分程序员的现状，但我真心不希望我们的技术团队是这样的一个团队，希望大家能够多强迫自己阅读并理解各种英文文档、英文书籍，久了自然而然就会越来越顺手，理解起来也就会越来越容易。</p>

<p>个人生活方面，最主要的还是一直以来的入睡困难、睡眠质量差的问题在困扰自己，导致自己很晚才能入睡，进一步导致自己无法早起，也就让自己失去了很多可以学习工作的时间，想想会觉得很难受。曾经想过很多办法，都效果不大。从8月份开始决定通过健身来彻底改变这些问题，最近也开始注意饮食，希望不久能够从根本上解决这个困扰自己多年的问题，给自己带来更多的学习、生活、工作时间。这里也想跟大家强调一下身体的重要性，任何东西都是以身体为基础的，身体如果不能够健健康康，那么其他的都无从谈起，所以一定要注意锻炼身体从而保证充足的活力和健康。此外，虽然公司给咱们买了保险，还是建议大家都给自己补充一些商业保险，这个其实也是理财的一种形式，用不上最好，一旦用上真的是解决大问题。</p>

<h3>总结</h3>

<p>以上是自己对2018的工作生活的总结，对照18年初的计划基本都达成了，自己大体也是满意的。对于其中各个方面的不足，新的一年也会采取措施来改善。对于2019年的规划，大体如下：</p>

<ol>
<li>加强技术委员会的横向管理作用，全面提升各个技术方向的研发实力。</li>
<li>采取更多更有效的方式提升各个技术Leader的技术管理以及架构能力。</li>
<li>把控架构组的日常工作和组件研发。</li>
<li>做好蜂巢推荐引擎的进一步推进工作，争取能够有突破性的进展。</li>
<li>完善各个团队的梯队建设。</li>
<li>进一步明确自己的角色定位，改善自己的沟通能力和管理能力。</li>
<li>每周做至少2-3道leetcode medium题目，保持自己的编程感觉。</li>
<li>改善自己的睡眠问题和身体状况，提高自己的活力，能够有更多的时间在工作、学习和生活上。</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Kotlin语法简明指南]]></title>
    <link href="http://www.rowkey.me/blog/2018/12/08/kotlin-notes/"/>
    <updated>2018-12-08T11:29:34+00:00</updated>
    <id>http://www.rowkey.me/blog/2018/12/08/kotlin-notes</id>
    <content type="html"><![CDATA[<p>Kotlin是Intellij IDEA的发明团队JetBrains带来的新一代JVM语言。虽然JVM上一次又一次出现新的语言叫嚣着取代Java，但时至今日，Java也开始吸纳其他语言的各种优势，其生命力依旧强盛，生态也越发强大。那么Kotlin的出现是又一次重蹈覆辙还是有其突破性的特性？</p>

<p>本文对其语法作了简要概括。</p>

<!--more-->


<p><strong>Kotlin版本：1.3.11</strong></p>

<ol>
<li><p>包的定义</p>

<p> 与Java类似，但包的定义与目录结构无需匹配，源代码可以在文件系统任意位置。</p>

<p> 与Java有一点不同，导入包的时候，可以使用import as实现重命名来解决名字冲突的问题。如：</p>

<pre><code class="`"> import me.rowkey.MainClass as aClass // aClass 代表“me.rowkey.MainClass”
</code></pre></li>
<li><p>没有类型的Java</p>

<p> 虽然Kotlin是静态语言，但其引入的安全类型推断让其无须声明类型。使用val/var即可，其中val定义只读变量，var定义可变变量。</p>

<pre><code class="`"> var str1 : String = "a" //有初始值，可以省略类型
 val str2 : String //无初始值，不能省略类型
 str2 = "b"
 var str = "i can change"
 val immutableStr = "i cannot change"
</code></pre></li>
<li><p>不需要的public</p>

<p> Kotlin中默认的可见性修饰符是public，所以public修饰符不需要写。其他修饰符如下：</p>

<ul>
<li>private：只在类内部/声明文件内部可见。</li>
<li>protected：private+子类中可见。</li>
<li>internal: 同一模块（编译在一起的一套Kotlin文件）可见。</li>
</ul>
</li>
<li><p>函数定义</p>

<p> 用fun关键字声明函数</p>

<pre><code class="`"> fun main(args: Array&lt;String&gt;) {
  ...
 }
</code></pre>

<p> 其中，函数参数使用 Pascal 表示法定义，即 name: type。参数用逗号隔开。每个参数必须有显式类型。</p>

<p> Kotlin中还能够直接通过表达式做为函数体来定义函数。</p>

<pre><code class="`"> fun sum(a : Int, b : Int) = a + b
</code></pre>

<p> Kotlin中的函数和Java中的方法是一致的，但与Java不同的是，Kotlin中的函数可以属于任何类，文件当中直接定义则作为“包级函数”，和类的使用方式一致</p></li>
<li><p>默认参数值</p>

<p> 函数的参数可以指定默认值。</p>

<pre><code class="`"> fun getList(list: Array&lt;String&gt;, offset: Int = 0, size: Int = list.size) { …… }
</code></pre>

<p> 不指定第2个参数调用方法时，offset参数取默认值0, size参数默认取第一个参数的size。</p></li>
<li><p>可变参数</p>

<p> 函数的参数（通常是最后一个）可以用 vararg 修饰符标记：</p>

<pre><code class="`"> fun printIntArray(vararg input: Int) {
     for (i in input) {
         println(i)
     }
 }
</code></pre></li>
<li><p>不需要的语句结束符</p>

<p> Kotlin中没有语句结束符，当然为了与java保持一致性，也可以使用;号作为语句结束符。</p></li>
<li><p>字符串连接符</p>

<p> 跟java一样，如果你需要把一个字符串写在多行里，可以使用+号连接字符串。代码可以这样写：</p>

<pre><code>val str = "hello" + "world" + "!!!";
</code></pre>

<p> Kotlin中的写法也可以这样：</p>

<pre><code class="`"> val str = """hello
 world
 !!!
 """
</code></pre>

<p> 三个”号之间不在需要+号进行连接，不过字符串中的格式符都会被保留，包括回车和tab。</p></li>
<li><p>字符串模板</p>

<p> Kotlin提供了$符来做字符串内的变量替换，并且可以做一些字符串操作。如下：</p>

<pre><code class="`"> var name = "hj"
 var strTemplate = "My name is $name"//My name is hj

 strTemplate = "My name is ${name.replace("j","a")}"// My name is ha
</code></pre></li>
<li><p>一切皆对象</p>

<p> Kotlin中一切皆对象。即使赋值为基本数据类型，也会自动转换为对应的类。</p></li>
<li><p>if条件表达式</p>

<p> Kotlin中支持if条件表达式。</p>

<pre><code class="`">val a = if(x &gt; 0) 1 else 2
fun maxOf(a: Int, b: Int) = if (a &gt; b) a else b
</code></pre></li>
<li><p>循环</p>

<p> Kotlin的while循环和Java没什么不同, 在for循环引入了区间的概念。</p>

<pre><code class="`"> for(i in 1..10){
     println(i)
 }

 for(i in 1..10 step 2){
     println(i)
 }

 for(i in 10 downTo 1 step 1){
     println(i)
 }

 for (i in 1 until 10) {
     // i in [1, 10) 排除了 10
     println(i)
 }

 for(c in 'A'..'Z'){
     println(c)
 }
</code></pre>

<p> 需要注意的是在Kotlin中不再支持Java的for循环形式：</p>

<pre><code class="`"> for(int i =0;i &lt; 10;i++){
     ...
 }
</code></pre></li>
<li><p>when</p>

<p>  Kotlin中没有switch。提供when做分支条件选择。</p>

<pre><code class="``">  when (x) {
     1 -&gt; print("x == 1")
     2 -&gt; print("x == 2")
     3, 4 -&gt; print("x == 3 or x == 4")
     in 10..99999 -&gt; print("x &gt; 10")
     else -&gt; { // 注意这个块
         print("x is neither 1 nor 2")
     }
 }

 when {
     x.isOdd() -&gt; print("x is odd")
     x.isEven() -&gt; print("x is even")
     else -&gt; print("x is funny")
  }
</code></pre>

<p>   when 既可以被当做表达式使用也可以被当做语句使用。如果它被当做表达式， 符合条件的分支的值就是整个表达式的值，如果当做语句使用， 则忽略个别分支的值。</p></li>
<li><p>操作符重载</p>

<p> Kotlin提供了操作符重载的支持。对于常用的”+“、&#8221;-&ldquo;等操作符，创建带有operator且名称符合要求的方法，即可实现。如：</p>

<pre><code class="`"> data class Point(val x: Int, val y: Int)

 operator fun Point.unaryMinus() = Point(-x, -y)

 val point = Point(10, 20)

 fun main() {
     println(-point)  // 输出“Point(x=-10, y=-20)”
 }
</code></pre>

<p> 上面即完成了对-的重载。</p></li>
<li><p>集合</p>

<p>Kotlin把集合分为可变集合和不可变集合。其创建需要通过标准库的方法：listOf()、 mutableListOf()、 setOf()、 mutableSetOf()、hashMapOf()、mutableHashMapOf()</p>

<pre><code>val list = listOf("1","2","3",""4)
val set = setOf("1","2")
val map = hashMapOf("name" to "hj","sex" to "male")
</code></pre>

<p>这些集合类实现了操作符重载，如下：</p>

<pre><code>val list1 = list - listOf("1","2")
val list2 = list + "2"
println(list1[0])

val map = hashMapOf("name" to "hj","sex" to "male")
val map1 = map + ("name2" to "hah") //{"name":"hj","name2":"ha","sex":"male"}
val map2 = map - "name"//{"sex":"male"}
println(map2)
</code></pre>

<p>Map的遍历如下：</p>

<pre><code>for ((k, v) in map) {
    println("$k -&gt; $v")
}
</code></pre>

<p>Kotlin中的集合具有类似Java中的Stream的操作如filter、map、foreach等。</p>

<pre><code>val positives = list.filter { x -&gt; x &gt; 0 }
//val positives = list.filter { it &gt; 0 }
</code></pre></li>
<li><p>Elvis操作符</p>

<p> 三目运算符通常以这种形式出现：</p>

<pre><code class="`"> String displayName = name != null ? name : "Unknown";
</code></pre>

<p> Kotlin中可以简化为：</p>

<pre><code class="`"> val displayName = name ?: "Unknown";
</code></pre></li>
<li><p>可空/非可空引用/函数返回值</p>

<p> Kotlin中区分一个引用可以容纳null和不能容纳null。默认的引用是不可空的。</p>

<pre><code class="`"> var a = "abc"
 a = null // 编译错误    ```
</code></pre>

<p> 需要使用?使其变为可空引用。</p>

<pre><code class="`"> var b : String ? = "abc"
 b = null
</code></pre>

<p> 如此，后续如果你调用a的任何方法都可以，但是调用b的会有编译错误。会强制去检查b是否为空</p>

<pre><code class="`"> val l = if (b != null) b.length else -1
</code></pre>

<p> 也可以使用?做安全调用</p>

<pre><code class="`"> b?.length()
</code></pre>

<p> b不为空才会执行后续的操作。配合let可以执行其他非自身的操作。</p>

<pre><code class="`"> b?.let{
     print("a")
 )
</code></pre>

<p> 同样的，对于函数参数以及返回值，默认也是非空的，只有加了?才允许传控制且要求做空值检测。</p>

<pre><code class="`"> fun parseInt(str: String?): Int? {
     // ……
     if(str == null){
         return null
     }

     ...
     return ..
 }

 val r = parseInt(null)
 r?.let{
     print r
 }
</code></pre></li>
<li><p>try with resources</p>

<pre><code class="`"> val stream = Files.newInputStream(Paths.get("/some/file.txt"))
 stream.buffered().reader().use { reader -&gt;
     println(reader.readText())
 }
</code></pre></li>
<li><p>延迟属性</p>

<p> Kotlin提供了延迟属性的支持，即只有在你第一次开始使用的时候才会真正初始化。默认使用同步锁保证只有一个线程初始化。下面例子改成了不使用同步锁，可以多线程执行。</p>

<pre><code class="`"> val p by lazy(LazyThreadSafetyMode.PUBLICATION) {
     println("computed!")
     "Hello"
 }
 println(p)
</code></pre></li>
<li><p>类</p>

<ul>
<li>无须public修饰符。文件名和类也没有任何关联。</li>
<li><p>创建对象不需要使用new关键字</p>

<pre><code class="``">  val test = Test()
</code></pre></li>
<li><p>对于类属性，默认会有get()和set()两个方法。直接访问属性或者给属性设置值都会调用这两个方法。</p>

<pre><code class="``">  class Test {
      var counter = 0 // 注意：这个初始器直接为幕后字段赋值
      get() {
          println("getter")
          return field
      }
      set(value) {
          println("setter")
          field = value
      }


  }

  val test = Test()
  test.counter = 10
  println(test.counter)
</code></pre></li>
<li><p>主构造函数和次构造函数。Kotlin中一个类可以有一个主构造函数以及一个或多个次构造函数。主构造函数是类头的一部分：它跟在类名（与可选的类型参数）后。主构造函数里的参数如果用val或者var修饰则成为类的属性。如果类有一个主构造函数，每个次构造函数需要委托给主构造函数。主构造函数不能包含任何的代码。初始化的代码可以放到以 init 关键字作为前缀的初始化块（即时没有主构造函数，也会在次构造函数前执行）。</p>

<pre><code class="``">  class Test(val counter: Int, val name: String = "test") {

      init{

      }

      constructor(counter: Int, name: String, sex: String) : this(counter, name) {

      }

  }

  val test = Test(10)
  println(test.counter)
</code></pre></li>
<li><p>Kotlin中引入了解构函数来对对象进行解构。</p>

<pre><code class="``">  class Test(val counter: Int, val name: String = "test") {

      operator fun component1() : Int{
          return counter
      }

      operator fun component2() : String{
          return name
      }

  }

  val (counter,name) = Test(10)
</code></pre>

<p>  如此，也和map一样可以用在集合迭代中。</p>

<pre><code class="``">  val testList = listOf(Test(1),Test(2))
  for((k,v) in testList){
      ...
  }
</code></pre></li>
<li><p>Kotlin中引入了数据类的概念。对于此种类，会默认根据主构造函数的属性生成equals()/hashCode()、toString()、componentN()、copy()这几个函数。</p>

<pre><code class="``">  data class User(val name: String, val age: Int)
</code></pre></li>
<li><p>Kotlin中提供了对象声明来实现单例模式。</p>

<pre><code class="``">  object SingleInstance {
      fun test(input: String) = println(input)
  }

  fun main(args: Array&lt;String&gt;) {
      SingleInstance.test("hj")
  }
</code></pre></li>
<li><p>Kotlin中提供了密封类来表示受限的类继承结构：当一个值为有限集中的类型、而不能有任何其他类型时。可以看做是枚举类的扩展。密封类需要在类名前面添加 sealed 修饰符。其所有子类都必须在与密封类自身相同的文件中声明。</p>

<pre><code class="``">  sealed class DataType
  data class Card(val number: Double) :DataType()
  data class Timeline(val e1: DataType, val e2: DataType) : DataType()
  object Illegal : DataType()
</code></pre></li>
<li><p>Kotlin的类中引入了伴生对象来声明静态方法、属性以及编译期常量（也可以在object中定义）。</p>

<pre><code class="``">  class Test(val counter: Int, val name: String = "test") {

      companion object {
          const val TYPE = 1
              val title = "haha"

              fun testStatic(){
              println("static method")
          }
  }
</code></pre></li>
<li><p>对一个对象调用多个方法。</p>

<pre><code class="``">  class Test(val counter : Int){
      fun test1(){

      }

      fun test2(){

      }
  }


  val test = Test(1)
  with(test){
      test1()
      test2()
  }
</code></pre></li>
</ul>
</li>
</ol>


<p>以上为Kotlin中的基本语法说明，其他诸如委托、lambda函数、协程、与Java互操作等可见<a href="https://www.kotlincn.net/docs/reference/">https://www.kotlincn.net/docs/reference/</a>。</p>
]]></content>
  </entry>
  
</feed>
