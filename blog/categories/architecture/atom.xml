<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: architecture | 后端技术杂谈 | 飒然Hang]]></title>
  <link href="http://www.rowkey.me/blog/categories/architecture/atom.xml" rel="self"/>
  <link href="http://www.rowkey.me/"/>
  <updated>2019-03-06T10:24:55+08:00</updated>
  <id>http://www.rowkey.me/</id>
  <author>
    <name><![CDATA[飒然Hang]]></name>
    <email><![CDATA[superhj1987@126.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[缓存这些事]]></title>
    <link href="http://www.rowkey.me/blog/2019/02/25/cache/"/>
    <updated>2019-02-25T19:29:34+08:00</updated>
    <id>http://www.rowkey.me/blog/2019/02/25/cache</id>
    <content type="html"><![CDATA[<p>缓存是为了弥补持久化存储服务如数据库的性能缓慢而出现的一种将数据存储在内存中，从而大大提高应用性能的服务。如缓存五分钟法则所讲：如果一个数据频繁被访问，那么就应该放内存中。这里的缓存就是一种读写效率都非常高的存储方案，能够应对高并发的访问请求，通常情况下也不需要持久化的保证。但相对其他存储来说，缓存一般是基于内存的，成本比较昂贵，因此不能滥用。</p>

<p>缓存可以分为：本地缓存和分布式缓存。</p>

<!--more-->


<h2>本地缓存</h2>

<p>本地缓存指的是内存中的缓存机制，适用于尺寸较小、高频的读取操作、变更操作较少的存储场景。在Java开发中常用的本地缓存实现有：</p>

<ol>
<li><p>ConcurrentHashMap</p>

<p> 这是JDK自带的线程安全map实现，适合用户全局缓存。其get、put的操作比较简单，不用赘述。如果想要实现缓存的失效、淘汰策略则需要自定义实现。</p></li>
<li><p>LinkedHashMap</p>

<p> LinkedHashMap也是JDK的实现。其简单的用途是一个可以保持插入或者访问顺序的HashMap，但其实其配置好是可以当做LRU cache的。这里的LRU即least recently used, 指的是固定容量的缓存，当缓存满的时候，优先淘汰的是最近未被访问的数据。</p>

<pre><code class="`"> int cacheSize = 1000; //最大缓存1000个元素

 LinkedHashMap cache = new LinkedHashMap&lt;String, String&gt;(16, 0.75f, true) {
     @Override
     protected boolean removeEldestEntry(Map.Entry&lt;String, String&gt; eldest) {
         return size() &gt; cacheSize;
     }
 };
</code></pre>

<p> 需要注意的是，LinkedHashMap是非线程安全的，如果是全局使用，需要做并发控制。</p></li>
<li><p>Guava Cache</p>

<p> Guava Cache来自于Google开源的Guava类库中，是一个实现的比较完全的本地缓存，包括缓存失效、LRU都做了支持。</p>

<pre><code class="`"> final int MAX_ENTRIES = 1000; //最大元素数目
 LoadingCache&lt;String, String&gt; cache = CacheBuilder.newBuilder()
     .maximumSize(MAX_ENTRIES)
     .concurrencyLevel(Runtime.getRuntime().availableProcessors())//并行度
     .expireAfterWrite(2, TimeUnit.SECONDS) //写入2秒后失效
     .build(new CacheLoader&lt;String, String&gt;() { 
         @Override
         public String load(String key) throws Exception {
             return ...;//异步加载数据到缓存
         }

         @Override
         public ListenableFuture&lt;String&gt; reload(String key, String oldValue) throws Exception {
             return ...;
         }
     }); 

 //Using the cache
 String value= cache.getUnchecked("testKey");
</code></pre>

<p> 上面的load方法是第一次加载对应的key的缓存时调用的方法,重载此方法可以实现单一线程回源，而reload方法的重载，则可以在后台定时刷新数据的过程中，依然使用旧数据响应请求，不会造成卡顿，这里默认的实现是load方法的代理，是同步的，建议重新用异步方式实现。此外，里面并行度指的是允许并行修改的线程数，此值建议根据当前机器的CPU核数来设置。</p>

<p> 上述的例子中使用了基于maximumSize和基于时间expireAfterWrite的缓存剔除，除此之外，还可以通过：</p>

<ol>
<li><p>基于权重的缓存剔除</p>

<pre><code class="`"> CacheBuilder.newBuilder()
     .maximumWeight(10000)             
     .weigher(new Weigher&lt;String, Object&gt;() {  
         @Override  
         public int weigh(String key, Object value) {  
             return key.length();  
         }  
     })
     .build();
</code></pre>

<p> 这样当cache中put一个key时，都会计算它的weight值并累加，当达到maximumWeight阀值时，会触发剔除操作。</p></li>
<li><p>制定key和value使用的引用类型来做缓存剔除</p>

<pre><code class="`"> CacheBuilder.newBuilder().weakKeys();
 CacheBuilder.newBuilder().weakValues();
 CacheBuilder.newBuilder().softValues();
</code></pre></li>
</ol>


<p> 还需要指明的一点是，Guava Cache中的缓存失效并非立即生效的，通常是延迟的, 在各种写入数据时都去检查并cleanUp。</p>

<p> 此外，Guava Cache还提供了asMap视图，可以获取保存数据使用的ConcurrentMap形式。使用此视图时需要注意读写操作会重置相关缓存项的访问时间，包括asMap().get()方法和Cache.asMap().put()方法，但asMap().containsKey()方法和遍历asMap().entrySet()除外。</p>

<p> 这里还需要提到的一点是，缓存框架Caffeine使用Java8对Guava进行了重写，包括驱逐策略、过期策略和并发机制，使得缓存性能得到了显著提升，并且使用上可以兼容Guava的API。如果是在Java8上的开发，推荐直接使用Caffeine作为本地缓存实现。</p>

<pre><code class="`"> LoadingCache&lt;String, String&gt; cache = CaffeinatedGuava.build(
            Caffeine.newBuilder().maximumSize(MAX_ENTRIES),
            new CacheLoader&lt;String, String&gt;() { // Guava's CacheLoader
                @Override
                public String load(String key) throws Exception {
                    return "";
                }
            });
</code></pre></li>
<li><p>Ehcache</p>

<p> Ehcache是一个纯Java的进程内缓存框架，具有快速、精干等特点，是Hibernate中默认的CacheProvider，使用比较广泛，支持多级存储，可以将数据存储到磁盘上。其最新版本为3.x，但使用不多，且兼容性也不好，推荐使用其2.x版本即可。</p></li>
</ol>


<h2>分布式缓存</h2>

<p>分布式缓存指的是单独的缓存服务，独立部署，通过协议、接口等提供缓存服务。相比起本地缓存，能够支持更大的容量。</p>

<p>几年前最流行的分布式缓存软件是Memcached，但其支持的数据结构太少，现在已经基本被Redis所取代。Redis能够支持丰富的数据结构，基于事件驱动的单线程非阻塞IO也能够应对高并发的业务场景。这里主要针对Redis来讲述，Redis版本为3.2.10。</p>

<p>Redis是非常强大的，既可以作为数据库又可以作为缓存，还能当做队列。总体概括来讲，其有以下用途：</p>

<ol>
<li>最简单的String,可以作为Memcached的替代品，用作缓存系统。</li>
<li>使用SetNx可以实现简单的分布式锁(如果需要对锁设置失效期，建议使用SET key value [EX|PX] NX xx命令以保证原子性),也可参考Redis作者的RedLock算法实现分布式锁（<a href="http://redis.cn/topics/distlock.html%EF%BC%89%E3%80%82">http://redis.cn/topics/distlock.html%EF%BC%89%E3%80%82</a></li>
<li>使用List的pop和push功能可以作为阻塞队列/非阻塞队列。</li>
<li>使用SUBSCRIBE和PUBLISH可以实现发布订阅模型。</li>
<li>对数据进行实时分析，如可以累加统计等。</li>
<li>使用Set做去重的计数统计。</li>
<li>使用SortedSet可以做排行榜等排序场景。</li>
<li>使用getbit、setbit、bitcount做大数据量的去重统计，允许误差的情况下可使用HyperLogLog。</li>
<li>使用GEO可以实现位置定位、附近的人。</li>
</ol>


<p>以上场景基本上涵盖了Redis支持的各种存储结构：</p>

<ul>
<li>Key: 可以是任意类型，但最终都会存储为byte[]。</li>
<li>String: 简单的(key,value)存储结构，支持数据的自增、支持BitSet结构。</li>
<li>Hash：哈希表数据结构，支持对field的自增等操作。</li>
<li>List：列表，支持按照索引、索引范围获取元素以及pop、push等堆栈操作。</li>
<li>Set：集合，去重的列表。</li>
<li>SortedSet：有序集合。</li>
<li>HyperLogLog：可对大数据进行去重，有一定的误差率。</li>
<li>GEO：地理位置的存储结构，支持GEOHASH。</li>
</ul>


<h3>内存压缩</h3>

<p>Redis的存储是以内存为主的，因此如何节省内存是使用的时候一个非常关键的地方。毕竟一个String类型的存储即使key和value是简单的1字节，其占用空间也达到了差不多64字节（估算近似值，包括了dictEntry、redisObject、key、value以及内存对齐等）。</p>

<p>首先，key越短越好，可以采取编码或者简写的方式。如用户的笔记数目缓存key可以使用u:{uid}:n_count作为Key。同时,key的数量也要控制，可以考虑使用hash做二级存储来合并类似的key从而减少key的数量。</p>

<p>其次，value也是越小越好，尤其是存储序列化后的字节时，要选择最节省内存的序列化方式, 如Kryo、Protobuf等。</p>

<p>此外，Redis支持的数据结构的底层实现会对内存使用有很大的影响，如：缓存用户的头像时，可以根据用户ID做分段存储，每一段使用hash结构进行存储:</p>

<pre><code>//第一段 1-999
hset u:avatar:1 1 http://xxxx
hset u:avatar:1 2 http://xxxx

//第二段 1000-1999
hset u:avatar:2 1000 http://xxxx
hset u:avatar:2 1999 http://xxxx
</code></pre>

<p>这样，相比起使用String存储，hash底层会使用ziplist做存储，极大地节省内存使用。但这里需要注意的是Redis有一个hash-max-ziplist-entries的参数，默认是512，如果hash中的field数目超过此值，那么hash将不再使用ziplist存储，开始使用hashtable。但是，此值设置过大，那么在查询的时候就会变慢。从实践来看，此值设置为1000，hash分段大小也为1000，此时的修改和查询性能最佳。此外，还有一个hash-max-ziplist-value参数，默认是64字节，value的最大字符串字节大小如果大于此值，那么则不会使用ziplist。</p>

<p>除了hash之外，其他数据结构也有类似的内存编码变化，使用的时候也需要注意。如下所示：</p>

<table>
<thead>
<tr>
<th>数据结构 </th>
<th> 编码 </th>
<th> 条件</th>
</tr>
</thead>
<tbody>
<tr>
<td>hash</td>
<td> ziplist</td>
<td> 最大value大小 &lt;= hash-max-ziplist-value &amp;&amp; field个数 &lt;= hash-max-ziplist-entries</td>
</tr>
<tr>
<td>hash</td>
<td> hashtable </td>
<td> 最大value大小 > hash-max-ziplist-value || field个数 > hash-max-ziplist-entries</td>
</tr>
<tr>
<td>list</td>
<td> ziplist</td>
<td> 最大value大小 &lt;= list-max-ziplist-value &amp;&amp; field个数 &lt;= list-max-ziplist-entries</td>
</tr>
<tr>
<td>list</td>
<td> linkedlist</td>
<td> 最大value大小 > list-max-ziplist-value || 列表长度 > list-max-ziplist-entries</td>
</tr>
<tr>
<td>set</td>
<td> intset</td>
<td> 元素都为整数 &amp;&amp; 集合长度 &lt;= set-max-intset-entries</td>
</tr>
<tr>
<td>set</td>
<td> hashtable</td>
<td> 元素非整数类型 || 集合长度 > set-max-intset-entries</td>
</tr>
<tr>
<td>sortedSet </td>
<td> ziplist</td>
<td> 最大value大小 &lt;= zset-max-ziplist-value &amp;&amp; 集合长度 &lt;= zset-max-ziplist-entries</td>
</tr>
<tr>
<td>sortedSet </td>
<td> skiplist </td>
<td> 最大value大小 > zset-max-ziplist-value || 集合长度 > zset-max-ziplist-entries</td>
</tr>
</tbody>
</table>


<p>此外，对于list来说，Redis 3.2使用了新的数据结构quicklist来编码实现，废弃了list-max-ziplist-value和list-max-ziplist-entries配置，使用list-max-ziplist-size（负数表示最大占用空间或者正数表示最大压缩长度）和list-compress-depth（最大压缩深度）这俩参数进行配置。</p>

<p>还有一点需要注意的是内存碎片，所谓内存碎片指的是小的非连续的内存，这种内存无法得到充分使用，会造成浪费。我们可以通过info命令获取mem_fragmentation_ratio（used_memory_rss/used_memory）此值来观察内存碎片的程度。</p>

<ul>
<li>此值通常在1左右，越大表示表示存在（内部或外部的）内存碎片。</li>
<li>小于1时表示Redis的部分内存被换出到了交换空间，会降低操作性能。</li>
</ul>


<h3>Redis Lua</h3>

<p>一般情况下，Redis提供的各种操作命令已经能够满足我们的需求。如果需要一次将多个操作请求发送到服务端，可以通过Jedis客户端的pipeline接口批量执行。但如果有以下三种需求，就需要使用Redis Lua：</p>

<ul>
<li>需要保证这些命令做为一个整体的原子性。</li>
<li>这些命令之间有依赖关系、</li>
<li>业务逻辑除了Redis操作还包括其他逻辑运算。</li>
</ul>


<p>Redis从2.6后内置对Lua Script的支持，通过eval或者evalsha执行Lua脚本。其脚本的执行具有原子性，因此适用于秒杀、签到等需要并发互斥且有一些业务逻辑的业务场景。</p>

<pre><code>String REDIS_SCRIPT_GRAB_GIFT =
            "local giftLeft = tonumber(redis.call('get',KEYS[1])) or 0;" //读取礼物剩余数量
                    + "if(giftLeft &lt;= 0) then return 0; end;" //抢购失败
                    + "redis.call('decr',KEYS[1]);" //减少礼物数量
                    + "return 1;";

...
Object grabResutl = jedis.eval(REDIS_SCRIPT_GRAB_GIFT, Lists.newArrayList("test:gifts:" + giftId + ":left"),null);
...
</code></pre>

<p>使用Redis Lua需要注意的是：</p>

<ul>
<li>Lua脚本里涉及的所有key尽量用变量，从外面传入，使Redis一开始就知道你要改变哪些key，尤其是在使用redis集群的时候。</li>
<li>建议先用SCRIPT LOAD载入script，返回哈希值。然后用EVALHASH执行脚本，可以节省脚本传输的成本。</li>
<li>如果想从Lua返回一个浮点数，应该将它作为一个字符串（比如ZSCORE命令）。因为Lua中整数和浮点数之间没有什么区别，在返回浮点数据类型时会转换为整数。</li>
</ul>


<h3>数据失效和淘汰</h3>

<p>如果某些数据并不需要永远存在，可以通过Expire设置其失效时间，让其在这段时间后被删除。这里设置了失效时间之后可以通过SET 和 GETSET 命令覆写失效期或者使用PERSIST去掉失效期。需要注意的是如果一个命令只是更新一个带生存时间的 key 的值而不是用一个新的 key 值来代替它的话，那么生存时间不会被改变。如INCR、DECR、LPUSH、HSET等命令就不改变key的失效时间。此外，设置了失效期的key其ttl是大于0的，直至被删除会变为-2, 未设置失效期的key其ttl为-1。</p>

<p>和大部分缓存一样，过期数据并非立即被删除的。在Redis中，其采取的方式如下：</p>

<ul>
<li>消极方法：主动get或set时触发失效删除</li>
<li>积极方法：后台线程周期性（每100ms一次）随机选取100个设置了有效期的key进行失效删除，如果有1/4的key失效，那么立即再选取100个设置了有效期的key进行失效删除。</li>
</ul>


<p>这里需要注意的是当使用主从模式时，删除操作只在Master端做，在Slave端做是无效的。</p>

<p>此外，当对Redis设置了最大内存maxmemory, 那么当内存使用达到maxmemory后，会触发缓存淘汰。Redis支持以下几种淘汰策略：</p>

<ul>
<li>volatile-lru：从已设置过期时间的数据集中挑选最近最少使用的数据淘汰。</li>
<li>volatile-ttl：从已设置过期时间的数据集中挑选将要过期的数据淘汰。</li>
<li>volatile-random：从已设置过期时间的数据集中任意选择数据淘汰。</li>
<li>allkeys-lru：从数据集中挑选最近最少使用的数据淘汰。</li>
<li>allkeys-random：从数据集中任意选择数据淘汰。</li>
<li>noeviction：禁止驱逐数据。</li>
</ul>


<p>其中，volatile-lru是3.0版本之前的默认淘汰策略，之后的版本默认策略改成了noeviction。</p>

<p>为了配合LRU的淘汰策略，Redis的内部数据结构中有一个lru字段记录了对象最后一次被访问的时间。可以通过object idletime [key]来在不更新lru字段的情况下查看相应key的空闲时间。进一步的可以结合使用scan+object idletile [key]来查询哪些健长时间未被访问，以判定热点key和冷key。</p>

<p>这里需要注意的是Redis中为了节省内存占用使用了整数对象池（即共享整数对象），但当淘汰策略为LRU时，由于无法对对象池的同一个对象设置多个访问时间戳，因此不再会使用整数对象池。</p>

<h3>持久化</h3>

<p>Redis支持对内存中的数据进行持久化，包括两种实现方式：</p>

<ol>
<li><p>RDB</p>

<p> RDB是基于二进制快照的持久化方案，其在指定的时间间隔内（默认触发策略是60秒内改了1万次或300秒内改了10次或900秒内改了1次）生成数据集的时间点快照（point-in-time snapshot),从而实现持久化。基于快照的特性，使其会丢失一些数据，比较适用于对Redis的数据进行备份。此外，RDB进行时，Redis会fork()出一个子进程，并由子进程来遍历内存中的所有数据进行持久化。在数据集比较庞大时，由于fork出的子进程需要复制内存中的数据，因此这个过程会非常耗时，会造成服务器停止处理客户端，停止时间可能会长达一秒。</p>

<p> 可配置RDB对数据进行压缩存储，支持字符串的LZF算法和String形式的数字变回int形式。</p></li>
<li><p>AOF</p>

<p> AOF是基于日志的持久化方案，记录服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集。这些命令全部以 Redis 协议的格式来保存（纯文本文件），新命令会被追加到文件的末尾。此外，为了避免AOF的文件体积超出保存数据集状态所需的实际大小，Redis在AOF文件过大时会fork出一个进程对AOF文件进行重写（将历史AOF记录中的命令合并替换成key-value的插入命令）。AOF这种方案，默认是每隔1秒进行一次fsync（将日志写入磁盘），因此与RDB相比，其最多丢失1秒钟的数据，当然如果配置成每次执行写入命令时 fsync（执行命令成功后进行aof，非常慢），甚至可以避免任何数据的丢失。但其文件的体积是明显大于RDB的，将日志刷到磁盘和从AOF恢复数据的过程也是慢于RDB的。</p></li>
</ol>


<p>如果想要保证数据的安全性，建议同时开启AOF和RDB，此时由于RDB有可能丢失文件，Redis重启时会优先使用AOF进行数据恢复。</p>

<p>此外，可以通过save或者bgsave命令来手动触发RDB持久化，通过bgrewriteaof触发aof重写。如此可以将rdb或者aof文件传到另一个Redis结点进行数据迁移。</p>

<p>需要注意的是，如果通过kill -9或者Ctrl+c来关闭redis,那么RDB和AOF都不会触发，会造成数据丢失，建议使用redis-cli shutdown或者kill优雅关闭Redis。</p>

<h3>分布式</h3>

<p>Redis对分布式的支持有三种：</p>

<ol>
<li><p>Master-Slave</p>

<p> 简单的主从模式，通过执行slaveof命令来启动，一旦执行， Slave会清掉自己的所有数据，同时Master会bgsave出一个RDB文件并以Client的方式连接Slave发送写命令给Slave传输数据（多个slave连接时，只要在master的bgsave完成之前，那么就不会多次bgsave）。2.8版本后，Redis提供了PSYNC协议，支持主备间的增量同步，类似于断点续传，不会每次连接Master都全量同步数据。</p>

<p> Redis提供了Redis Sentinel做上述方案的fail-over，能够对 Redis 主从复制进行监控，并实现主挂掉之后的自动故障转移。</p>

<p> 首先，Sentinel会在Master上建一个pub/sub channel，通告各种信息。所有Sentinel通过接收pub/sub channel上的+sentinel的信息发现彼此（Sentinel每5秒会发送一次<strong>sentinel</strong>:hello消息)。然后，Seneinel每秒钟会对所有Master、Slave和其他Sentinel执行ping，这些redis-server会响应+PONG、-LOADING或者-MASTERDOWN告知其存活状态等。如果一台Sentinel在30s中内没有收到Master的应答，会认为Master已经处于SDOWN状态同时会询问其他Sentinel此Master是否SDOWN,如果quonum台Sentinels认为Master已经SDOWN,那么认为Master是真的挂掉（ODOWN），此时会选出一个状态正常且与Master的连接没有断开太久的Slave作为新的Master。</p>

<p> Redis Sentinel提供了notify脚本机制可以接受任何pub/sub消息，以便于发出故障告警等信息；提供了reconfig脚本机制在Slave开始提升成Master、所有Slave都已指向新Master、提升被终止等情况下触发对此类脚本的调用，可以实现一些自定义的配置逻辑。</p></li>
<li><p>Redis Cluster</p>

<p> Redis 3.0后内置的集群方案。此方案没有中心节点的，每一个Redis实例都负责一部分slot（存储一部分key），业务应用需要通过Redis Cluster客户端程序对数据进行操作。客户端可以向任一实例发出请求，如果所需数据不在该实例中，则该实例引导客户端去对应实例读写数据。Redis Cluster的成员管理（节点名称、IP、端口、状态、角色）等，都通过节点之间两两通讯，基于Gossip协议定期交换并更新。是一种比较重的集群方案。</p>

<p> Redis的集群方案除了内置的Redis Cluster之外，很多公司都采用基于代理中间件的思路做了一些实现，Twemproxy、Codis是其中用的比较多的软件。相比起官方的集群方案，其使用方式和单点Redis是一模一样的，原有的业务改动很少（个别命令会不支持），且其数据存储和分布式逻辑是分离的便于扩展和升级。</p></li>
<li><p>客户端分片</p>

<p> 除了上述集群方案之外，在客户端做分片也是一种常用的Redis集群实现方式，不依赖于第三方分布式中间件，实现方法和代码都自己掌控，相比代理方式少了中间环节。但是此方式数据迁移、合并等都不够灵活，建议慎用。Jedis2.0开始就提供了ShardedJedis实现客户端分片，但实际应用并不多见。</p></li>
</ol>


<h3>使用提示</h3>

<h3>Redis数据操作</h3>

<ul>
<li>不同业务共用同一Redis实例时，务必使用前缀来区分各个key，以防止key冲突覆盖。</li>
<li>尽量减少字符串频繁修改操作如append，setrange, 改为直接使用set修改字符串，可以降低预分配带来的内存浪费和内存碎片化。</li>
<li>不要在大数据量线上环境中使用keys命令，很容易造成Redis阻塞。</li>
<li>缓存的失效时间不要集中在同一时刻，会导致缓存占满内存触发内存淘汰（占用CPU）或者直接导致缓存雪崩。</li>
<li>String类型在1KB（Redis官方测试）是一个吞吐量性能拐点，因此String类型的大小以1KB以内为宜（局域网环境下，1KB以内吞吐性能基本一致），最大不超过10KB。</li>
<li>SortedSet中元素的score使用双精度64位浮点数，取值范围为-(2<sup>53</sup>)到+(2<sup>53</sup>)。更大的整数在内部用指数形式表示，因此如果为分数设置一个非常大的整数，其本质是一个近似的十进制数。</li>
<li>尽量使用mset、hmset等做批量操作，以节省网络IO消耗。此外，lpush、rpush、sadd也支持一次输入多个value，同样可以节省网络IO。但需要注意单次请求操作的数量尽量控制在500以内，从而避免慢查询。</li>
<li>使用Redis的事务命令（multi、exec、discard）, 其事务级别类似于Read Committed，即事务无法看到其他事务未提交的改动。还可以使用watch对某一个key做监控，当key对应的值被改变时，事务会被打断，能够达到CAS的效果。但需要注意的是Redis的事务和关系型数据库的事务不同，并非严格的ACID事务，仅仅能达到Isolation。</li>
<li>在Java中使用Jedis的pipeline一次执行多条互相没有依赖关系的命令可以节省网络IO的成本，但pipeline和事务不同，其只是一种批量写批量读的多命令流水线机制，Redis服务器并不保证这些命令的原子性。</li>
<li>可以使用SortedSet做范围查询，如：使用日期作为score,那么就可以根据日期来查询。此外，还可以在范围数据中进行查询，例如：IP定位库的数据一般是某一段IP范围属于哪一个城市,那么可以使用SortedSet存储每一段范围的最小IP和最大IP做为score，城市做为memeber。当给定一个IP时，根据score先找出大于这个IP的最小值，再找出小于这个IP的最大值，如果两者对应的城市相同，即完成定位，否则，无法获取到位置信息。</li>
<li>使用List做队列时，如果需要ack, 可以考虑再使用一个SortedSet，每次队列中pop出一个元素则按照访问时间将其存储到SortedSet中，消费完后进行删除。</li>
<li>控制集合键数据（list、set、zset、hash）的元素个数在5000以内，防止造成大key的查询阻塞其他请求的处理。可以使用zsan、hsan、sscan进行渐进操作或者分拆key来处理。</li>
<li>当无法避免对大集合键数据（元素非常多）进行全量读取时，可以通过搭建多个slave来提升性能，也可以使用Memcached作为Redis前面全量读取的缓存，从而利用MC的多线程实现方式以及对二进制KV的高效读取来获得性能的提升。</li>
<li><p>对大集合键数据的删除避免使用del，会造成Redis阻塞。</p>

<ul>
<li>hash: 通过hscan命令，每次获取一部分字段，再用hdel命令，每次删除1个字段。</li>
<li>list： 使用ltrim命令每次删除少量元素。</li>
<li>set: 使用sscan命令，每次扫描集合中一部分元素，再用srem命令每次删除一个键。</li>
<li>zset: 使用zremrangebyrank命令,每次删除top 100个元素。</li>
</ul>
</li>
<li><p>在Java开发中一般选择直接使用Jedis即可。如果需要诸如分布式锁、主从等分布式特性或者应用层级的Redis操作封装（布隆过滤器、队列），可以选择使用Redisson库来操作Redis。此外，Spring Data Redis也是一种选择，在4.2.2中做过讲述。</p></li>
</ul>


<h3>配置与监控</h3>

<ul>
<li>可以通过monitor命令监测Redis上命令执行的情况。</li>
<li>使用redis-cli &ndash;bigkeys可以扫描出每种数据类型最大的key。</li>
<li>由于Redis自身单线程的原因，切忌慢查询会阻塞住整个Redis, 可以通过slowlog get来查看慢查询日志。</li>
<li>设置Redis最大内存，以防内存用爆。</li>
<li>使用redis-rdb-tools对rdb文件进行分析，如每条key对应value所占的大小，从而做量化分析。</li>
<li>可以使用Redis Sampler，统计Redis中的数据分布情况。</li>
<li>Redis的最大连接数默认为10000（通过命令CONFIG GET maxclients得到），可以在redis.conf配置（maxclients: 10000）。如果还是有限制，需要考虑修改系统的单个进程可打开的最大文件个数（ulimit -n）以及网络的并发连接数。</li>
<li>单点Redis的性能一般能够达到10万QPS左右。</li>
</ul>


<h2>缓存设计</h2>

<p>在使用缓存系统的时候，还需要考虑缓存设计的问题，重点在于缓存失效时的处理和如何更新缓存。</p>

<p>缓存失效是在使用缓存时不得不面对的问题。在业务开发中，缓存失效由于找不到整个数据，一般会出于容错考虑，从存储层再进行查询，如果有则放入缓存。如果查找的数据压根在存储层就不存在，缓存失去意义，还给后端服务带来了巨大的请求压力，会进一步引起雪崩效应。这种现象又称为缓存穿透。</p>

<p>目前常用的解决缓存穿透问题的方案如下：</p>

<ol>
<li>在底层存储系统之上加一层布隆过滤器，将所有可能存在的数据哈希到一个足够大的BitMap中，一个一定不存在的数据会被这个BitMap拦截掉，从而避免了对底层存储系统的查询压力。</li>
<li>如果数据在存储层查询也为空，那么对此空结果也进行缓存，但要设置合适的失效时间。</li>
</ol>


<p>更进一步的，解决缓存穿透的问题其实是和缓存的更新机制是相关的。缓存更新的常用三种模式如下：</p>

<ul>
<li>Cache Aside Pattern: 应用程序以数据库为准，失效则从底层存储更新，更新数据先写入数据库再更新缓存。是最常用的缓存更新模式。</li>
<li>Read/Write Through Pattern: 以缓存为准，应用只读写缓存，但是需要保证数据同步更新到了数据库中。</li>
<li>Write Behind Caching Pattern: 以缓存为准，应用只读写缓存，数据异步更新到数据库，不保证数据正确写回，会丢数据。可以采用Write Ahead Logging等机制避免丢数据。</li>
</ul>


<p>如上，在缓存失效时采用何种策略去更新缓存直接决定了能否解决缓存穿透的问题。Cache Aside Pattern中缓存失效则从底层存储更新无法避免缓存穿透的问题。基于以上三种模式采用下面更为细化的更新机制可以在一定程度上避免缓存穿透的问题：</p>

<ol>
<li>缓存失效时，用加锁或者队列的方式单线程/进程去更更新缓存并等待结果。</li>
<li>缓存失效时，先使用旧值，同时异步（控制为同时只有一个线程/进程）更新缓存，缓存更新失败则抛出异常。</li>
<li>缓存失效时，先使用旧值，同时异步（控制为同时只有一个线程/进程）更新缓存，缓存更新失败延续旧值的有效期。</li>
<li>数据写入或者修改时，更新数据存储后再更新缓存。缓存失效时即认为数据不存在。</li>
<li>数据写入或者修改时，只更新缓存，使用单独线程周期批量刷新缓存到底层存储。缓存失效时即认为数据不存在。此种方案不能保障数据的安全性，有可能会丢数据。</li>
<li>采用单独线程/进程周期将数据从底层存储放到缓存中（MySQL可以基于binlog增量更新缓存）。缓存失效时即认为数据不存在。此种方案无法保证缓存数据和底层存储的数据强一致性。</li>
</ol>


<p>如果一开始设计缓存结构的时候注意切分粒度，把缓存力度划分的细一点，那么缓存命中率相对会越高，也能在一定程度上避免缓存穿透的问题。</p>

<p>此外，还可以在后端做流量控制、服务降级或者动态扩展，以应对缓存穿透带来的访问压力。</p>

<blockquote><p>本文节选自《Java工程师修炼之道》一书。</p></blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何应对在线故障]]></title>
    <link href="http://www.rowkey.me/blog/2018/11/22/online-debug/"/>
    <updated>2018-11-22T22:29:34+08:00</updated>
    <id>http://www.rowkey.me/blog/2018/11/22/online-debug</id>
    <content type="html"><![CDATA[<p>线上运行的Java应用突然没有响应、响应缓慢，进程突然消失，遇到这些情况应该如何应对呢？</p>

<p><strong>来自公司内部分享</strong></p>

<!--more-->


<p><img src="//post_images/debug/arch-2.jpeg" alt="" />
<img src="//post_images/debug/arch-3.jpeg" alt="" />
<img src="//post_images/debug/arch-4.jpeg" alt="" />
<img src="//post_images/debug/arch-5.jpeg" alt="" />
<img src="//post_images/debug/arch-6.jpeg" alt="" />
<img src="//post_images/debug/arch-7.jpeg" alt="" />
<img src="//post_images/debug/arch-8.jpeg" alt="" />
<img src="//post_images/debug/arch-9.jpeg" alt="" />
<img src="//post_images/debug/arch-10.jpeg" alt="" />
<img src="//post_images/debug/arch-11.jpeg" alt="" />
<img src="//post_images/debug/arch-12.jpeg" alt="" />
<img src="//post_images/debug/arch-13.jpeg" alt="" />
<img src="//post_images/debug/arch-14.jpeg" alt="" />
<img src="//post_images/debug/arch-15.jpeg" alt="" />
<img src="//post_images/debug/arch-16.jpeg" alt="" />
<img src="//post_images/debug/arch-17.jpeg" alt="" />
<img src="//post_images/debug/arch-18.jpeg" alt="" />
<img src="//post_images/debug/arch-19.jpeg" alt="" />
<img src="//post_images/debug/arch-20.jpeg" alt="" />
<img src="//post_images/debug/arch-21.jpeg" alt="" />
<img src="//post_images/debug/arch-22.jpeg" alt="" />
<img src="//post_images/debug/arch-23.jpeg" alt="" />
<img src="//post_images/debug/arch-24.jpeg" alt="" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Java应用性能调优之调优准备]]></title>
    <link href="http://www.rowkey.me/blog/2018/10/31/profile-ready/"/>
    <updated>2018-10-31T22:29:34+08:00</updated>
    <id>http://www.rowkey.me/blog/2018/10/31/profile-ready</id>
    <content type="html"><![CDATA[<p>实际的开发工作中，有时候会遇到程序突然变得响应缓慢或者进程消失的情况。这时候就需要对程序进行问题排查和调优，找出产生问题的根源，并进行优化。</p>

<!--more-->


<ul>
<li>调优概览：<a href="https://github.com/superhj1987/pragmatic-java-engineer/blob/master/book/chapter8-profile/README.md">https://github.com/superhj1987/pragmatic-java-engineer/blob/master/book/chapter8-profile/README.md</a></li>
<li>调优准备：<a href="https://github.com/superhj1987/pragmatic-java-engineer/blob/master/book/chapter8-profile/ready.md">https://github.com/superhj1987/pragmatic-java-engineer/blob/master/book/chapter8-profile/ready.md</a></li>
</ul>


<blockquote><p>本文来自《Java工程师修炼之道》一书。</p></blockquote>

<p><img src="http://www.rowkey.me/post_images/book-all.png" width="400"/></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[架构设计与原则（2018修订版）]]></title>
    <link href="http://www.rowkey.me/blog/2018/09/20/arch-new/"/>
    <updated>2018-09-20T22:29:34+08:00</updated>
    <id>http://www.rowkey.me/blog/2018/09/20/arch-new</id>
    <content type="html"><![CDATA[<p>之前的<a href="http://www.rowkey.me/blog/2017/08/24/arch/">《谈谈架构》</a>的最新修订版。</p>

<p><strong>来自公司内部分享</strong></p>

<!--more-->


<p><img src="//post_images/arch-new/arch-2.jpeg" alt="" />
<img src="//post_images/arch-new/arch-3.jpeg" alt="" />
<img src="//post_images/arch-new/arch-4.jpeg" alt="" />
<img src="//post_images/arch-new/arch-5.jpeg" alt="" />
<img src="//post_images/arch-new/arch-6.jpeg" alt="" />
<img src="//post_images/arch-new/arch-7.jpeg" alt="" />
<img src="//post_images/arch-new/arch-8.jpeg" alt="" />
<img src="//post_images/arch-new/arch-9.jpeg" alt="" />
<img src="//post_images/arch-new/arch-10.jpeg" alt="" />
<img src="//post_images/arch-new/arch-11.jpeg" alt="" />
<img src="//post_images/arch-new/arch-12.jpeg" alt="" />
<img src="//post_images/arch-new/arch-13.jpeg" alt="" />
<img src="//post_images/arch-new/arch-14.jpeg" alt="" />
<img src="//post_images/arch-new/arch-15.jpeg" alt="" />
<img src="//post_images/arch-new/arch-16.jpeg" alt="" />
<img src="//post_images/arch-new/arch-17.jpeg" alt="" />
<img src="//post_images/arch-new/arch-18.jpeg" alt="" />
<img src="//post_images/arch-new/arch-19.jpeg" alt="" />
<img src="//post_images/arch-new/arch-20.jpeg" alt="" />
<img src="//post_images/arch-new/arch-21.jpeg" alt="" />
<img src="//post_images/arch-new/arch-22.jpeg" alt="" />
<img src="//post_images/arch-new/arch-23.jpeg" alt="" />
<img src="//post_images/arch-new/arch-24.jpeg" alt="" />
<img src="//post_images/arch-new/arch-25.jpeg" alt="" />
<img src="//post_images/arch-new/arch-26.jpeg" alt="" />
<img src="//post_images/arch-new/arch-27.jpeg" alt="" />
<img src="//post_images/arch-new/arch-28.jpeg" alt="" />
<img src="//post_images/arch-new/arch-29.jpeg" alt="" /></p>

<p><strong>附录链接：</strong></p>

<ul>
<li><a href="https://www.ibm.com/developerworks/cn/rational/06/r-wenyu/index.html">软件架构 &ldquo;4+1&rdquo; 视图模型</a>: 逻辑视图、开发视图、过程视图、物理视图 + 场景视图</li>
<li><a href="https://github.com/superhj1987/awesome-tech-collections/blob/master/document/tech-research.md">技术调研文档模板</a>:技术方案调研输出</li>
<li><a href="https://github.com/superhj1987/awesome-tech-collections/blob/master/document/tech-analysis.md">技术方案分析文档模板</a>: 技术方案选型，设计、评估和选择备选方案</li>
<li><a href="https://github.com/superhj1987/awesome-tech-collections/blob/master/document/arch.md">系统设计文档模板</a>:系统架构设计</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[响应式微服务架构-分布式系统设计原则]]></title>
    <link href="http://www.rowkey.me/blog/2018/06/07/reactive-microservice/"/>
    <updated>2018-06-07T19:29:34+08:00</updated>
    <id>http://www.rowkey.me/blog/2018/06/07/reactive-microservice</id>
    <content type="html"><![CDATA[<p>O’Reilly的电子书《Reactive Microservices Architecture》讲述了微服务/分布式系统的一些设计原则，本文是笔者阅读完此书后的理解。书籍地址：<a href="https://info.lightbend.com/COLL-20XX-Reactive-Microservices-Architecture-RES-LP.html">https://info.lightbend.com/COLL-20XX-Reactive-Microservices-Architecture-RES-LP.html</a>。</p>

<!--more-->


<p>微服务相比传统的单体应用能够带来快速的响应，以小的系统产生大的影响。而随着网络加速、磁盘成本降低、RAM成本降低、多核技术的发展、云架构技术的爆发，微服务不再受这些客观条件的限制，已经开始大规模的应用。</p>

<p>与SOA架构，微服务和它都具有相同的初衷：解耦、隔离、组合、集成、分散以及自主，但是SOA经常被误解和误用，尤其是使用ESB来支持对多个单体系统的协议（复杂、低效、不稳定）调用，使得系统变得非常复杂。而随着这些年硬件以及软件架构理念的发展，所有的系统基本都已经变成分布式架构，也带来了很多新的挑战。也就需要新的思路和理念来面对这些问题，其中本书所讲述的响应式原则（Reactive principles）即一种解决分布式系统的思路。响应式原则也并非一个新的东西，Erlang中的Actor模型即一种响应式设计。微服务是响应式原则的一个架构设计，其借鉴了SOA架构中好的理念，并使用了现代的基础服务设施（云服务、自动化工具等）。</p>

<h2>响应式微服务定义</h2>

<p>使用微服务架构最关键的一个原则就是将系统划分成一个个相互隔离、无依赖的子系统，这些子系统通过定义良好的协议进行通信。其中隔离是实现弹性、可伸缩系统的前提，并且需要在服务间建立异步通信边界，因此要在以下两方面进行解耦：</p>

<ul>
<li>时间：允许并发。</li>
<li>空间：允许分布式和移动性，即服务能够随时移动。</li>
</ul>


<p>此外，微服务还需要消除共享状态从而最小化相互协作、联结的成本，要尽量达到“不共享任何东西”。</p>

<h3>隔离任何东西</h3>

<p>隔离是微服务架构中最重要的特性。不仅仅是微服务带来的很多优势的基础，也是对设计和架构影响最大的方面。如康威定律所说，它还对组织架构有非常大的影响，</p>

<pre><code>系统的结构是对团队组织架构的反映。
</code></pre>

<p>失败隔离是一种与“舱壁”（船舱的隔板）相关的设计模式：隔离错误、失败以防止其蔓延至所有服务，导致更大面积的失败。</p>

<p>“舱壁”这种模式已经在轮船上使用了几个世纪：创建一个个密封不漏水的空间以防止船的外壳破损或者其他泄漏。这些空间是完全互相隔离的，这样即使一个隔离区充满了水，也不会蔓延流到其他隔离空间中，从而使得船整体仍然能够运作。</p>

<p>弹性（从失败中恢复的能力）即依赖于这种舱壁和失败隔离的设计，并且需要打破同步通信机制。由此，微服务一般是在边界之间使用异步消息传输，从而使得正常的业务逻辑避免对捕获错误、错误处理的依赖。</p>

<p>进一步的，服务之间的隔离使得“持续交付”变得很容易，能够随时地部署服务而无需担心影响正常的业务。而且隔离的单个服务很容易监控、调试、测试和部署，非常便于扩展。</p>

<h3>自主地行动</h3>

<p>上面所讲的隔离是自主性的前提。只有当服务之间是完全隔离的，那么才可能实现完全的自主，包括独立的决策、独立的行动以及与其他服务协调合作来解决问题。</p>

<p>一个自主的服务仅仅保证其对外公布的协议/API的正确性即可。如此，不仅能够让我们更好地了解协作的这些系统以及对他们的建模，也能够在面对冲突、失败状况时，只在一个服务内进行排查、修复即可。</p>

<p>使用自主服务能够给服务编排、工作流管理以及服务合作上带来很大灵活性，同时也带来可扩展性、可用性、运行时管理等优势。但其付出的代价就是需要花心思在定义良好的可组合的API设计上，这个是有一定挑战性的。</p>

<h3>只做一件事，并且做好</h3>

<p>如Unix编程哲学所说：程序应该只做一件事，并且做好它。然后让他们一起工作完成任务。这也类似于面向对象编程语言中软件开发单一职责原则（SRP）的描述。</p>

<p>而在微服务中一个很大的问题就是如何正确地确定服务的大小。比如怎样的粒度才能被认为是“微”（micro）？多少行代码还能被认为是微服务。但这里“micro”其实是和职责范围有关的，就如Unix的SRP原则：只做一件事并且做好。</p>

<p>每一个服务都应该只有一个存在的原因，提供了一组相关的功能，业务和职责不会糅杂在一起。所有服务组织在一起整体上能够便于扩展、具有弹性、易理解和维护。</p>

<h3>拥有自己的私有状态</h3>

<p>微服务中有一个很关键的部分就是状态（state），很多微服务也都是有状态的实体，包括对状态和行为的封装。而在“无状态”的设计理念下，很多服务都把自己的状态下沉到一个大的共享数据库中，这也是很多传统的Web框架的做法。如此就造成了在扩展性、可用性以及数据集成上很难做好把控。而本质上，一个有着共享数据库的微服务架构本质还是一个单体应用。</p>

<p>合理的方式是一个服务既然具有单一职责，那么就应该拥有自己的状态和持久化机制，建模成一个边界上下文，有自己的域名和语言。这些也都是DDD（Domain-Drivern Design）里面的技术。微服务受DDD影响很大，其中很多微服务的上下文的概念都来自于DDD。</p>

<p>当访问一个服务时，也只能是客气的请求其状态而并不能强制其一定具有状态。如此，每个服务都能够通过事件溯源(Event Sourcing)和CQRS（Command Query Responsibility Segreation）自定义自己的状态表示和实现（RDBMS、NoSQL、Time-Series、EventLog）。</p>

<p>去中心化的数据管理和持久化（多语言持久化）能够带来很多优势。数据的存储媒介可以根据服务自己的需要选择，服务包括其数据都可以看做一个单独的单元。同时并不允许一个服务直接去访问另一个服务的数据库，如果要访问只能通过API（通过指定规范、策略和Code Review来保证）。</p>

<p>Event Log是一种消息的存储方式。我们可以以消息进入服务的形式存储（发送到服务的Commnds），即命令溯源(Command Sourcing)。我们也可以忽略命令，让命令先执行对服务产生一些作用，如果触发了状态变更，那么我们捕获此次变动并用事件溯源（Event Sourcing）将此次Event存储到EventLog中。</p>

<p>消息有序存储，能够提供服务所有的交互历史。同时消息也保存了服务的事务，也就能够对这些事务日志进行查询、审计、重放从而用于弹性伸缩、调试以及冗余等。</p>

<p>命令溯源和事件溯源是不同的语义。重放命令意味着会重放其带来的副作用。而重放事件则是执行状态的改变。需要根据具体场景的不同选择使用哪种溯源技术。</p>

<p>使用EventLog可以避免&#8221;对象关系不匹配&#8221;的问题（ORM中经常出现）。而由于其自身天然适合异步消息传输，因此绝大多数情况下，Event Log是微服务中最佳的持久化模型。</p>

<h3>拥抱异步消息传输</h3>

<p>微服务之间的通信的最佳机制就是消息传输。如上文所说，服务之间的异步边界能够在时间和空间两方面进行解耦，能够提升整体系统的性能。</p>

<p>异步非阻塞执行以及IO都是对资源的高效操作，能够最小化访问共享资源时的阻塞消耗（扩展性、低延迟以及高吞吐的最大障碍）。简单的例子：如果要发起对10个服务的访问，其中每一个请求需要耗时100ms，那么如果使用同步模式，则完成所有请求则需要10*100=1000ms。而如果使用异步模式，同时发起10个线程，则一共就需要100ms。</p>

<p>异步消息传输还能够让我们注重网络编程的限制，而不是假装这些限制不存在，尤其是在失败场景下。还能够让我们更关注工作流以及服务间的数据流、协议、交互是怎样进行的。</p>

<p>然而目前微服务的默认通信协议以REST为主，其本质是同步通信机制，比较适用于可控的服务调用或者紧耦合的服务调用上。</p>

<p>此外，使用异步消息传输的另一个需求在于对消息的持续流处理（可能是无界的）。也是我们从“data at rest”到&#8221;data in motion&#8221;的理念的改变。之前的数据是离线被使用的，而现在的数据是被在线处理的。应用对数据变更的响应需要达到实时级别：当变动发生，需要实时进行持续的查询、聚合并反馈给最终的应用。这个理念的形成经历了三个主要阶段：</p>

<ol>
<li><p>&ldquo;data at rest&rdquo;: 将大量数据存储在HDFS类似的数据存储媒介中，然后使用离线批处理技术去处理这些数据，一般会有数个小时的延迟。</p></li>
<li><p>意识到了“data in motion”正变得越来越重要：在数秒内捕获数据、处理数据并反馈给运行中的系统。Lambda即此时出现的一种架构: 加速层用来做实时在线计算；批处理层用来做复杂的离线处理。加速层实时处理的结果后续被批处理层的结果合并。这个模型解决了某些场景需要数据即时响应的问题，但其架构的复杂使得不容易维护。</p></li>
<li><p>“data in motion”: 全面拥抱移动数据的概念。传统的面向批处理的架构都在逐渐向纯流处理的架构转变。这种模型作为通信协议和持久化方案（通过Event Logging）也能够给微服务带来“data in motion”和流处理的能力。</p></li>
</ol>


<h3>保持移动，但可寻址</h3>

<p>如上述所讲，异步消息传输带来了对时间和空间的解耦。其中，对于空间的解耦也被称为“位置透明”：在多核或者多结点上的微服务在运行时无须改变结点即可以动态扩展的能力。这也决定了系统的弹性和移动性。要实现这些需要依赖云计算带来的一些特性和其“按需使用”模型。</p>

<p>而可寻址则是说服务的地址需要是稳定的，从而可以无限地引用此服务，而无论服务目前是否可以被定位到。当服务在运行中、已经停止、被挂起、升级中、已经崩溃等等情形下，地址都应该是可用的，任意客户端能够随时发送消息给一个地址。实际中，这些消息有可能进入队列排队、重提交、代理、日志记录或者进入死信队列。此外，地址需要是虚拟的，可以代表一组实例提供的服务。</p>

<ul>
<li>在无状态的服务间做负载均衡：如果服务是无状态的，那么请求被哪一个服务实例处理都是没任何问题的。也有很多种的路由算法供使用，如：轮训、广播或者基于度量信息。</li>
<li>在有状态的服务之间构建Active-Passive的冗余设计：如果一个服务是有状态的，那么可以使用sticky路由算法（同一个客户端的请求都会发送给同一个服务实例）。冗余一个passive实例是为了在主实例挂的时候接管上面的请求。因此，服务的每一个状态变动都需要同步到passive实例上。</li>
<li>有状态的服务的重定位：将一个服务实例从一个位置移动到另一个位置可以提高引用的本地性（让数据和计算靠近）和资源利用率。</li>
</ul>


<p>使用虚拟地址能够让服务消费方无须关心服务目前是如何配置操作的，只要知道地址即可。</p>

<h2>微服务系统实现</h2>

<p>一个微服务并非真正的“微服务”，一系列微服务通过通信、合作才能够解决问题，才能组成一个完整的业务系统。实现一个服务是相对简单的，困难的是其他基础设施的实现：服务发现、协作、安全、冗余、数据一致性、容错、部署以及与其他系统的集成。</p>

<h3>系统需要利用现实</h3>

<p>微服务架构带来的一个很大优势就在于它提供了一套工具，能够利用现实，模仿真实的世界来创建系统，包括真实世界的限制和机会。</p>

<p>首先根据“康威定律”，微服务的部署是和现实中工程组织/部门如何工作是相适应的。此外，还需要注意的是现实不是一致的，任何事情都是相对的，即使是时间和“现在”这个概念。</p>

<p>信息的传播速度不可能比光快，甚至大部分是很慢的，这也意味着信息通信是有延迟的。信息都是来自过去的，我们稍微思考一下可以知道信息承载的都是我们观察到的东西。而我们观察/学习到的事实至少都是很短时间之前发生的，也就是说我们总是在看过去，“现在”只是旁观者的视角。</p>

<p>每一个微服务都可以看做一个安全的小岛，提供了确定性和强一致性，上面的时间和“目前”都是绝对的。但是当离开一个微服务的边界时，就进入了一片充满非确定性的大海-分布式系统的世界。如很多人所说，构建分布式系统是困难的。但现实世界同时也提供了如何解决诸如弹性、可伸缩、隔离性等分布式问题的解决思路。因此，即使构建分布式系统是困难的，但是我们也不应该退化为单体应用，而是学习如何使用一系列的设计原则、抽象概念和工具来管理它。</p>

<p>正如Pat Helland在《Data on the Outside versus Data on the Inside.”》对&#8221;data on the inside&#8221;和“data on the outside”的对比所说：内部的数据就是我们本地的“目前”，而外部数据-事件即是来自过去的信息，服务之间的命令则是“对未来的希望”。</p>

<h3>服务发现</h3>

<p>服务发现要解决的问题就是如何定位一系列的服务从而可以使用地址去调用。其中最简单的手段就是将地址和端口信息硬编码在所有服务中或者外置在服务的配置文件中。这种方式的问题在于其是一种静态部署模型，与微服务的初衷是相矛盾的。</p>

<p>服务需要保持解耦和移动，而系统需要是弹性和动态的。因此可以通过使用控制反转（Inversion of Control）模式引入一个间接层来解决此问题。也就是说每一个服务都上报自己的信息（位置、如何访问）给一个统一的平台。这个平台被称作“服务发现”，是微服务平台的一个基础部分。这样，一旦服务的信息被存储了，服务就可以使用“服务注册中心”来查找调用服务的信息，这种模式被称作“Client-Side服务发现”。另一种策略是将信息存储、维护在一个负载均衡器（AWS的ELB)或者直接维护在服务提供方的地址中-“Server-Side服务发现”。</p>

<p>可以选择CP特性的数据库作为服务信息的存储，能够保证信息的一致性。但是这种数据库是牺牲了一定程度的可用性来达到强一致性的，并且依赖一些额外的基础设施，而很多时候强一致性并非那么需要。因此，更好的选择是使用AP特性的点对点的技术来存储，比如使用CRDTs（Conflict-Free Replicated Data Types ）与Epidemic Gossip可以实现信息的最终一致性传播，能够有更好的弹性，也不需要额外的基础设施。</p>

<h3>API管理</h3>

<p>API管理解决的问题在于如何将服务的协议和API统一管理起来，以方便服务的调用。包括协议和数据版本的升级和后退等。解决此问题可以通过引入一个负责序列化编码、协议维护以及数据传输的层，甚至直接将服务版本化。这在DDD中被称作&#8221;Anti-Corruption&#8221;层，可以加入到服务本身或者在API网关中实现。</p>

<p>假如一个客户端需要调用10个服务（每一个都有不同的API）来完成一个任务，那么对于这个客户端来说是非常繁琐的。相比起让客户端直接去调用服务，更好的方式是让客户端通过API网关服务来调用。API网关负责接受客户端的请求，然后路由请求到相应的服务（如果有必要需要转换协议），组装响应并将其返回给客户端。这样，做为客户端和服务之间的一层其就能够简化client-to-service协议。但这里如果是中心化的则很难达到高可用和可扩展性，所以使用去中心化技术（比如服务发现）实现API网关则是更好的选择。</p>

<p><img src="//post_images/rx-ms/gw.png" alt="" /></p>

<p>但需要注意的是API网关，包括所有的核心出服务并不是一定要自建的，理想地它应该是底层平台的一部分。</p>

<h3>管理通信模式</h3>

<p>在一个由数个微服务组成的系统中，使用点对点的通信就能完成服务间的通信工作。但是当服务数目越来越多，如果还是让他们之间直接调用，那么很快整个系统会变得混乱不堪。解决此问题需要一个机制能够解耦发送者和接受者，并且能够按照某种定义好的原则路由数据。</p>

<p>发布订阅机制是一种解决方案：发布者发布信息到某个topic中，订阅者监听此topic以监听消息。可以使用可扩展消息系统（Apache Kafka、Amazon Kinesis）或者NoSQL数据库（AP特性数据库，如Cassendra和Riak）来实现。</p>

<p>在SOA架构中，ESB承担的即这种角色。微服务中我们肯定不会使用它来桥接单体应用，但是可以将它做为一个发布系统用来广播任务和数据或者做为系统间的通信总线（通过Spark Streaming收集数据到Spark中）。</p>

<p>发布订阅协议有时候也是有不足的。比如无法提供允许程序员自定义路由规则的高级路由特性或者数据的转化、丰富、分隔以及合并等功能（可以使用Akka Streams或者Apache Camel）。</p>

<h3>集成</h3>

<p>系统与外界或者系统之间的通信都是必需的。当与一个外部系统通信时，尤其当外部系统无法把控时，那么就会有很大的失败风险（系统超载、业务失败）。因此即使协议协商得再好，也不能信赖外部服务，需要做好各种预防措施以保证自身服务的安全。</p>

<p>首先要达成一个良好的协议从而可以最小化一个系统突发超载造成服务不可用的风险，比如要避免发起的请求超过服务提供方的承载能力。也要尽量避免使用同步通信机制，否则就把自身服务的可用性放在了依赖的第三方服务的控制中。</p>

<p>避免级联失败需要服务足够解耦和隔离。使用异步通信机制是一个最佳的方案。此外，还需要通过背压（back-pressure，接收方根据自己的接受状况调节接受速率，通过反向的响应来控制发送方的发送速率）来达成数据流速度的一致性，以防止响应快速的系统压垮其中较慢的部分。而越来越多的工具和库都在开始拥抱“响应式流”（Reactive Streams）规范（Akka Stream、RxJava、Spark Streaming、Cassandra drivers），这些技术使用异步背压实时流来桥接系统，从而在总体上提高系统的可靠性、性能以及互操作性。</p>

<p>如何管理调用服务时候的失败也是微服务中一个关键的问题。捕获到错误后，先重试，而如果错误一直发生，那么就隔离服务一段时间直到服务恢复-“断路器”模式（Netflix和Akka中都有实现）。</p>

<p>面对可扩展性、高吞吐以及可用性的要求，系统集成的实现从传统的依赖于中心化服务如RDBMS/ESB逐渐变为现在采用去中心化策略（HTTP REST、ZeroMQ）或者订阅发布系统（Kakka、Amazon Kinesis）。而最近事件流平台（Event Streaming Platforms）正成为系统集成选型的趋势，其理念来自于Fast Data和实时数据管理。</p>

<p>如上文所述，服务之间使用异步通信机制能够得到很多的好处。但是如果是客户端（浏览器、APP）与服务之间的通信，使用REST经常是更好的选择。但是并非所有的地方都非得使用同步通信机制，需要根据不同的场景做不同的评估。很多情况下，开发者出于习惯都会倾向于使用同步方案，而不是根据真正的需要作出能够简化操作、提升操作性的选择。这里给出几个通常会使用同步方案建模但其本质是异步行为的事例：</p>

<ul>
<li>查询一个商品是否有货，如果此商品比较热门被卖光了，用户要得到通知。</li>
<li>如果一个餐馆的特价菜单改动了，用户要立刻知道。</li>
<li>用户对于一个网站的评论需要实时对话。</li>
<li>广告系统根据用户在页面上的行为输出不同的响应。</li>
</ul>


<p>对于上述实例，我们需要分别进行分析去理解怎样才是符合客户端和服务通信的最自然的方式。同时也经常需要根据数据的完整性约束来寻找可以弱化一致性保证（有序）的可能，目的就是找到最少的协调约束条件给用户以直观的语义：找到利用现实的最佳策略。</p>

<h3>安全管理</h3>

<p>安全管理主要是对服务的认证授权管理，限制某些service只允许某些服务访问。</p>

<ul>
<li>TLS Client Certificates也被称为相互验证、双路验证。它给每一个service都分配一个单独的私钥和证书，从而能够很好地保证服务间的认证访问。不仅仅服务要验证客户端的身份，客户端也要验证服务的身份。因此，其不仅能防止数据被窃听，而且即使在不安全的网络中也能防止对数据的拦截和转发。基于SSL之上的通信不仅安全，其也是一个公开、易于理解的标准。但是其非常复杂，无法得到底层平台的足够支持。同样的，HTTPS Basic Authentication也是双路验证，但其对SSL证书的管理也很复杂，请求也不能被反向代理缓存。</li>
<li>Asymmetric Request Signing：每一个服务都需要使用自己的私钥给自己发送的请求进行签名，同时每一个服务的公钥都要上报给“服务发现”服务。此方案的缺点在于一旦网络不可靠，那么则很难防止数据窃听或者请求重放攻击。</li>
<li>Hash Message Authentication Code (HMAC) ： 基于共享密钥来对请求进行一定规则的签名。这个方案比较简单，但是由于每一对需要通信的服务都需要唯一的一个共享密钥，整个系统则需要所有服务排列数目的共享密钥数量，实现起来比较麻烦。</li>
</ul>


<h3>最小化数据耦合</h3>

<p>微服务架构中，完成一个任务需要多个服务的协同，因此最小化服务之间的状态协作成本，有助于提升微服务系统的整体性能。</p>

<p>需要做的是要从业务的视角去分析数据以理解数据间的关系、担保和完整性约束。然后对数据进行反范式设计并在系统内定义一致性边界。如此，可以在边界内部实现强一致性。接着，需要使用这些边界来驱动微服务的设计和范围。如果设计的服务之间有很多数据依赖和关系，那么就需要去减少甚至是消除这些数据的耦合，从而避免对服务状态的协同。</p>

<h3>最小化协作成本</h3>

<p>如上节所述，已经最小化数据耦合了，但仍然还是会有业务场景需要多个服务协作完成。这个的确是无法避免的，但到了目前这一步，需要做的是可以根据需要逐渐的添加协作，而不是一开始各种耦合再逐渐去消除（比较麻烦和困难）。</p>

<p>这里提供几种可扩展、弹性伸缩的方式来协同数据改变，以达到Composability（对数据的变动无须停止数据所在的服务，也无须等待某些条件）。</p>

<ul>
<li>Apology-Oriented Programming: 基于请求原谅比请求权限容易的想法。如果你不能响应协作，那么就做出一个合理的猜测，赌一个条件已经满足，后续如果错了，那么就道歉并做补偿。这种做法和现实是非常相似的。比如航班的超售，如果起飞的时候没有座位那么就去做一些补偿措施。</li>
<li>事件驱动架构（Event-Driven Architecture ）：基于异步消息传输和事件溯源。需要区分命令和事件，命令表示一个将要产生副作用的操作意图（对未来的希望），而事件表示已经发生的事实。使用CQRS模式进行查询，将写入方（持久化事件日志）与读取方（将数据存入RDBMS或者NoSQL数据库中）分离。这里使用事件日志做状态管理和持久化具有很多好处：简化审计、调试、冗余、容错，并且允许重放过去任意时间点的事件流。</li>
<li>ACID2.0：由Pat Helland创造，定义了一组原则，目的是实现可扩展、弹性的协议以及API设计。A是Associative，表示分组消息不会产生影响，可以批量处理。C是Commutative，表示消息的顺序不重要。I是Idempotent，表示消息重复不会产生影响。D是Distributed，没有实质的意义，猜测是为了凑ACID这个首字母缩写。</li>
</ul>


<p>CRDTs是一个囊括了上面这些东西的工具，可以实现最终一致性、据有丰富的数据结构（counters、sets、maps、graphs），并且不需要协作就可以收敛聚合。其更新操作的顺序前后也并不影响最终的合并结果，能够自动安全的进行合并。虽然CRDTs最近才出现在业界视野中，但其实它已经在生产环境使用了很多年。已经有一些生产级别的库可以直接使用（Akka、Riak）。</p>

<p>然而，很多业务场景并不允许最终一致性。这时可以使用因果一致性（causal consistency）。因果关系很容易被大家理解。而且因果一致性模型能够实现可扩展性和可用性。其一般使用逻辑时间，在很多NoSQL数据库、事件日志以及分布式事件流产品中都可用。</p>

<p>分布式事务是一个经常使用的方式用来协调分布式系统的变动，但其本质需要约束并发执行，保证同一时间只有一个用户在操作。因此其成本非常昂贵，会使得系统变慢、无法扩展。<a href="http://bit.ly/22hhl6F">Saga模式</a>是分布式事务之外的一个能够实现可扩展、弹性伸缩的选择。它的理论基础在于一个长时间运行的业务事务大多时候都是由多个事务步骤组成的，而事务步骤的总体一致性能够通过将这些步骤分组成一个总体的分布式事务来实现。该技术将每一个阶段的事务与一个可补偿回滚的事务配对，如果一个阶段的事务失败了，那么总体的分布式事务就可以回滚（反向顺序）。</p>

<p><img src="//post_images/rx-ms/saga.png" alt="" /></p>

<h3>总结</h3>

<p>当设计一个响应式微服务时，需要坚持隔离、单一职责、自主、独占状态、异步消息传输和移动等特质。微服务需要协作才能形成一个系统去发挥作用。一个能够提供基础服务和响应式原则模式的复杂微服务平台是有必要的。</p>

<p><img src="http://www.rowkey.me/post_images/book-all.png" width="400"/></p>
]]></content>
  </entry>
  
</feed>
